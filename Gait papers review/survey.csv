name,doi,Abstract,keywords,URL,key,Algorithm used,Accuracy,base network/provided network,github,application,Dataset,Notes,favourite,Category
"N. Wu et al., ""Deep Neural Networks Improve Radiologists’ Performance in Breast Cancer Screening,"" in IEEE Transactions on Medical Imaging, vol. 39, no. 4, pp. 1184-1194, April 2020.",doi: 10.1109/TMI.2019.2945514,"Abstract: We present a deep convolutional neural network for breast cancer screening exam classification, trained, and evaluated on over 200000 exams (over 1000000 images). Our network achieves an AUC of 0.895 in predicting the presence of cancer in the breast, when tested on the screening population. We attribute the high accuracy to a few technical advances. 1) Our network's novel two-stage architecture and training procedure, which allows us to use a high-capacity patch-level network to learn from pixel-level labels alongside a network learning from macroscopic breast-level labels. 2) A custom ResNet-based network used as a building block of our model, whose balance of depth and width is optimized for high-resolution medical images. 3) Pretraining the network on screening BI-RADS classification, a related task with more noisy labels. 4) Combining multiple input views in an optimal way among a number of possible choices. To validate our model, we conducted a reader study with 14 readers, each reading 720 screening mammogram exams, and show that our model is as accurate as experienced radiologists when presented with the same data. We also show that a hybrid model, averaging the probability of malignancy predicted by a radiologist with a prediction of our neural network, is more accurate than either of the two separately. To further understand our results, we conduct a thorough analysis of our network's performance on different subpopulations of the screening population, the model's design, training procedure, errors, and properties of its internal representations. Our best models are publicly available at https://github.com/nyukat/breast_cancer_classifier.","keywords: {cancer;convolutional neural nets;image classification;image resolution;learning (artificial intelligence);mammography;medical image processing;probability;probability;network learning;breast cancer screening exam classification;deep convolutional neural network;radiologist performance;hybrid model;experienced radiologists;screening mammogram exams;noisy labels;screening BI-RADS classification;high-resolution medical images;custom ResNet-based network;macroscopic breast-level labels;pixel-level labels;high-capacity patch-level network;training procedure;two-stage architecture;technical advances;screening population;Breast cancer;Task analysis;Biomedical imaging;Predictive models;Training;Deep learning;deep convolutional neural networks;breast cancer screening;mammography},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8861376&isnumber=9055242,1,CNN,0.895 AUC,ResNet,GitHub - nyukat/breast_cancer_classifier: Deep Neural Networks Improve Radiologists' Performance in Breast Cancer Screening,radiology: breast cancer detection,,,,1
"T. Lin, P. Goyal, R. Girshick, K. He and P. Dollár, ""Focal Loss for Dense Object Detection,"" in IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 42, no. 2, pp. 318-327, 1 Feb. 2020.",doi: 10.1109/TPAMI.2018.2858826,"Abstract: The highest accuracy object detectors to date are based on a two-stage approach popularized by R-CNN, where a classifier is applied to a sparse set of candidate object locations. In contrast, one-stage detectors that are applied over a regular, dense sampling of possible object locations have the potential to be faster and simpler, but have trailed the accuracy of two-stage detectors thus far. In this paper, we investigate why this is the case. We discover that the extreme foreground-background class imbalance encountered during training of dense detectors is the central cause. We propose to address this class imbalance by reshaping the standard cross entropy loss such that it down-weights the loss assigned to well-classified examples. Our novel Focal Loss focuses training on a sparse set of hard examples and prevents the vast number of easy negatives from overwhelming the detector during training. To evaluate the effectiveness of our loss, we design and train a simple dense detector we call RetinaNet. Our results show that when trained with the focal loss, RetinaNet is able to match the speed of previous one-stage detectors while surpassing the accuracy of all existing state-of-the-art two-stage detectors. Code is at: https://github.com/facebookresearch/Detectron.","keywords: {convolutional neural nets;entropy;image classification;image segmentation;learning (artificial intelligence);object detection;dense sampling;cross entropy loss;focal loss;dense object detection;classifier;foreground-background class imbalance;R-CNN;RetinaNet;convolutional neural networks;machine leaming;Detectors;Training;Object detection;Entropy;Proposals;Convolutional neural networks;Feature extraction;Computer vision;object detection;machine learning;convolutional neural networks},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8417976&isnumber=8952810,2,CNN,40 AP,"RetinaNet, ResNet, FPN","GitHub - facebookresearch/Detectron: FAIR's research platform for object detection research, implementing popular algorithms like Mask R-CNN and RetinaNet.",,COCO,,1,
"K. He, G. Gkioxari, P. Dollár and R. Girshick, ""Mask R-CNN,"" in IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 42, no. 2, pp. 386-397, 1 Feb. 2020.",doi: 10.1109/TPAMI.2018.2844175,"Abstract: We present a conceptually simple, flexible, and general framework for object instance segmentation. Our approach efficiently detects objects in an image while simultaneously generating a high-quality segmentation mask for each instance. The method, called Mask R-CNN, extends Faster R-CNN by adding a branch for predicting an object mask in parallel with the existing branch for bounding box recognition. Mask R-CNN is simple to train and adds only a small overhead to Faster R-CNN, running at 5 fps. Moreover, Mask R-CNN is easy to generalize to other tasks, e.g., allowing us to estimate human poses in the same framework. We show top results in all three tracks of the COCO suite of challenges, including instance segmentation, bounding-box object detection, and person keypoint detection. Without bells and whistles, Mask R-CNN outperforms all existing, single-model entries on every task, including the COCO 2016 challenge winners. We hope our simple and effective approach will serve as a solid baseline and help ease future research in instance-level recognition. Code has been made available at: https://github.com/facebookresearch/Detectron.","keywords: {convolutional neural nets;image segmentation;object detection;object recognition;pose estimation;Faster R-CNN;Mask R-CNN;object mask;bounding-box object detection;flexible framework;object instance segmentation;high-quality segmentation mask;bounding box recognition;human pose estimation;COCO suite;person keypoint detection;instance-level recognition;Task analysis;Semantics;Feature extraction;Object detection;Proposals;Image segmentation;Quantization (signal);Instance segmentation;object detection;pose estimation;convolutional neural network},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8372616&isnumber=8952810,3,R-CNN,37 AP,"ResNet, FPN","GitHub - facebookresearch/Detectron: FAIR's research platform for object detection research, implementing popular algorithms like Mask R-CNN and RetinaNet.",,COCO,,2,
"S. Dey, A. K. Singh, D. K. Prasad and K. D. Mcdonald-Maier, ""IRON-MAN: An Approach to Perform Temporal Motionless Analysis of Video Using CNN in MPSoC,"" in IEEE Access, vol. 8, pp. 137101-137115, 2020.",doi: 10.1109/ACCESS.2020.3010185,"Abstract: This paper proposes a novel human-inspired methodology called IRON-MAN (Integrated RatiONal prediction and Motionless ANalysis) for mobile multi-processor systems-on-chips (MPSoCs). The methodology integrates analysis of the previous image frames of the video to represent the analysis of the current frame in order to perform Temporal Motionless Analysis of the Video (TMAV). This is the first work on TMAV using Convolutional Neural Network (CNN) for scene prediction in MPSoCs. Experimental results show that our methodology outperforms state-of-the-art. We also introduce a metric named, Energy Consumption per Training Image (ECTI) to assess the suitability of using a CNN model in mobile MPSoCs with a focus on energy consumption and lifespan reliability of the device.","keywords: {convolutional neural nets;image segmentation;learning (artificial intelligence);multiprocessing systems;system-on-chip;video signal processing;CNN model;mobile MPSoCs;energy consumption;IRON-MAN;MPSoC;mobile multiprocessor systems-on-chips;image frames;TMAV;convolutional neural network;scene prediction;human-inspired methodology;integrated rational prediction and motionless analysis;temporal motionless analysis of the video;Streaming media;Predictive models;Cameras;Energy consumption;Reliability;Analytical models;Convolutional neural networks;Convolutional neural network (CNN);temporal analysis;motionless analysis;video;lifespan;reliability;energy efficiency;embedded device;multiprocessor systems-on-chip (MPSoCs)},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9144173&isnumber=8948470,4,CNN,0.795,CNN,,Wifi roads surveilance ,UCSD,,,
"C. Luo, J. Ji, Q. Wang, X. Chen and P. Li, ""Channel State Information Prediction for 5G Wireless Communications: A Deep Learning Approach,"" in IEEE Transactions on Network Science and Engineering, vol. 7, no. 1, pp. 227-236, 1 Jan.-March 2020.",doi: 10.1109/TNSE.2018.2848960,"Abstract: Channel state information (CSI) estimation is one of the most fundamental problems in wireless communication systems. Various methods, so far, have been developed to conduct CSI estimation. However, they usually require high computational complexity, which makes them unsuitable for 5G wireless communications due to employing many new techniques (e.g., massive MIMO, OFDM, and millimeter-Wave (mmWave)). In this paper, we propose an efficient online CSI prediction scheme, called OCEAN, for predicting CSI from historical data in 5G wireless communication systems. Specifically, we first identify several important features affecting the CSI of a radio link and a data sample consists of the information of the features and the CSI. We then design a learning framework that is an integration of a CNN (convolutional neural network) and a long short term with memory (LSTM) network. We also further develop an offline-online two-step training mechanism, enabling the prediction results to be more stable when applying it to practical 5G wireless communication systems. To validate OCEAN's efficacy, we consider four typical case studies, and conduct extensive experiments in the four scenarios, i.e., two outdoor and two indoor scenarios. The experiment results show that OCEAN not only obtains the predicted CSI values very quickly but also achieves highly accurate CSI prediction with up to 2.650-3.457 percent average difference ratio (ADR) between the predicted and measured CSI.","keywords: {5G mobile communication;channel estimation;computational complexity;convolutional neural nets;learning (artificial intelligence);radio links;telecommunication computing;wireless channels;average difference ratio;convolutional neural network;CNN;long short term with memory network;efficient online CSI prediction scheme;CSI estimation;channel state information estimation;deep learning approach;channel state information prediction;highly accurate CSI prediction;wireless communication systems;Wireless communication;5G mobile communication;Estimation;Channel estimation;MIMO communication;Oceans;Fading channels;Channel state estimation;5G wireless communications;deep learning},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8395053&isnumber=9025091,5,LSTM,,CNN,,,,Network,,
"A. Waheed, M. Goyal, D. Gupta, A. Khanna, F. Al-Turjman and P. R. Pinheiro, ""CovidGAN: Data Augmentation Using Auxiliary Classifier GAN for Improved Covid-19 Detection,"" in IEEE Access, vol. 8, pp. 91916-91923, 2020.",doi: 10.1109/ACCESS.2020.2994762,"Abstract: Coronavirus (COVID-19) is a viral disease caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). The spread of COVID-19 seems to have a detrimental effect on the global economy and health. A positive chest X-ray of infected patients is a crucial step in the battle against COVID-19. Early results suggest that abnormalities exist in chest X-rays of patients suggestive of COVID-19. This has led to the introduction of a variety of deep learning systems and studies have shown that the accuracy of COVID-19 patient detection through the use of chest X-rays is strongly optimistic. Deep learning networks like convolutional neural networks (CNNs) need a substantial amount of training data. Because the outbreak is recent, it is difficult to gather a significant number of radiographic images in such a short time. Therefore, in this research, we present a method to generate synthetic chest X-ray (CXR) images by developing an Auxiliary Classifier Generative Adversarial Network (ACGAN) based model called CovidGAN. In addition, we demonstrate that the synthetic images produced from CovidGAN can be utilized to enhance the performance of CNN for COVID-19 detection. Classification using CNN alone yielded 85% accuracy. By adding synthetic images produced by CovidGAN,the accuracy increased to 95%. We hope this method will speed up COVID-19 detection and lead to more robust systems of radiology.","keywords: {diagnostic radiography;diseases;image classification;learning (artificial intelligence);medical image processing;microorganisms;molecular biophysics;neural nets;CovidGAN;synthetic images;auxiliary classifier GAN;improved Covid-19 detection;severe acute respiratory syndrome coronavirus 2;SARS-CoV-2;positive chest X-ray;deep learning systems;COVID-19 patient detection;deep learning networks;synthetic chest X-ray images;auxiliary classifier generative adversarial network based model;Generative adversarial networks;Training;Biomedical imaging;X-ray imaging;Computer architecture;Machine learning;COVID-19;Deep learning;convolutional neural networks;generative adversarial networks;synthetic data augmentation;COVID-19 detection},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9093842&isnumber=8948470,6,GAN,from .85 to .95,ACGAN,,Generating Covid-19 X-rays for better CNN models,,,,
"Y. Oh, S. Park and J. C. Ye, ""Deep Learning COVID-19 Features on CXR Using Limited Training Data Sets,"" in IEEE Transactions on Medical Imaging, vol. 39, no. 8, pp. 2688-2700, Aug. 2020.",doi: 10.1109/TMI.2020.2993291,"Abstract: Under the global pandemic of COVID-19, the use of artificial intelligence to analyze chest X-ray (CXR) image for COVID-19 diagnosis and patient triage is becoming important. Unfortunately, due to the emergent nature of the COVID-19 pandemic, a systematic collection of CXR data set for deep neural network training is difficult. To address this problem, here we propose a patch-based convolutional neural network approach with a relatively small number of trainable parameters for COVID-19 diagnosis. The proposed method is inspired by our statistical analysis of the potential imaging biomarkers of the CXR radiographs. Experimental results show that our method achieves state-of-the-art performance and provides clinically interpretable saliency maps, which are useful for COVID-19 diagnosis and patient triage.","keywords: {convolutional neural nets;diagnostic radiography;diseases;learning (artificial intelligence);medical image processing;patient diagnosis;statistical analysis;limited training data;chest X-ray image;COVID-19 diagnosis;patient triage;COVID-19 pandemic;deep neural network training;patch-based convolutional neural network approach;CXR radiographs;deep learning COVID-19 features;trainable parameters;imaging biomarkers;Lung;Diseases;Image segmentation;Training;Neural networks;Sensitivity;Computed tomography;COVID-19;COVID-19;chest X-ray;deep learning;segmentation;classification;saliency map;Algorithms;Betacoronavirus;Coronavirus Infections;Deep Learning;Humans;Image Interpretation, Computer-Assisted;Lung;Pandemics;Pneumonia, Viral;Radiography, Thoracic},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9090149&isnumber=9153182,7,CNN,,ResNet,,Classifying COVID through X-Rays,"JSTR, NLM, CXR",,,
"S. Khan Tayyaba et al., ""5G Vehicular Network Resource Management for Improving Radio Access Through Machine Learning,"" in IEEE Access, vol. 8, pp. 6792-6800, 2020.",doi: 10.1109/ACCESS.2020.2964697,"Abstract: The current cellular technology and vehicular networks cannot satisfy the mighty strides of vehicular network demands. Resource management has become a complex and challenging objective to gain expected outcomes in a vehicular environment. The 5G cellular network promises to provide ultra-high-speed, reduced delay, and reliable communications. The development of new technologies such as the network function virtualization (NFV) and software defined networking (SDN) are critical enabling technologies leveraging 5G. The SDN-based 5G network can provide an excellent platform for autonomous vehicles because SDN offers open programmability and flexibility for new services incorporation. This separation of control and data planes enables centralized and efficient management of resources in a very optimized and secure manner by having a global overview of the whole network. The SDN also provides flexibility in communication administration and resource management, which are of critical importance when considering the ad-hoc nature of vehicular network infrastructures, in terms of safety, privacy, and security, in vehicular network environments. In addition, it promises the overall improved performance. In this paper, we propose a flow-based policy framework on the basis of two tiers virtualization for vehicular networks using SDNs. The vehicle to vehicle (V2V) communication is quite possible with wireless virtualization where different radio resources are allocated to V2V communications based on the flow classification, i.e., safety-related flow or non-safety flows, and the controller is responsible for managing the overall vehicular environment and V2X communications. The motivation behind this study is to implement a machine learning-enabled architecture to cater the sophisticated demands of modern vehicular Internet infrastructures. The inclination towards robust communications in 5G-enabled networks has made it somewhat tricky to manage network slicing efficiently. This paper also presents a proof of concept for leveraging machine learning-enabled resource classification and management through experimental evaluation of special-purpose testbed established in custom mininet setup. Furthermore, the results have been evaluated using Long Short-Term Memory (LSTM), Convolutional Neural Network (CNN), and Deep Neural Network (DNN). While concluding the paper, it is shown that the LSTM has outperformed the rest of classification techniques with promising results.","keywords: {5G mobile communication;computer network management;computer network reliability;convolutional neural nets;Internet;learning (artificial intelligence);mobility management (mobile radio);radio access networks;resource allocation;software defined networking;vehicular ad hoc networks;virtualisation;software defined networking;vehicular network environments;resource classification;convolutional neural network;deep neural network;5G vehicular network resource management;SDN-based 5G cellular network;vehicular Internet infrastructures;machine learning;radio access network;NFV;network function virtualization;flow-based policy framework;vehicle to vehicle communication;V2V communication;wireless virtualization;LSTM;long short-term memory;CNN;DNN;Resource management;5G mobile communication;Computer architecture;Wireless communication;Machine learning;Ad hoc networks;Communication system security;Future internet architectures;machine learning;network reliability;privacy;resource management;security;software defined networks;vehicular networks},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8951149&isnumber=8948470,8,LSTM,0.9936,LSTM,,,,Network,,
"W. Shi, F. Jiang, S. Liu and D. Zhao, ""Image Compressed Sensing Using Convolutional Neural Network,"" in IEEE Transactions on Image Processing, vol. 29, pp. 375-388, 2020.",doi: 10.1109/TIP.2019.2928136,"Abstract: In the study of compressed sensing (CS), the two main challenges are the design of sampling matrix and the development of reconstruction method. On the one hand, the usually used random sampling matrices (e.g., GRM) are signal independent, which ignore the characteristics of the signal. On the other hand, the state-of-the-art image CS methods (e.g., GSR and MH) achieve quite good performance, however with much higher computational complexity. To deal with the two challenges, we propose an image CS framework using convolutional neural network (dubbed CSNet) that includes a sampling network and a reconstruction network, which are optimized jointly. The sampling network adaptively learns the sampling matrix from the training images, which makes the CS measurements retain more image structural information for better reconstruction. Specifically, three types of sampling matrices are learned, i.e., floating-point matrix, {0, 1}-binary matrix, and {-1, +1}-bipolar matrix. The last two matrices are specially designed for easy storage and hardware implementation. The reconstruction network, which contains a linear initial reconstruction network and a non-linear deep reconstruction network, learns an end-to-end mapping between the CS measurements and the reconstructed images. Experimental results demonstrate that CSNet offers state-of-the-art reconstruction quality, while achieving fast running speed. In addition, CSNet with {0, 1}-binary matrix, and {-1, +1}-bipolar matrix gets comparable performance with the existing deep learning-based CS methods, outperforms the traditional CS methods. Experimental results further suggest that the learned sampling matrices can improve the traditional image CS reconstruction methods significantly.","keywords: {compressed sensing;convolutional neural nets;image reconstruction;image sampling;learning (artificial intelligence);matrix algebra;optimisation;image compressed sensing;convolutional neural network;sampling matrix design;reconstruction method development;sampling network;joint optimisation;network adaptive learning;image structural information;sampling matrices;floating-point matrix;binary matrix;bipolar matrix;nonlinear deep reconstruction network;end-to-end mapping;Image reconstruction;Reconstruction algorithms;Matching pursuit algorithms;Deep learning;Computational complexity;Hardware;Compressed sensing;Compressed sensing;deep learning;convolutional neural network;sampling matrix;image reconstruction},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8765626&isnumber=8835130,9,CNN,,CNN,,,,X,,
"R. Wang, B. Li, S. Hu, W. Du and M. Zhang, ""Knowledge Graph Embedding via Graph Attenuated Attention Networks,"" in IEEE Access, vol. 8, pp. 5212-5224, 2020.",doi: 10.1109/ACCESS.2019.2963367,"Abstract: Knowledge graphs contain a wealth of real-world knowledge that can provide strong support for artificial intelligence applications. Much progress has been made in knowledge graph completion, state-of-the-art models are based on graph convolutional neural networks. These models automatically extract features, in combination with the features of the graph model, to generate feature embeddings with a strong expressive ability. However, these methods assign the same weights on the relation path in the knowledge graph and ignore the rich information presented in neighbor nodes, which result in incomplete mining of triple features. To this end, we propose Graph Attenuated Attention networks(GAATs), a novel representation method, which integrates an attenuated attention mechanism to assign different weight in different relation path and acquire the information from the neighborhoods. As a result, entities and relations can be learned in any neighbors. Our empirical research provides insight into the effectiveness of the attenuated attention-based models, and we show significant improvement compared to the state-of-the-art methods on two benchmark datasets WN18RR and FB15k-237.","keywords: {convolutional neural nets;feature extraction;graph theory;learning (artificial intelligence);artificial intelligence applications;knowledge graph completion;graph convolutional neural networks;feature embeddings;attention mechanism;relation path;attention-based models;knowledge graph embedding;graph attenuated attention networks;Neural networks;Knowledge engineering;Tensors;Feature extraction;Convolution;Adaptation models;Semantics;Knowledge graph embedding;attenuated attention mechanism;neighbor nodes;translational model;graph attention networks},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8946600&isnumber=8948470,10,CapsE,,GAAT,,Knowledge graph relations,"WN18RR, FB15k-237",?,,
"T. Song, W. Zheng, P. Song and Z. Cui, ""EEG Emotion Recognition Using Dynamical Graph Convolutional Neural Networks,"" in IEEE Transactions on Affective Computing, vol. 11, no. 3, pp. 532-541, 1 July-Sept. 2020.",doi: 10.1109/TAFFC.2018.2817622,"Abstract: In this paper, a multichannel EEG emotion recognition method based on a novel dynamical graph convolutional neural networks (DGCNN) is proposed. The basic idea of the proposed EEG emotion recognition method is to use a graph to model the multichannel EEG features and then perform EEG emotion classification based on this model. Different from the traditional graph convolutional neural networks (GCNN) methods, the proposed DGCNN method can dynamically learn the intrinsic relationship between different electroencephalogram (EEG) channels, represented by an adjacency matrix, via training a neural network so as to benefit for more discriminative EEG feature extraction. Then, the learned adjacency matrix is used to learn more discriminative features for improving the EEG emotion recognition. We conduct extensive experiments on the SJTU emotion EEG dataset (SEED) and DREAMER dataset. The experimental results demonstrate that the proposed method achieves better recognition performance than the state-of-the-art methods, in which the average recognition accuracy of 90.4 percent is achieved for subject dependent experiment while 79.95 percent for subject independent cross-validation one on the SEED database, and the average accuracies of 86.23, 84.54 and 85.02 percent are respectively obtained for valence, arousal and dominance classifications on the DREAMER database.","keywords: {convolutional neural nets;electroencephalography;emotion recognition;feature extraction;graph theory;learning (artificial intelligence);medical signal processing;signal classification;electroencephalogram channels;neural network;learned adjacency matrix;discriminative features;recognition performance;multichannel EEG emotion recognition method;dynamical graph convolutional neural networks;multichannel EEG features;EEG emotion classification;DGCNN method;SJTU emotion EEG dataset;DREAMER dataset;average recognition accuracy;dominance classification;valence classification;arousal classification;SEED database;Electroencephalography;Emotion recognition;Brain modeling;Feature extraction;Convolutional neural networks;Convolution;Biological neural networks;EEG emotion recognition;adjacency matrix;graph convolutional neural networks (GCNN);dynamical convolutional neural networks (DGCNN)},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8320798&isnumber=9167328,11,GCNN,0.904,DGCNN,,EEG emotion recognition improvement,"SEED, Dreamer EEG",,1,
"Y. Jing, Y. Yang, Z. Feng, J. Ye, Y. Yu and M. Song, ""Neural Style Transfer: A Review,"" in IEEE Transactions on Visualization and Computer Graphics, vol. 26, no. 11, pp. 3365-3385, 1 Nov. 2020.",doi: 10.1109/TVCG.2019.2921336,"Abstract: The seminal work of Gatys et al. demonstrated the power of Convolutional Neural Networks (CNNs) in creating artistic imagery by separating and recombining image content and style. This process of using CNNs to render a content image in different styles is referred to as Neural Style Transfer (NST). Since then, NST has become a trending topic both in academic literature and industrial applications. It is receiving increasing attention and a variety of approaches are proposed to either improve or extend the original NST algorithm. In this paper, we aim to provide a comprehensive overview of the current progress towards NST. We first propose a taxonomy of current algorithms in the field of NST. Then, we present several evaluation methods and compare different NST algorithms both qualitatively and quantitatively. The review concludes with a discussion of various applications of NST and open problems for future research. A list of papers discussed in this review, corresponding codes, pre-trained models and more comparison results are publicly available at: https://osf.io/f8tu4/.","keywords: {convolutional neural nets;image processing;neural style transfer;convolutional neural networks;CNN;artistic imagery;image content;NST algorithm;Rendering (computer graphics);Painting;Taxonomy;Visualization;Convolutional neural networks;Art;Shape;Neural style transfer (NST);convolutional neural network (CNN)},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8732370&isnumber=9210268,12,CNN,,CNN/GAN,,NST,,Review,,
"T. Li, M. Hua and X. Wu, ""A Hybrid CNN-LSTM Model for Forecasting Particulate Matter (PM2.5),"" in IEEE Access, vol. 8, pp. 26933-26940, 2020.",doi: 10.1109/ACCESS.2020.2971348,"Abstract: PM2.5 is one of the most important pollutants related to air quality, and the increase of its concentration will aggravate the threat to people's health. Therefore, the prediction of surface PM2.5 concentration is of great significance to human health protection. In this study, A hybrid CNN-LSTM model is developed by combining the convolutional neural network (CNN) with the long short-term memory (LSTM) neural network for forecasting the next 24h PM2.5 concentration in Beijing, which makes full use of their advantages that CNN can effectively extract the features related to air quality and the LSTM can reflect the long term historical process of input time series data. The air quality data of the last 7days and the PM2.5 concentration of the next day are first set as the input and output of the model due to the periodicity, respectively. Subsequently four models namely univariate LSTM model, multivariate LSTM model, univariate CNN-LSTM model and multivariate CNN-LSTM model, are established for PM2.5 concentration prediction. Finally, mean absolute error (MAE) and root mean square error (RMSE) are employed to evaluate the performance of these models and results show that the proposed multivariate CNN-LSTM model performs the best results due to low error and short training time.","keywords: {air pollution;air quality;convolutional neural nets;environmental science computing;feature extraction;health hazards;recurrent neural nets;time series;PM2.5 concentration prediction;multivariate CNN-LSTM model;hybrid CNN-LSTM model;particulate matter forecasting;human health protection;convolutional neural network;long short-term memory neural network;input time series data;air quality data;multivariate LSTM model;univariate CNN-LSTM model;Predictive models;Atmospheric modeling;Time series analysis;Forecasting;Data models;Deep learning;Feature extraction;Deep learning;CNN;LSTM;PM2.5 concentration prediction},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8979420&isnumber=8948470,13,LSTM,23.4 RMSE,CNN/LSTM hybrid,,Forecasting,(https://archive.ics.uci.edu/ml/datasets.php),,,
"S. Zhou, D. Nie, E. Adeli, J. Yin, J. Lian and D. Shen, ""High-Resolution Encoder–Decoder Networks for Low-Contrast Medical Image Segmentation,"" in IEEE Transactions on Image Processing, vol. 29, pp. 461-475, 2020.",doi: 10.1109/TIP.2019.2919937,"Abstract: Automatic image segmentation is an essential step for many medical image analysis applications, include computer-aided radiation therapy, disease diagnosis, and treatment effect evaluation. One of the major challenges for this task is the blurry nature of medical images (e.g., CT, MR, and microscopic images), which can often result in low-contrast and vanishing boundaries. With the recent advances in convolutional neural networks, vast improvements have been made for image segmentation, mainly based on the skip-connection-linked encoder-decoder deep architectures. However, in many applications (with adjacent targets in blurry images), these models often fail to accurately locate complex boundaries and properly segment tiny isolated parts. In this paper, we aim to provide a method for blurry medical image segmentation and argue that skip connections are not enough to help accurately locate indistinct boundaries. Accordingly, we propose a novel high-resolution multi-scale encoder-decoder network (HMEDN), in which multi-scale dense connections are introduced for the encoder-decoder structure to finely exploit comprehensive semantic information. Besides skip connections, extra deeply supervised high-resolution pathways (comprised of densely connected dilated convolutions) are integrated to collect high-resolution semantic information for accurate boundary localization. These pathways are paired with a difficulty-guided cross-entropy loss function and a contour regression task to enhance the quality of boundary detection. The extensive experiments on a pelvic CT image dataset, a multi-modal brain tumor dataset, and a cell segmentation dataset show the effectiveness of our method for 2D/3D semantic segmentation and 2D instance segmentation, respectively. Our experimental results also show that besides increasing the network complexity, raising the resolution of semantic feature maps can largely affect the overall model performance. For different tasks, finding a balance between these two factors can further improve the performance of the corresponding network.","keywords: {brain;computerised tomography;convolutional neural nets;diseases;entropy;feature extraction;image coding;image resolution;image segmentation;medical image processing;regression analysis;tumours;encoder-decoder structure;boundary localization;high-resolution multiscale encoder-decoder network;skip-connection-linked encoder-decoder deep architectures;disease diagnosis;difficulty-guided cross-entropy loss function;contour regression task;2D-3D semantic segmentation;semantic feature maps;computed tomography;pelvic CT image dataset;boundary detection;high-resolution semantic information;densely connected dilated convolutions;high-resolution pathways;multiscale dense connections;blurry medical image segmentation;complex boundaries;blurry images;convolutional neural networks;microscopic images;blurry nature;treatment effect evaluation;computer-aided radiation therapy;medical image analysis applications;automatic image segmentation;low-contrast medical image segmentation;network complexity;2D instance segmentation;cell segmentation dataset;multimodal brain tumor dataset;Image segmentation;Semantics;Task analysis;Computed tomography;Shape;Medical diagnostic imaging;Image segmentation;low-contrast image;high-resolution pathway},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8741187&isnumber=8835130,14,CNN 3D,,HMDEN,,Particulate Matter,PELVIC CT,,,
"J. Hu, L. Shen, S. Albanie, G. Sun and E. Wu, ""Squeeze-and-Excitation Networks,"" in IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 42, no. 8, pp. 2011-2023, 1 Aug. 2020.",doi: 10.1109/TPAMI.2019.2913372,"Abstract: The central building block of convolutional neural networks (CNNs) is the convolution operator, which enables networks to construct informative features by fusing both spatial and channel-wise information within local receptive fields at each layer. A broad range of prior research has investigated the spatial component of this relationship, seeking to strengthen the representational power of a CNN by enhancing the quality of spatial encodings throughout its feature hierarchy. In this work, we focus instead on the channel relationship and propose a novel architectural unit, which we term the “Squeeze-and-Excitation” (SE) block, that adaptively recalibrates channel-wise feature responses by explicitly modelling interdependencies between channels. We show that these blocks can be stacked together to form SENet architectures that generalise extremely effectively across different datasets. We further demonstrate that SE blocks bring significant improvements in performance for existing state-of-the-art CNNs at slight additional computational cost. Squeeze-and-Excitation Networks formed the foundation of our ILSVRC 2017 classification submission which won first place and reduced the top-5 error to 2.251 percent, surpassing the winning entry of 2016 by a relative improvement of -25 percent. Models and code are available at https://github.com/hujie-frank/SENet.","keywords: {convolutional neural nets;image representation;spatial encodings;feature hierarchy;squeeze-and-excitation block;channel-wise feature responses;SENet architectures;CNNs;convolutional neural networks;channel-wise information;local receptive fields;spatial component;ILSVRC 2017 classification submission;Computer architecture;Computational modeling;Convolution;Task analysis;Correlation;Optimization;Convolutional neural networks;Squeeze-and-excitation;image representations;attention;convolutional neural networks},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8701503&isnumber=9130977,15,CNN,0.2238,SENet,hujie-frank/SENet: Squeeze-and-Excitation Networks (github.com),,ImageNet,,,
"Y. Sun, B. Xue, M. Zhang and G. G. Yen, ""Evolving Deep Convolutional Neural Networks for Image Classification,"" in IEEE Transactions on Evolutionary Computation, vol. 24, no. 2, pp. 394-407, April 2020.",doi: 10.1109/TEVC.2019.2916183,"Abstract: Evolutionary paradigms have been successfully applied to neural network designs for two decades. Unfortunately, these methods cannot scale well to the modern deep neural networks due to the complicated architectures and large quantities of connection weights. In this paper, we propose a new method using genetic algorithms for evolving the architectures and connection weight initialization values of a deep convolutional neural network to address image classification problems. In the proposed algorithm, an efficient variable-length gene encoding strategy is designed to represent the different building blocks and the potentially optimal depth in convolutional neural networks. In addition, a new representation scheme is developed for effectively initializing connection weights of deep convolutional neural networks, which is expected to avoid networks getting stuck into local minimum that is typically a major issue in the backward gradient-based optimization. Furthermore, a novel fitness evaluation method is proposed to speed up the heuristic search with substantially less computational resource. The proposed algorithm is examined and compared with 22 existing algorithms on nine widely used image classification tasks, including the state-of-the-art methods. The experimental results demonstrate the remarkable superiority of the proposed algorithm over the state-of-the-art designs in terms of classification error rate and the number of parameters (weights).","keywords: {convolutional neural nets;genetic algorithms;gradient methods;image classification;backward gradient-based optimization;genetic algorithms;evolutionary paradigms;variable-length gene encoding strategy;image classification problems;connection weights;deep convolutional neural networks;Computer architecture;Architecture;Optimization;Genetic algorithms;Encoding;Task analysis;Convolutional neural networks;Convolutional neural network (CNN);deep learning;genetic algorithms (GAs);image classification},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8712430&isnumber=9051613,16,CNN,.95:.99,EvoCNN,https://github.com/sunkevin1214/codes,,FASHION BENCHMARK DATASET,,,
"J. Zhang, Y. Zheng, J. Sun and D. Qi, ""Flow Prediction in Spatio-Temporal Networks Based on Multitask Deep Learning,"" in IEEE Transactions on Knowledge and Data Engineering, vol. 32, no. 3, pp. 468-478, 1 March 2020.",doi: 10.1109/TKDE.2019.2891537,"Abstract: Predicting flows (e.g., the traffic of vehicles, crowds, and bikes), consisting of the in-out traffic at a node and transitions between different nodes, in a spatio-temporal network plays an important role in transportation systems. However, this is a very challenging problem, affected by multiple complex factors, such as the spatial correlation between different locations, temporal correlation among different time intervals, and external factors (like events and weather). In addition, the flow at a node (called node flow) and transitions between nodes (edge flow) mutually influence each other. To address these issues, we propose a multitask deep-learning framework that simultaneously predicts the node flow and edge flow throughout a spatio-temporal network. Based on fully convolutional networks, our approach designs two sophisticated models for predicting node flow and edge flow, respectively. These two models are connected by coupling their latent representations of middle layers, and trained together. The external factor is also integrated into the framework through a gating fusion mechanism. In the edge flow prediction model, we employ an embedding component to deal with the sparse transitions between nodes. We evaluate our method based on the taxicab data in Beijing and New York City. Experimental results show the advantages of our method beyond 11 baselines, such as ConvLSTM, CNN, and Markov Random Field.","keywords: {convolutional neural nets;learning (artificial intelligence);Markov processes;spatiotemporal phenomena;traffic information systems;spatio-temporal network;multitask deep learning;multiple complex factors;temporal correlation;node flow;multitask deep-learning framework;fully convolutional networks;predicting node flow;external factor;edge flow prediction model;ConvLSTM;CNN;Markov random field;taxicab data;Beijing;New York City;Correlation;Predictive models;Urban areas;Matrix converters;Sparse matrices;Deep learning;Deep learning;spatio-temporal data;urban computing},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8606218&isnumber=8985136,17,LSTM,,"CNN, LSTM",,MDL,NYC/Beijing weather data,,,
"H. Ye, L. Liang, G. Y. Li and B. Juang, ""Deep Learning-Based End-to-End Wireless Communication Systems With Conditional GANs as Unknown Channels,"" in IEEE Transactions on Wireless Communications, vol. 19, no. 5, pp. 3133-3143, May 2020.",doi: 10.1109/TWC.2020.2970707,"Abstract: In this article, we develop an end-to-end wireless communication system using deep neural networks (DNNs), where DNNs are employed to perform several key functions, including encoding, decoding, modulation, and demodulation. However, an accurate estimation of instantaneous channel transfer function, i.e., channel state information (CSI), is needed in order for the transmitter DNN to learn to optimize the receiver gain in decoding. This is very much a challenge since CSI varies with time and location in wireless communications and is hard to obtain when designing transceivers. We propose to use a conditional generative adversarial net (GAN) to represent channel effects and to bridge the transmitter DNN and the receiver DNN so that the gradient of the transmitter DNN can be back-propagated from the receiver DNN. In particular, a conditional GAN is employed to model the channel effects in a data-driven way, where the received signal corresponding to the pilot symbols is added as a part of the conditioning information of the GAN. To address the curse of dimensionality when the transmit symbol sequence is long, convolutional layers are utilized. From the simulation results, the proposed method is effective on additive white Gaussian noise (AWGN) channels, Rayleigh fading channels, and frequency-selective channels, which opens a new door for building data-driven DNNs for end-to-end communication systems.","keywords: {AWGN channels;channel estimation;error statistics;learning (artificial intelligence);neural nets;radio transceivers;Rayleigh channels;telecommunication computing;transfer functions;convolutional layers;AWGN channels;end-to-end wireless communication systems;conditional generative adversarial net;decoding;receiver gain;CSI;channel state information;instantaneous channel transfer function;key functions;deep neural networks;unknown channels;deep learning;data-driven DNNs;frequency-selective channels;Rayleigh fading channels;additive white Gaussian noise channels;conditioning information;received signal;channel effects;conditional GAN;receiver DNN;transmitter DNN;Gallium nitride;Transmitters;Receivers;Wireless communication;Training;Maximum likelihood decoding;Channel GAN;CNN;end-to-end communication system;channel coding},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8985539&isnumber=9090043,18,GAN,,GAN,,Wireless communication,,,,
"C. You et al., ""CT Super-Resolution GAN Constrained by the Identical, Residual, and Cycle Learning Ensemble (GAN-CIRCLE),"" in IEEE Transactions on Medical Imaging, vol. 39, no. 1, pp. 188-203, Jan. 2020.",doi: 10.1109/TMI.2019.2922960,"Abstract: In this paper, we present a semi-supervised deep learning approach to accurately recover high-resolution (HR) CT images from low-resolution (LR) counterparts. Specifically, with the generative adversarial network (GAN) as the building block, we enforce the cycle-consistency in terms of the Wasserstein distance to establish a nonlinear end-to-end mapping from noisy LR input images to denoised and deblurred HR outputs. We also include the joint constraints in the loss function to facilitate structural preservation. In this process, we incorporate deep convolutional neural network (CNN), residual learning, and network in network techniques for feature extraction and restoration. In contrast to the current trend of increasing network depth and complexity to boost the imaging performance, we apply a parallel 1 × 1 CNN to compress the output of the hidden layer and optimize the number of layers and the number of filters for each convolutional layer. The quantitative and qualitative evaluative results demonstrate that our proposed model is accurate, efficient and robust for super-resolution (SR) image restoration from noisy LR input images. In particular, we validate our composite SR networks on three large-scale CT datasets, and obtain promising results as compared to the other state-of-the-art methods.","keywords: {computerised tomography;convolutional neural nets;feature extraction;image denoising;image resolution;image restoration;medical image processing;supervised learning;high-resolution CT images;low-resolution counterparts;generative adversarial network;Wasserstein distance;nonlinear end-to-end mapping;noisy LR input images;denoised HR outputs;deblurred HR outputs;loss function;structural preservation;residual learning;feature extraction;CNN;convolutional layer;super-resolution image restoration;composite SR networks;large-scale CT datasets;CT super-resolution GAN;GAN-CIRCLE;semisupervised deep learning approach;cycle learning ensemble;deep convolutional neural network;Computed tomography;Gallium nitride;Image resolution;Generative adversarial networks;Image reconstruction;Training;Computed tomography (CT);super-resolution;noise reduction;deep learning;adversarial learning;residual learning;Abdomen;Aged;Aged, 80 and over;Deep Learning;Female;Humans;Image Processing, Computer-Assisted;Male;Neural Networks, Computer;Tibia;Tomography, X-Ray Computed},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8736838&isnumber=8946770,19,GAN,,GAN/CNN,,CT improvement,,,,
"Y. He, K. Song, Q. Meng and Y. Yan, ""An End-to-End Steel Surface Defect Detection Approach via Fusing Multiple Hierarchical Features,"" in IEEE Transactions on Instrumentation and Measurement, vol. 69, no. 4, pp. 1493-1504, April 2020.",doi: 10.1109/TIM.2019.2915404,"Abstract: A complete defect detection task aims to achieve the specific class and precise location of each defect in an image, which makes it still challenging for applying this task in practice. The defect detection is a composite task of classification and location, leading to related methods is often hard to take into account the accuracy of both. The implementation of defect detection depends on a special detection data set that contains expensive manual annotations. In this paper, we proposed a novel defect detection system based on deep learning and focused on a practical industrial application: steel plate defect inspection. In order to achieve strong classification ability, this system employs a baseline convolution neural network (CNN) to generate feature maps at each stage, and then the proposed multilevel feature fusion network (MFN) combines multiple hierarchical features into one feature, which can include more location details of defects. Based on these multilevel features, a region proposal network (RPN) is adopted to generate regions of interest (ROIs). For each ROI, a detector, consisting of a classifier and a bounding box regressor, produces the final detection results. Finally, we set up a defect detection data set NEU-DET for training and evaluating our method. On the NEU-DET, our method achieves 74.8/82.3 mAP with baseline networks ResNet34/50 by using 300 proposals. In addition, by using only 50 proposals, our method can detect at 20 ft/s on a single GPU and reach 92% of the above performance, hence the potential for real-time detection.","keywords: {convolutional neural nets;feature extraction;image classification;inspection;learning (artificial intelligence);mechanical engineering computing;object detection;plates (structures);steel;multiple hierarchical feature fusion;real-time detection;defect detection data;final detection results;region proposal network;multilevel features;multilevel feature fusion network;feature maps;baseline convolution neural network;strong classification ability;steel plate defect inspection;practical industrial application;novel defect detection system;special detection data;composite task;precise location;complete defect detection task;end-to-end steel surface defect detection approach;velocity 20.0 ft/s;Feature extraction;Task analysis;Inspection;Detectors;Steel;Proposals;Training;Automated defect inspection (ADI);defect detection dataset (NEU-DET);defect detection network (DDN);multilevel-feature fusion network (MFN)},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8709818&isnumber=9031571,20,CNN,0.9967,"CNN, MFN, ROI",,Steel Surface Defect Detection,,,,
"J. Zhang and D. Tao, ""FAMED-Net: A Fast and Accurate Multi-Scale End-to-End Dehazing Network,"" in IEEE Transactions on Image Processing, vol. 29, pp. 72-84, 2020.",doi: 10.1109/TIP.2019.2922837,"Abstract: Single image dehazing is a critical image pre-processing step for subsequent high-level computer vision tasks. However, it remains challenging due to its ill-posed nature. Existing dehazing models tend to suffer from model overcomplexity and computational inefficiency or have limited representation capacity. To tackle these challenges, here, we propose a fast and accurate multi-scale end-to-end dehazing network, called FAMED-Net, which comprises encoders at three scales and a fusion module to efficiently and directly learn the haze-free image. Each encoder consists of cascaded and densely connected point-wise convolutional layers and pooling layers. Since no larger convolutional kernels are used and features are reused layer-by-layer, FAMED-Net is lightweight and computationally efficient. Thorough empirical studies on public synthetic datasets (including RESIDE) and real-world hazy images demonstrate the superiority of FAMED-Net over other representative state-of-the-art models with respect to model complexity, computational efficiency, restoration accuracy, and cross-set generalization. The code will be made publicly available.","keywords: {computer vision;convolutional neural nets;image coding;image restoration;single image dehazing;dehazing models;encoder;haze-free image;image pre-processing step;high-level computer vision tasks;densely connected point-wise convolutional layers;cascaded connected point-wise convolutional layers;FAMED-Net;multiscale end-to-end dehazing network;pooling layers;Atmospheric modeling;Computational modeling;Scattering;Computer architecture;Convolutional codes;Channel estimation;Computer vision;Dehazing;image restoration;point-wise convolution;deep neural network},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8753731&isnumber=8835130,21,CNN,,Famed-net,,dehazing,,,1,
"D. Cozzolino and L. Verdoliva, ""Noiseprint: A CNN-Based Camera Model Fingerprint,"" in IEEE Transactions on Information Forensics and Security, vol. 15, pp. 144-159, 2020.",doi: 10.1109/TIFS.2019.2916364,"Abstract: Forensic analyses of digital images rely heavily on the traces of in-camera and out-camera processes left on the acquired images. Such traces represent a sort of camera fingerprint. If one is able to recover them, by suppressing the high-level scene content and other disturbances, a number of forensic tasks can be easily accomplished. A notable example is the PRNU pattern, which can be regarded as a device fingerprint, and has received great attention in multimedia forensics. In this paper, we propose a method to extract a camera model fingerprint, called noiseprint, where the scene content is largely suppressed and model-related artifacts are enhanced. This is obtained by means of a Siamese network, which is trained with pairs of image patches coming from the same (label +1) or different (label -1) cameras. Although the noiseprints can be used for a large variety of forensic tasks, in this paper we focus on image forgery localization. Experiments on several datasets widespread in the forensic community show noiseprint-based methods to provide state-of-the-art performance.","keywords: {cameras;convolutional neural nets;feature extraction;fingerprint identification;image forensics;CNN-based camera model fingerprint;forensic analyses;digital images;camera fingerprint;high-level scene content;forensic tasks;PRNU pattern;device fingerprint;multimedia forensics;model-related artifacts;image patches;image forgery localization;forensic community;noiseprint;Cameras;Training;Feature extraction;Forgery;Task analysis;Image forensics;Digital image forensics;noise residual;siamese networks;deep learning},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8713484&isnumber=8833568,22,CNN,,siamese CNN,,Model finger-print,,,1,
"Q. Zhang, X. Chang and S. B. Bian, ""Vehicle-Damage-Detection Segmentation Algorithm Based on Improved Mask RCNN,"" in IEEE Access, vol. 8, pp. 6997-7004, 2020.",doi: 10.1109/ACCESS.2020.2964055,"Abstract: Traffic congestion due to vehicular accidents seriously affects normal travel, and accurate and effective mitigating measures and methods must be studied. To resolve traffic accident compensation problems quickly, a vehicle-damage-detection segmentation algorithm based on transfer learning and an improved mask regional convolutional neural network (Mask RCNN) is proposed in this paper. The experiment first collects car damage pictures for preprocessing and uses Labelme to make data set labels, which are divided into training sets and test sets. The residual network (ResNet) is optimized, and feature extraction is performed in combination with Feature Pyramid Network (FPN). Then, the proportion and threshold of the Anchor in the region proposal network (RPN) are adjusted. The spatial information of the feature map is preserved by bilinear interpolation in ROIAlign, and different weights are introduced in the loss function for different-scale targets. Finally, the results of self-made dedicated dataset training and testing show that the improved Mask RCNN has better Average Precision (AP) value, detection accuracy and masking accuracy, and improves the efficiency of solving traffic accident compensation problems.","keywords: {convolutional neural nets;feature extraction;image segmentation;interpolation;learning (artificial intelligence);road accidents;road traffic;traffic engineering computing;traffic accident compensation problems;mask regional convolutional neural network;residual network;Feature Pyramid Network;region proposal network;Mask RCNN;traffic congestion;vehicular accidents;vehicle-damage-detection segmentation;Labelme;feature extraction;bilinear interpolation;ROIAlign;Image segmentation;Feature extraction;Automobiles;Object detection;Accidents;Prediction algorithms;Training;Mask RCNN;vehicle-damage-detection;loss function;detection accuracy},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8950115&isnumber=8948470,23,R-CNN,0.933,Mask R-CNN,,Vehicle-Damage-Detection,,,,3
"L. Jing, Y. Chen and Y. Tian, ""Coarse-to-Fine Semantic Segmentation From Image-Level Labels,"" in IEEE Transactions on Image Processing, vol. 29, pp. 225-236, 2020.",doi: 10.1109/TIP.2019.2926748,"Abstract: Deep neural network-based semantic segmentation generally requires large-scale cost extensive annotations for training to obtain better performance. To avoid pixel-wise segmentation annotations that are needed for most methods, recently some researchers attempted to use object-level labels (e.g., bounding boxes) or image-level labels (e.g., image categories). In this paper, we propose a novel recursive coarse-to-fine semantic segmentation framework based on only image-level category labels. For each image, an initial coarse mask is first generated by a convolutional neural network-based unsupervised foreground segmentation model and then is enhanced by a graph model. The enhanced coarse mask is fed to a fully convolutional neural network to be recursively refined. Unlike the existing image-level label-based semantic segmentation methods, which require labeling of all categories for images that contain multiple types of objects, our framework only needs one label for each image and can handle images that contain multi-category objects. Only trained on ImageNet, our framework achieves comparable performance on the PASCAL VOC dataset with other image-level label-based state-of-the-art methods of semantic segmentation. Furthermore, our framework can be easily extended to foreground object segmentation task and achieves comparable performance with the state-of-the-art supervised methods on the Internet object dataset.","keywords: {convolutional neural nets;graph theory;image classification;image segmentation;learning (artificial intelligence);object detection;image-level labels;neural network-based semantic segmentation;large-scale cost extensive annotations;pixel-wise segmentation annotations;object-level labels;coarse-to-fine semantic segmentation framework;image-level category labels;initial coarse mask;convolutional neural network-based unsupervised foreground segmentation model;fully convolutional neural network;multicategory objects;image-level label-based state-of-the-art methods;foreground object segmentation task;image-level label-based semantic segmentation methods;PASCAL VOC dataset;ImageNet framework;Internet object dataset;Image segmentation;Semantics;Task analysis;Convolutional neural networks;Object segmentation;Urban areas;Training;Weakly supervised learning;semantic segmentation;foreground object segmentation;convolutional neural network;deep learning},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8760555&isnumber=8835130,24,CNN,.62 IOU,DFPN,,semantic segmentation,"ImageNet, VOC, MIT Object Discovery Dataset:",,,
"B. A. Albert, ""Deep Learning From Limited Training Data: Novel Segmentation and Ensemble Algorithms Applied to Automatic Melanoma Diagnosis,"" in IEEE Access, vol. 8, pp. 31254-31269, 2020.",doi: 10.1109/ACCESS.2020.2973188,"Abstract: Deep learning algorithms often require thousands of training instances to generalize well. The presented research demonstrates a novel algorithm, Predict-Evaluate-Correct K-fold (PECK), that trains ensembles to learn well from limited data. The PECK algorithm is used to train a deep ensemble on 153 non-dermoscopic lesion images, significantly outperforming prior publications and state-of-the-art methods trained and evaluated on the same dataset. The PECK algorithm merges deep convolutional neural networks with support vector machine and random forest classifiers to achieve an introspective learning method. Where the ensemble is organized hierarchically, deeper layers are provided not only more training folds, but also the predictions of previous layers. Subsequent classifiers then learn and correct the previous layer errors by training on the original data with injected predictions for new data folds. In addition to the PECK algorithm, a novel segmentation algorithm, Synthesis and Convergence of Intermediate Decaying Omnigradients (SCIDOG), is developed to accurately detect lesion contours in non-dermoscopic images, even in the presence of significant noise, hair, and fuzzy lesion boundaries. As SCIDOG is a non-learning algorithm, it is unhindered by data quantity limitations. The automatic and precise segmentations that SCIDOG produces allows for the extraction of 1,812 lesion features that quantify shape, color and texture. These morphological features are used in conjunction with convolutional neural network predictions for training the PECK ensemble. The combination of SCIDOG and PECK algorithms are used to diagnose melanomas and benign nevi through automatic digital image analysis on the MED-NODE dataset. Evaluated using 10-fold cross validation, the proposed methods achieve significantly increased diagnostic capability over the best prior methods.","keywords: {biomedical optical imaging;cancer;convolutional neural nets;feature extraction;image classification;image colour analysis;image segmentation;image texture;learning (artificial intelligence);medical image processing;skin;support vector machines;deep learning algorithms;Predict-Evaluate-Correct K-fold;PECK algorithm;nondermoscopic lesion images;deep convolutional neural networks;introspective learning method;segmentation algorithm;nonlearning algorithm;convolutional neural network predictions;PECK ensemble;automatic digital image analysis;SCIDOG algorithm;support vector machine;random forest classifiers;fuzzy lesion boundaries;Lesions;Skin;Image segmentation;Melanoma;Training;Deep learning;Feature extraction;Convolutional neural network;feature extraction;medical diagnostic imaging;random forest;support vector machine},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8993822&isnumber=8948470,25,CNN,,PECK,,Training on limited datasets,MED-NODE,,,
"L. Yang, Y. Li, J. Wang and R. S. Sherratt, ""Sentiment Analysis for E-Commerce Product Reviews in Chinese Based on Sentiment Lexicon and Deep Learning,"" in IEEE Access, vol. 8, pp. 23522-23530, 2020.",doi: 10.1109/ACCESS.2020.2969854,"Abstract: In recent years, with the rapid development of Internet technology, online shopping has become a mainstream way for users to purchase and consume. Sentiment analysis of a large number of user reviews on e-commerce platforms can effectively improve user satisfaction. This paper proposes a new sentiment analysis model-SLCABG, which is based on the sentiment lexicon and combines Convolutional Neural Network (CNN) and attention-based Bidirectional Gated Recurrent Unit (BiGRU). In terms of methods, the SLCABG model combines the advantages of sentiment lexicon and deep learning technology, and overcomes the shortcomings of existing sentiment analysis model of product reviews. The SLCABG model combines the advantages of the sentiment lexicon and deep learning techniques. First, the sentiment lexicon is used to enhance the sentiment features in the reviews. Then the CNN and the Gated Recurrent Unit (GRU) network are used to extract the main sentiment features and context features in the reviews and use the attention mechanism to weight. And finally classify the weighted sentiment features. In terms of data, this paper crawls and cleans the real book evaluation of dangdang.com, a famous Chinese e-commerce website, for training and testing, all of which are based on Chinese. The scale of the data has reached 100000 orders of magnitude, which can be widely used in the field of Chinese sentiment analysis. The experimental results show that the model can effectively improve the performance of text sentiment analysis.","keywords: {convolutional neural nets;electronic commerce;feature extraction;Internet;sentiment analysis;Web sites;sentiment lexicon;weighted sentiment features;sentiment feature extraction;Chinese sentiment analysis;text sentiment analysis;e-commerce product reviews;user reviews;SLCABG model;deep learning technology;convolutional neural network;CNN;gated recurrent unit network;GRU network;Chinese e-commerce website;Internet technology;Sentiment analysis;Analytical models;Feature extraction;Deep learning;Support vector machines;Attention mechanism;CNN;BiGRU;sentiment analysis;sentiment lexicon},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8970492&isnumber=8948470,26,GRU,0.935,"biGRU, CNN",,Sentiment Analysis,Dangdang book,,,
"M. Trotzek, S. Koitka and C. M. Friedrich, ""Utilizing Neural Networks and Linguistic Metadata for Early Detection of Depression Indications in Text Sequences,"" in IEEE Transactions on Knowledge and Data Engineering, vol. 32, no. 3, pp. 588-601, 1 March 2020.",doi: 10.1109/TKDE.2018.2885515,"Abstract: Depression is ranked as the largest contributor to global disability and is also a major reason for suicide. Still, many individuals suffering from forms of depression are not treated for various reasons. Previous studies have shown that depression also has an effect on language usage and that many depressed individuals use social media platforms or the internet in general to get information or discuss their problems. This paper addresses the early detection of depression using machine learning models based on messages on a social platform. In particular, a convolutional neural network based on different word embeddings is evaluated and compared to a classification based on user-level linguistic metadata. An ensemble of both approaches is shown to achieve state-of-the-art results in a current early detection task. Furthermore, the currently popular ERDE score as metric for early detection systems is examined in detail and its drawbacks in the context of shared tasks are illustrated. A slightly modified metric is proposed and compared to the original score. Finally, a new word embedding was trained on a large corpus of the same domain as the described task and is evaluated as well.","keywords: {behavioural sciences computing;convolutional neural nets;Internet;learning (artificial intelligence);meta data;social networking (online);depressed individuals;social media platforms;convolutional neural network;user-level linguistic metadata;early detection systems;early detection task;depression indication detection;text sequences;machine learning models;word embeddings;ERDE score;shared tasks;Task analysis;Natural language processing;Social network services;Machine learning;Linguistics;Metadata;Europe;Depression;early detection;linguistic metadata;convolutional neural network;word embeddings},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8580405&isnumber=8985136,27,GRU,73 f1,BERT,,Depression detection,eRisk 2017,,,
"G. Wang et al., ""A Noise-Robust Framework for Automatic Segmentation of COVID-19 Pneumonia Lesions From CT Images,"" in IEEE Transactions on Medical Imaging, vol. 39, no. 8, pp. 2653-2663, Aug. 2020.",doi: 10.1109/TMI.2020.3000314,"Abstract: Segmentation of pneumonia lesions from CT scans of COVID-19 patients is important for accurate diagnosis and follow-up. Deep learning has a potential to automate this task but requires a large set of high-quality annotations that are difficult to collect. Learning from noisy training labels that are easier to obtain has a potential to alleviate this problem. To this end, we propose a novel noise-robust framework to learn from noisy labels for the segmentation task. We first introduce a noise-robust Dice loss that is a generalization of Dice loss for segmentation and Mean Absolute Error (MAE) loss for robustness against noise, then propose a novel COVID-19 Pneumonia Lesion segmentation network (COPLE-Net) to better deal with the lesions with various scales and appearances. The noise-robust Dice loss and COPLE-Net are combined with an adaptive self-ensembling framework for training, where an Exponential Moving Average (EMA) of a student model is used as a teacher model that is adaptively updated by suppressing the contribution of the student to EMA when the student has a large training loss. The student model is also adaptive by learning from the teacher only when the teacher outperforms the student. Experimental results showed that: (1) our noise-robust Dice loss outperforms existing noise-robust loss functions, (2) the proposed COPLE-Net achieves higher performance than state-of-the-art image segmentation networks, and (3) our framework with adaptive self-ensembling significantly outperforms a standard training process and surpasses other noise-robust training approaches in the scenario of learning from noisy labels for COVID-19 pneumonia lesion segmentation.","keywords: {computerised tomography;image denoising;image segmentation;learning (artificial intelligence);medical image processing;neural nets;COPLE-Net;deep learning;noise-robust dice loss;COVID-19 pneumonia lesions;automatic segmentation;noise-robust training;image segmentation;noise-robust loss functions;mean absolute error loss;noisy training labels;COVID-19 patients;Noise measurement;Image segmentation;Lesions;Lung;Training;COVID-19;COVID-19;convolutional neural network;noisy label;segmentation;pneumonia;Algorithms;Betacoronavirus;Coronavirus Infections;Deep Learning;Humans;Lung;Pandemics;Pneumonia, Viral;Tomography, X-Ray Computed},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9109297&isnumber=9153182,28,CNN 3D,,COPLE-Net,,COVID-19 CT noise robust,,,,2
"A. Kim, M. Park and D. H. Lee, ""AI-IDS: Application of Deep Learning to Real-Time Web Intrusion Detection,"" in IEEE Access, vol. 8, pp. 70245-70261, 2020.",doi: 10.1109/ACCESS.2020.2986882,"Abstract: Deep Learning has been widely applied to problems in detecting various network attacks. However, no cases on network security have shown applications of various deep learning algorithms in real-time services beyond experimental conditions. Moreover, owing to the integration of high-performance computing, it is necessary to apply systems that can handle large-scale traffic. Given the rapid evolution of web-attacks, we implemented and applied our Artificial Intelligence-based Intrusion Detection System (AI-IDS). We propose an optimal convolutional neural network and long short-term memory network (CNN-LSTM) model, normalized UTF-8 character encoding for Spatial Feature Learning (SFL) to adequately extract the characteristics of real-time HTTP traffic without encryption, calculating entropy, and compression. We demonstrated its excellence through repeated experiments on two public datasets (CSIC-2010, CICIDS2017) and fixed real-time data. By training payloads that analyzed true or false positives with a labeling tool, AI-IDS distinguishes sophisticated attacks, such as unknown patterns, encoded or obfuscated attacks from benign traffic. It is a flexible and scalable system that is implemented based on Docker images, separating user-defined functions by independent images. It also helps to write and improve Snort rules for signature-based IDS based on newly identified patterns. As the model calculates the malicious probability by continuous training, it could accurately analyze unknown web-attacks.","keywords: {computer network security;convolutional neural nets;hypermedia;learning (artificial intelligence);real-time systems;transport protocols;CICIDS2017 dataset;Docker images;Snort rules;CSIC-2010 dataset;normalized UTF-8 character encoding;CNN-LSTM model;real-time web intrusion detection;unknown web-attacks;signature-based IDS;real-time HTTP traffic;spatial feature learning;short-term memory network model;optimal convolutional neural network;artificial intelligence-based intrusion detection system;large-scale traffic;high-performance computing;real-time services;deep learning algorithms;network security;network attacks;AI-IDS;Intrusion detection;Feature extraction;Machine learning;Real-time systems;Wireless sensor networks;Payloads;Computer networks;intrusion detection;neural networks;large-scale systems;intelligent systems;real time systems;security;CNN-LSTM},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9063416&isnumber=8948470,29,LSTM,0.92,"CNN, LSTM",,Web Intrusion Detection,"CSIC-2010, CICISC-2017",,,
"H. Lee, K. Sohn and D. Min, ""Unsupervised Low-Light Image Enhancement Using Bright Channel Prior,"" in IEEE Signal Processing Letters, vol. 27, pp. 251-255, 2020.",doi: 10.1109/LSP.2020.2965824,"Abstract: Recent approaches for low-light image enhancement achieve excellent performance through supervised learning based on convolutional neural networks. However, it is still challenging to collect a large amount of low-/normal-light image pairs in real environments for training the networks. In this letter, we propose an unsupervised learning approach for single low-light image enhancement using the bright channel prior (BCP) that the brightest pixel in a small patch is likely to be close to 1. An unsupervised loss function is defined with the pseudo ground-truth generated using the BCP. An enhancement network, consisting of a simple encoder-decoder, is then trained using the unsupervised loss function. To the best of our knowledge, this is the first attempt that enhances a low-light image through unsupervised learning. Furthermore, we introduce saturation loss and self-attention map for preserving image details and naturalness in the enhanced result. The performance of the proposed method is validated on various public datasets. Experimental results demonstrate that the proposed unsupervised approach achieves competitive performance over state-of-the-art methods based on supervised learning.","keywords: {image colour analysis;image denoising;image enhancement;lighting;neural nets;unsupervised learning;low-light image;BCP;unsupervised approach;enhanced result;image details;enhancement network;unsupervised loss function;unsupervised learning approach;convolutional neural networks;supervised learning;bright channel prior;unsupervised low-light image enhancement;Lighting;Image enhancement;Brightness;Training data;Unsupervised learning;Supervised learning;Training;Unsupervised learning;low-light image enhancement;bright channel prior},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8955834&isnumber=8966529,30,CNN,,CNN,,Low-Light Image Enhancement,,,,
"W. Luo, P. Sun, F. Zhong, W. Liu, T. Zhang and Y. Wang, ""End-to-End Active Object Tracking and Its Real-World Deployment via Reinforcement Learning,"" in IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 42, no. 6, pp. 1317-1332, 1 June 2020.",doi: 10.1109/TPAMI.2019.2899570,"Abstract: We study active object tracking, where a tracker takes visual observations (i.e., frame sequences) as input and produces the corresponding camera control signals as output (e.g., move forward, turn left, etc.). Conventional methods tackle tracking and camera control tasks separately, and the resulting system is difficult to tune jointly. These methods also require significant human efforts for image labeling and expensive trial-and-error system tuning in the real world. To address these issues, we propose, in this paper, an end-to-end solution via deep reinforcement learning. A ConvNet-LSTM function approximator is adopted for the direct frame-to-action prediction. We further propose an environment augmentation technique and a customized reward function, which are crucial for successful training. The tracker trained in simulators (ViZDoom and Unreal Engine) demonstrates good generalization behaviors in the case of unseen object moving paths, unseen object appearances, unseen backgrounds, and distracting objects. The system is robust and can restore tracking after occasional lost of the target being tracked. We also find that the tracking ability, obtained solely from simulators, can potentially transfer to real-world scenarios. We demonstrate successful examples of such transfer, via experiments over the VOT dataset and the deployment of a real-world robot using the proposed active tracker trained in simulation.","keywords: {convolutional neural nets;function approximation;learning (artificial intelligence);object detection;object tracking;recurrent neural nets;end-to-end active object tracking;real-world deployment;visual observations;frame sequences;camera control signals;camera control tasks;deep reinforcement learning;ConvNet-LSTM function approximator;frame-to-action prediction;customized reward function;unseen object moving paths;unseen object appearances;distracting objects;tracking ability;real-world robot;active tracker;Object tracking;Cameras;Target tracking;Reinforcement learning;Robot vision systems;Active object tracking;reinforcement learning;environment augmentation},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8642452&isnumber=9087915,31,LSTM,,"CNN, LSTM, RL",,Object Tracking,VOT,,,
"G. Xu, M. Liu, Z. Jiang, W. Shen and C. Huang, ""Online Fault Diagnosis Method Based on Transfer Convolutional Neural Networks,"" in IEEE Transactions on Instrumentation and Measurement, vol. 69, no. 2, pp. 509-520, Feb. 2020.",doi: 10.1109/TIM.2019.2902003,"Abstract: Fault detection and diagnosis (FDD) is crucial for stable, reliable, and safe operation of industrial equipment. In recent years, deep learning models have been widely used in data-driven FDD methods because of their automatic feature learning capability. In general, these models are trained on historical sensor data, and therefore, it is very difficult to meet the real-time requirement of online FDD applications. Since transfer learning can solve different but similar problems in the target domain efficiently and effectively with the knowledge learned from the source domain, this paper proposes an online fault diagnosis method based on a deep transfer convolutional neural network (TCNN) framework. The TCNN framework is made up of an online CNN based on LeNet-5 and several offline CNNs with a shallow structure. First, time-domain signal data are converted into images that contain abundant fault information and are suitable as the input of CNN. Then, the online CNN is constructed to automatically extract representative features from the converted images and classify faults. Finally, in order to improve the real-time performance of the online CNN, several offline CNNs are also constructed and pretrained on related data sets. By directly transferring the shallow layers of the trained offline CNNs to the online CNN, the online CNN can significantly improve the real-time performance and successfully address the issue of achieving the desired diagnostic accuracy within limited training time. The proposed method is validated on two bearing data sets and one pump data set, respectively. The prediction accuracy of the proposed method using three data sets are 99.88%, 99.13%, and 99.98%, respectively. The experimental results also indicate that the improvement of accuracy is 19.21% for the motor bearing case, 29.82% for the rolling mill bearing case, and 33.26% for the pump case during the early stage of learning.","keywords: {condition monitoring;convolutional neural nets;fault diagnosis;feature extraction;image classification;learning (artificial intelligence);machine bearings;mechanical engineering computing;production equipment;trained offline CNNs;online CNN;online fault diagnosis method;deep learning models;data-driven FDD methods;automatic feature learning capability;historical sensor data;transfer learning;deep transfer convolutional neural network framework;time-domain signal data;faults classification;fault detection and diagnosis;industrial equipment;TCNN framework;feature extraction;motor bearing;rolling mill bearing;Fault diagnosis;Feature extraction;Deep learning;Circuit faults;Real-time systems;Training;Data models;Convolutional neural network (CNN);online fault diagnosis;real-time performance;signal-to-image conversion;transfer learning},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8672123&isnumber=8950241,32,CNN,,LeNet,,,,,,
"M. Zhang, W. Li, Q. Du, L. Gao and B. Zhang, ""Feature Extraction for Classification of Hyperspectral and LiDAR Data Using Patch-to-Patch CNN,"" in IEEE Transactions on Cybernetics, vol. 50, no. 1, pp. 100-111, Jan. 2020.",doi: 10.1109/TCYB.2018.2864670,"Abstract: Multisensor fusion is of great importance in Earth observation related applications. For instance, hyperspectral images (HSIs) provide wealthy spectral information while light detection and ranging (LiDAR) data provide elevation information, and using HSI and LiDAR data together can achieve better classification performance. In this paper, an unsupervised feature extraction framework, named as patch-to-patch convolutional neural network (PToP CNN), is proposed for collaborative classification of hyperspectral and LiDAR data. More specific, a three-tower PToP mapping is first developed to seek an accurate representation from HSI to LiDAR data, aiming at merging multiscale features between two different sources. Then, by integrating hidden layers of the designed PToP CNN, extracted features are expected to possess deeply fused characteristics. Accordingly, features from different hidden layers are concatenated into a stacked vector and fed into three fully connected layers. To verify the effectiveness of the proposed classification framework, experiments are executed on two benchmark remote sensing data sets. The experimental results demonstrate that the proposed method provides superior performance when compared with some state-of-the-art classifiers, such as two-branch CNN and context CNN.","keywords: {feature extraction;geophysical image processing;geophysical techniques;hyperspectral imaging;image classification;neural nets;optical radar;remote sensing by laser beam;LiDAR data;patch-to-patch CNN;Earth observation related applications;hyperspectral images;wealthy spectral information;light detection and ranging;unsupervised feature extraction framework;patch-to-patch convolutional neural network;collaborative classification;multiscale features;classification framework;benchmark remote sensing data sets;PToP CNN;Feature extraction;Laser radar;Decoding;Computer architecture;Hyperspectral imaging;Task analysis;Deep convolutional neural network (CNN);feature extraction;hyperspectral image (HSI) classification;multisensor fusion},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8467496&isnumber=8879634,33,,,,,,,,,
"Y. Gong et al., ""Context-Aware Convolutional Neural Network for Object Detection in VHR Remote Sensing Imagery,"" in IEEE Transactions on Geoscience and Remote Sensing, vol. 58, no. 1, pp. 34-44, Jan. 2020.",doi: 10.1109/TGRS.2019.2930246,"Abstract: Object detection in very-high-resolution (VHR) remote sensing imagery remains a challenge. Environmental factors, such as illumination intensity and weather, reduce image quality, resulting in poor feature representation and limited detection accuracy. To enrich the feature representation and mine the underlying context information among objects, this article proposes a context-aware convolutional neural network (CA-CNN) model for object detection that includes proposal generation, context feature extraction, feature fusion, and classification. During feature extraction, we propose integrating a context-regions-of-interests (Context-RoIs) mining layer into the CNN model and extracting context features by mapping Context-RoIs mined from the foreground proposals to multilevel feature maps. Finally, the context features extracted from multilevel layers are fused into a single layer, and the proposals represented by the fused features are classified by a softmax classifier. In this article, through numerous experiments, we thoroughly explore the influence of key factors, such as Context-RoIs, different feature scales, and different spatial context window sizes. Because of the end-to-end network design approach, our proposed model simultaneously maintains high efficiency and effectiveness. We conducted all model testing on the public NWPU VHR-10 data set. The experimental results demonstrate that our proposed CA-CNN model achieves significantly improved model performance and better detection results compared with the state-of-the-art methods.","keywords: {convolutional neural nets;feature extraction;geophysical image processing;image classification;image resolution;object detection;remote sensing;context-aware convolutional neural network model;object detection;context feature extraction;context-regions-of-interests;end-to-end network design approach;CA-CNN model;VHR remote sensing imagery;very-high-resolution remote sensing imagery;illumination intensity;spatial context window sizes;feature scale representation;fused feature representation;multilevel feature map layers;context-RoIs mapping;VHR remote sensing imagey;softmax classifier;public NWPU VHR-10 dataset;Feature extraction;Object detection;Proposals;Microsoft Windows;Semantics;Context modeling;Convolutional codes;Contextual information mining;convolutional neural network (CNN);object detection},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8846087&isnumber=8944190,34,R-CNN,89.85,CA-CNN,,,ImageNet,,1,
"X. Wang, X. Wang and S. Mao, ""Deep Convolutional Neural Networks for Indoor Localization with CSI Images,"" in IEEE Transactions on Network Science and Engineering, vol. 7, no. 1, pp. 316-327, 1 Jan.-March 2020.",doi: 10.1109/TNSE.2018.2871165,"Abstract: With the increasing demand of location-based services, Wi-Fi based localization has attracted great interest because it provides ubiquitous access in indoor environments. In this paper, we propose CiFi, deep convolutional neural networks (DCNN) for indoor localization with commodity 5GHz WiFi. Leveraging a modified device driver, we extract phase data of channel state information (CSI), which is used to estimate the angle of arrival (AoA). We then create estimated AoA images as input to a DCNN, to train the weights in the offline phase. The location of mobile device is predicted based using the trained DCNN and new CSI AoA images. We implement the proposed CiFi system with commodity Wi-Fi devices in the 5GHz band and verify its performance with extensive experiments in two representative indoor environments.","keywords: {convolutional neural nets;image representation;indoor radio;location based services;mobile computing;wireless LAN;DCNN;angle of arrival;Wi-Fi based localization;indoor environments;commodity Wi-Fi devices;CSI AoA images;channel state information;phase data extraction;device driver;commodity 5GHz WiFi;indoor localization;deep convolutional neural networks;location-based services;Wireless fidelity;Phase measurement;Antenna measurements;Training;Wireless sensor networks;Wireless communication;OFDM;Indoor localization;fingerprinting;deep convolutional neural network;5 GHz commodity Wi-Fi;Channel state information},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8468057&isnumber=9025091,35,CNN,87% under 3 m(mean error),CiFi,,IPS,CSI,,1,
"A. George, Z. Mostaani, D. Geissenbuhler, O. Nikisins, A. Anjos and S. Marcel, ""Biometric Face Presentation Attack Detection With Multi-Channel Convolutional Neural Network,"" in IEEE Transactions on Information Forensics and Security, vol. 15, pp. 42-55, 2020.",doi: 10.1109/TIFS.2019.2916652,"Abstract: Face recognition is a mainstream biometric authentication method. However, the vulnerability to presentation attacks (a.k.a. spoofing) limits its usability in unsupervised applications. Even though there are many methods available for tackling presentation attacks (PA), most of them fail to detect sophisticated attacks such as silicone masks. As the quality of presentation attack instruments improves over time, achieving reliable PA detection with visual spectra alone remains very challenging. We argue that analysis in multiple channels might help to address this issue. In this context, we propose a multi-channel Convolutional Neural Network-based approach for presentation attack detection (PAD). We also introduce the new Wide Multi-Channel presentation Attack (WMCA) database for face PAD which contains a wide variety of 2D and 3D presentation attacks for both impersonation and obfuscation attacks. Data from different channels such as color, depth, near-infrared, and thermal are available to advance the research in face PAD. The proposed method was compared with feature-based approaches and found to outperform the baselines achieving an ACER of 0.3% on the introduced dataset. The database and the software to reproduce the results are made available publicly.","keywords: {biometrics (access control);convolutional neural nets;face recognition;feature extraction;biometric face presentation attack detection;face recognition;presentation attacks;face PAD;obfuscation attacks;biometric authentication method;PA detection;wide multichannel presentation attack database;multichannel convolutional neural network-based approach;Face;Two dimensional displays;Databases;Image color analysis;Face recognition;Three-dimensional displays;Feature extraction;Presentation attack detection;convolutional neural network;biometrics;face recognition;anti-spoofing;multi-channel sensors},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8714076&isnumber=8833568,36,CNN,99.28,multi-channel CNN,,presentation attack detection,WMCA,,1,
"Z. Zhou, M. M. R. Siddiquee, N. Tajbakhsh and J. Liang, ""UNet++: Redesigning Skip Connections to Exploit Multiscale Features in Image Segmentation,"" in IEEE Transactions on Medical Imaging, vol. 39, no. 6, pp. 1856-1867, June 2020.",doi: 10.1109/TMI.2019.2959609,"Abstract: The state-of-the-art models for medical image segmentation are variants of U-Net and fully convolutional networks (FCN). Despite their success, these models have two limitations: (1) their optimal depth is apriori unknown, requiring extensive architecture search or inefficient ensemble of models of varying depths; and (2) their skip connections impose an unnecessarily restrictive fusion scheme, forcing aggregation only at the same-scale feature maps of the encoder and decoder sub-networks. To overcome these two limitations, we propose UNet++, a new neural architecture for semantic and instance segmentation, by (1) alleviating the unknown network depth with an efficient ensemble of U-Nets of varying depths, which partially share an encoder and co-learn simultaneously using deep supervision; (2) redesigning skip connections to aggregate features of varying semantic scales at the decoder sub-networks, leading to a highly flexible feature fusion scheme; and (3) devising a pruning scheme to accelerate the inference speed of UNet++. We have evaluated UNet++ using six different medical image segmentation datasets, covering multiple imaging modalities such as computed tomography (CT), magnetic resonance imaging (MRI), and electron microscopy (EM), and demonstrating that (1) UNet++ consistently outperforms the baseline models for the task of semantic segmentation across different datasets and backbone architectures; (2) UNet++ enhances segmentation quality of varying-size objects-an improvement over the fixed-depth U-Net; (3) Mask RCNN++ (Mask R-CNN with UNet++ design) outperforms the original Mask R-CNN for the task of instance segmentation; and (4) pruned UNet++ models achieve significant speedup while showing only modest performance degradation. Our implementation and pre-trained models are available at https://github.com/MrGiovanni/UNetPlusPlus.","keywords: {biomedical MRI;computerised tomography;feature extraction;image classification;image fusion;image representation;image segmentation;learning (artificial intelligence);medical image processing;neural nets;electron microscopy;MRI;CT;computed tomography;deep supervision;UNet++ design;mask R-CNN;fixed-depth U;backbone architectures;semantic segmentation;magnetic resonance imaging;imaging modalities;medical image segmentation datasets;highly flexible feature fusion scheme;semantic scales;neural architecture;decoder sub-networks;same-scale feature maps;fully convolutional networks;Decoding;Image segmentation;Computer architecture;Modeling;Semantics;Training;Biomedical imaging;Neuronal structure segmentation;liver segmentation;cell segmentation;nuclei segmentation;brain tumor segmentation;lung nodule segmentation;medical image segmentation;semantic segmentation;instance segmentation;deep supervision;model pruning},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8932614&isnumber=9106594,37,CNN/R-CNN,95.1 IOU,UNet++,https://github.com/MrGiovanni/UNetPlusPlus,medical image segmentaion,Nuclei,,1,
"N. E. M. Khalifa, M. H. N. Taha, D. Ezzat Ali, A. Slowik and A. E. Hassanien, ""Artificial Intelligence Technique for Gene Expression by Tumor RNA-Seq Data: A Novel Optimized Deep Learning Approach,"" in IEEE Access, vol. 8, pp. 22874-22883, 2020.",doi: 10.1109/ACCESS.2020.2970210,"Abstract: Cancer is one of the most feared and aggressive diseases in the world and is responsible for more than 9 million deaths universally. Staging cancer early increases the chances of recovery. One staging technique is RNA sequence analysis. Recent advances in the efficiency and accuracy of artificial intelligence techniques and optimization algorithms have facilitated the analysis of human genomics. This paper introduces a novel optimized deep learning approach based on binary particle swarm optimization with decision tree (BPSO-DT) and convolutional neural network (CNN) to classify different types of cancer based on tumor RNA sequence (RNA-Seq) gene expression data. The cancer types that will be investigated in this research are kidney renal clear cell carcinoma (KIRC), breast invasive carcinoma (BRCA), lung squamous cell carcinoma (LUSC), lung adenocarcinoma (LUAD) and uterine corpus endometrial carcinoma (UCEC). The proposed approach consists of three phases. The first phase is preprocessing, which at first optimize the high-dimensional RNA-seq to select only optimal features using BPSO-DT and then, converts the optimized RNA-Seq to 2D images. The second phase is augmentation, which increases the original dataset of 2086 samples to be 5 times larger. The selection of the augmentations techniques was based achieving the least impact on manipulating the features of the images. This phase helps to overcome the overfitting problem and trains the model to achieve better accuracy. The third phase is deep CNN architecture. In this phase, an architecture of two main convolutional layers for featured extraction and two fully connected layers is introduced to classify the 5 different types of cancer according to the availability of images on the dataset. The results and the performance metrics such as recall, precision and F1 score show that the proposed approach achieved an overall testing accuracy of 96.90%. The comparative results are introduced, and the proposed method outperforms those in related works in terms of testing accuracy for 5 classes of cancer. Moreover, the proposed approach is less complex and consume less memory.","keywords: {cancer;convolutional neural nets;data analysis;decision trees;feature extraction;feature selection;genomics;image classification;kidney;learning (artificial intelligence);lung;medical image processing;neural net architecture;particle swarm optimisation;RNA;tumours;RNA sequence analysis;artificial intelligence;optimization algorithms;optimized deep learning;BPSO-DT;convolutional neural network;tumor RNA sequence gene expression data;cancer type classification;breast invasive carcinoma;lung adenocarcinoma;uterine corpus endometrial carcinoma;deep CNN architecture;tumor RNA-Seq data;cancer staging;human genomics;binary particle swarm optimization with decision tree;kidney renal clear cell carcinoma;lung squamous cell carcinoma;feature selection;2D image features;Cancer;Tumors;Gene expression;Deep learning;Computer architecture;RNA;Cancer;RNA sequence;deep convolutional neural network;gene expression data},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8974295&isnumber=8948470,38,CNN,96.9,CNN,,Cancer gene detection,https://data.mendeley.com/datasets/sf5n64hydt/1,,E,
"C. Yan et al., ""STAT: Spatial-Temporal Attention Mechanism for Video Captioning,"" in IEEE Transactions on Multimedia, vol. 22, no. 1, pp. 229-241, Jan. 2020.",doi: 10.1109/TMM.2019.2924576,"Abstract: Video captioning refers to automatic generate natural language sentences, which summarize the video contents. Inspired by the visual attention mechanism of human beings, temporal attention mechanism has been widely used in video description to selectively focus on important frames. However, most existing methods based on temporal attention mechanism suffer from the problems of recognition error and detail missing, because temporal attention mechanism cannot further catch significant regions in frames. In order to address above problems, we propose the use of a novel spatial-temporal attention mechanism (STAT) within an encoder-decoder neural network for video captioning. The proposed STAT successfully takes into account both the spatial and temporal structures in a video, so it makes the decoder to automatically select the significant regions in the most relevant temporal segments for word prediction. We evaluate our STAT on two well-known benchmarks: MSVD and MSR-VTT-10K. Experimental results show that our proposed STAT achieves the state-of-the-art performance with several popular evaluation metrics: BLEU-4, METEOR, and CIDEr.","keywords: {computer vision;decoding;encoding;image segmentation;natural language processing;neural nets;video signal processing;video captioning;video summarization;visual attention mechanism;video description;spatial-temporal attention mechanism;spatial structures;temporal structures;encoder-decoder neural network;Feature extraction;Decoding;Semantics;Convolutional neural networks;Visualization;Fuses;Video captioning;spatial-temporal attention mechanism;encoder-decoder neural networks},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8744407&isnumber=8949825,39,CNN/R-CNN,0.738 CIDEr,STAT,,Video Captioning,MSVD,,,
"L. Zhao et al., ""T-GCN: A Temporal Graph Convolutional Network for Traffic Prediction,"" in IEEE Transactions on Intelligent Transportation Systems, vol. 21, no. 9, pp. 3848-3858, Sept. 2020.",doi: 10.1109/TITS.2019.2935152,"Abstract: Accurate and real-time traffic forecasting plays an important role in the intelligent traffic system and is of great significance for urban traffic planning, traffic management, and traffic control. However, traffic forecasting has always been considered an “open” scientific issue, owing to the constraints of urban road network topological structure and the law of dynamic change with time. To capture the spatial and temporal dependences simultaneously, we propose a novel neural network-based traffic forecasting method, the temporal graph convolutional network (T-GCN) model, which is combined with the graph convolutional network (GCN) and the gated recurrent unit (GRU). Specifically, the GCN is used to learn complex topological structures for capturing spatial dependence and the gated recurrent unit is used to learn dynamic changes of traffic data for capturing temporal dependence. Then, the T-GCN model is employed to traffic forecasting based on the urban road network. Experiments demonstrate that our T-GCN model can obtain the spatio-temporal correlation from traffic data and the predictions outperform state-of-art baselines on real-world traffic datasets. Our tensorflow implementation of the T-GCN is available at https://www.github.com/lehaifeng/T-GCN.","keywords: {convolutional neural nets;data handling;graph theory;intelligent transportation systems;learning (artificial intelligence);road traffic;traffic information systems;traffic data dynamic changes;complex topological structure learning;neural network-based traffic forecasting;spatio-temporal correlation;T-GCN model;spatial dependence;gated recurrent unit;temporal graph convolutional network model;temporal dependences;spatial dependences;urban road network topological structure;traffic control;traffic management;urban traffic planning;intelligent traffic system;real-time traffic forecasting;traffic prediction;Predictive models;Forecasting;Roads;Data models;Task analysis;Logic gates;Kalman filters;Traffic forecasting;temporal graph convolutional network (T-GCN);spatial dependence;temporal dependence},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8809901&isnumber=9179974,40,GRU/GCN,0.72/0.87,T-GCN,https://github.com/lehaifeng/T-GCN,Graph CNN,SZ-TAXI/LOS-LOOP,,,
"M. A. Khan, ""An IoT Framework for Heart Disease Prediction Based on MDCNN Classifier,"" in IEEE Access, vol. 8, pp. 34717-34727, 2020.",doi: 10.1109/ACCESS.2020.2974687,"Abstract: Nowadays, heart disease is the leading cause of death worldwide. Predicting heart disease is a complex task since it requires experience along with advanced knowledge. Internet of Things (IoT) technology has lately been adopted in healthcare systems to collect sensor values for heart disease diagnosis and prediction. Many researchers have focused on the diagnosis of heart disease, yet the accuracy of the diagnosis results is low. To address this issue, an IoT framework is proposed to evaluate heart disease more accurately using a Modified Deep Convolutional Neural Network (MDCNN). The smartwatch and heart monitor device that is attached to the patient monitors the blood pressure and electrocardiogram (ECG). The MDCNN is utilized for classifying the received sensor data into normal and abnormal. The performance of the system is analyzed by comparing the proposed MDCNN with existing deep learning neural networks and logistic regression. The results demonstrate that the proposed MDCNN based heart disease prediction system performs better than other methods. The proposed method shows that for the maximum number of records, the MDCNN achieves an accuracy of 98.2 which is better than existing classifiers.","keywords: {bioelectric potentials;convolutional neural nets;diseases;electrocardiography;health care;Internet of Things;learning (artificial intelligence);medical computing;medical signal processing;patient monitoring;regression analysis;smartwatch;heart monitor device;modified deep convolutional neural network;IoT framework;heart disease diagnosis;blood pressure;electrocardiogram;deep learning neural networks;logistic regression;MDCNN based heart disease prediction system;Heart;Diseases;Biomedical monitoring;Cloud computing;Monitoring;Electrocardiography;AEHO;cuttlefish algorithm;MDCNN;IoT;Cleveland dataset;sensors;wearable device;CAGR;electrocardiogram;LSTM;and CNN},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9000918&isnumber=8948470,41,CNN,98.2,MDCNN,,Heart Disease Prediction,UCI repository dataset,,,
"Z. Ul Abideen et al., ""Uncertainty Assisted Robust Tuberculosis Identification With Bayesian Convolutional Neural Networks,"" in IEEE Access, vol. 8, pp. 22812-22825, 2020.",doi: 10.1109/ACCESS.2020.2970023,"Abstract: Tuberculosis (TB) is an infectious disease that can lead towards death if left untreated. TB detection involves extraction of complex TB manifestation features such as lung cavity, air space consolidation, endobronchial spread, and pleural effusions from chest x-rays (CXRs). Deep learning based approach named convolutional neural network (CNN) has the ability to learn complex features from CXR images. The main problem is that CNN does not consider uncertainty to classify CXRs using softmax layer. It lacks in presenting the true probability of CXRs by differentiating confusing cases during TB detection. This paper presents the solution for TB identification by using Bayesian-based convolutional neural network (B-CNN). It deals with the uncertain cases that have low discernibility among the TB and non-TB manifested CXRs. The proposed TB identification methodology based on B-CNN is evaluated on two TB benchmark datasets, i.e., Montgomery and Shenzhen. For training and testing of proposed scheme we have utilized Google Colab platform which provides NVidia Tesla K80 with 12 GB of VRAM, single core of 2.3 GHz Xeon Processor, 12 GB RAM and 320 GB of disk. B-CNN achieves 96.42% and 86.46% accuracy on both dataset, respectively as compared to the state-of-the-art machine learning and CNN approaches. Moreover, B-CNN validates its results by filtering the CXRs as confusion cases where the variance of B-CNN predicted outputs is more than a certain threshold. Results prove the supremacy of B-CNN for the identification of TB and non-TB sample CXRs as compared to counterparts in terms of accuracy, variance in the predicted probabilities and model uncertainty.","keywords: {convolutional neural nets;diagnostic radiography;diseases;feature extraction;image classification;learning (artificial intelligence);lung;medical image processing;B-CNN;machine learning;CNN approaches;uncertainty assisted robust tuberculosis identification;Bayesian convolutional neural networks;infectious disease;TB detection;air space consolidation;deep learning based approach;Bayesian-based convolutional neural network;nonTB manifested CXRs;TB identification methodology;TB benchmark datasets;TB manifestation features;Montgomery dataset;Shenzhen dataset;memory size 12.0 GByte;frequency 2.3 GHz;memory size 320.0 GByte;Feature extraction;Uncertainty;Deep learning;Support vector machines;Bayes methods;Convolutional neural networks;Tuberculosis identification;computer-aided diagnostics;medical image analysis;Bayesian convolutional neural networks;model uncertainty},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8972440&isnumber=8948470,42,CNN,0.9642/0.8646,B-CNN,,Tuberculosis detection,Montgomery/Shenzhen,,,
"S. Seo, C. Kim, H. Kim, K. Mo and P. Kang, ""Comparative Study of Deep Learning-Based Sentiment Classification,"" in IEEE Access, vol. 8, pp. 6861-6875, 2020.",doi: 10.1109/ACCESS.2019.2963426,"Abstract: The purpose of sentiment classification is to determine whether a particular document has a positive or negative nuance. Sentiment classification is extensively used in many business domains to improve products or services by understanding the opinions of customers regarding these products. Deep learning achieves state-of-the-art results in various challenging domains. With the success of deep learning, many studies have proposed deep-learning-based sentiment classification models and achieved better performances compared with conventional machine learning models. However, one practical issue occurring in deep-learning-based sentiment classification is that the best model structure depends on the characteristics of the dataset on which the deep learning model is trained; moreover, it is manually determined based on the domain knowledge of an expert or selected from a grid search of possible candidates. Herein, we present a comparative study of different deep-learning-based sentiment classification model structures to derive meaningful implications for building sentiment classification models. Specifically, eight deep-learning models, three based on convolutional neural networks and five based on recurrent neural networks, with two types of input structures, i.e., word level and character level, are compared for 13 review datasets, and the classification performances are discussed under different perspectives.","keywords: {convolutional neural nets;learning (artificial intelligence);pattern classification;recurrent neural nets;sentiment analysis;deep learning;sentiment classification;customer opinions;grid search;convolutional neural networks;recurrent neural networks;Convolution;Sentiment analysis;Analytical models;Task analysis;Deep learning;Feature extraction;Recurrent neural networks;Sentiment classification;deep learning;convolutional neural network;recurrent neural network;word embedding;character embedding},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8948030&isnumber=8948470,43,LSTM/GRU,,Vanilla RNN/LSTM/CNN/GRU/BRNN,,Sentiment Analysis,,,1,
"T. Su, H. Sun, J. Zhu, S. Wang and Y. Li, ""BAT: Deep Learning Methods on Network Intrusion Detection Using NSL-KDD Dataset,"" in IEEE Access, vol. 8, pp. 29575-29585, 2020.",doi: 10.1109/ACCESS.2020.2972627,"Abstract: Intrusion detection can identify unknown attacks from network traffics and has been an effective means of network security. Nowadays, existing methods for network anomaly detection are usually based on traditional machine learning models, such as KNN, SVM, etc. Although these methods can obtain some outstanding features, they get a relatively low accuracy and rely heavily on manual design of traffic features, which has been obsolete in the age of big data. To solve the problems of low accuracy and feature engineering in intrusion detection, a traffic anomaly detection model BAT is proposed. The BAT model combines BLSTM (Bidirectional Long Short-term memory) and attention mechanism. Attention mechanism is used to screen the network flow vector composed of packet vectors generated by the BLSTM model, which can obtain the key features for network traffic classification. In addition, we adopt multiple convolutional layers to capture the local features of traffic data. As multiple convolutional layers are used to process data samples, we refer BAT model as BAT-MC. The softmax classifier is used for network traffic classification. The proposed end-to-end model does not use any feature engineering skills and can automatically learn the key features of the hierarchy. It can well describe the network traffic behavior and improve the ability of anomaly detection effectively. We test our model on a public benchmark dataset, and the experimental results demonstrate our model has better performance than other comparison methods.","keywords: {computer network security;feature extraction;learning (artificial intelligence);pattern classification;recurrent neural nets;telecommunication traffic;feature engineering;network traffic behavior;BAT-MC;traffic data;convolutional layers;network traffic classification;BLSTM model;network flow vector;attention mechanism;bidirectional long short-term memory;BAT model;traffic anomaly detection model;big data;machine learning models;network anomaly detection;network security;NSL-KDD dataset;network intrusion detection;deep learning methods;Intrusion detection;Feature extraction;Deep learning;Anomaly detection;Machine learning algorithms;Pattern matching;Network traffic;intrusion detection;deep learning;BLSTM;attention mechanism},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8988230&isnumber=8948470,44,LSTM,0.8425,BAT/BLSTM/CNN,,Intrusion Detection,KDDTes/NSL-KDD,,,
"A. Rosenfeld and J. K. Tsotsos, ""Incremental Learning Through Deep Adaptation,"" in IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 42, no. 3, pp. 651-663, 1 March 2020.",doi: 10.1109/TPAMI.2018.2884462,"Abstract: Given an existing trained neural network, it is often desirable to learn new capabilities without hindering performance of those already learned. Existing approaches either learn sub-optimal solutions, require joint training, or incur a substantial increment in the number of parameters for each added domain, typically as many as the original network. We propose a method called Deep Adaptation Modules (DAM) that constrains newly learned filters to be linear combinations of existing ones. DAMs precisely preserve performance on the original domain, require a fraction (typically 13 percent, dependent on network architecture) of the number of parameters compared to standard fine-tuning procedures and converge in less cycles of training to a comparable or better level of performance. When coupled with standard network quantization techniques, we further reduce the parameter cost to around 3 percent of the original with negligible or no loss in accuracy. The learned architecture can be controlled to switch between various learned representations, enabling a single network to solve a task from multiple different domains. We conduct extensive experiments showing the effectiveness of our method on a range of image classification tasks and explore different aspects of its behavior.","keywords: {learning (artificial intelligence);neural nets;DAM;network architecture;standard fine-tuning procedures;standard network quantization techniques;parameter cost;learned architecture;learned representations;incremental learning;trained neural network;deep adaptation modules;image classification tasks;Task analysis;Switches;Training;Neural networks;Computer architecture;Convolutional codes;Incremental learning;transfer learning;domain adaptation},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8554156&isnumber=8984605,45,CNN,,DAM,,Deep Adaptation/finetuning,,,1,
"S. Jiang, W. Min, L. Liu and Z. Luo, ""Multi-Scale Multi-View Deep Feature Aggregation for Food Recognition,"" in IEEE Transactions on Image Processing, vol. 29, pp. 265-276, 2020.",doi: 10.1109/TIP.2019.2929447,"Abstract: Recently, food recognition has received more and more attention in image processing and computer vision for its great potential applications in human health. Most of the existing methods directly extracted deep visual features via convolutional neural networks (CNNs) for food recognition. Such methods ignore the characteristics of food images and are, thus, hard to achieve optimal recognition performance. In contrast to general object recognition, food images typically do not exhibit distinctive spatial arrangement and common semantic patterns. In this paper, we propose a multi-scale multi-view feature aggregation (MSMVFA) scheme for food recognition. MSMVFA can aggregate high-level semantic features, mid-level attribute features, and deep visual features into a unified representation. These three types of features describe the food image from different granularity. Therefore, the aggregated features can capture the semantics of food images with the greatest probability. For that solution, we utilize additional ingredient knowledge to obtain mid-level attribute representation via ingredient-supervised CNNs. High-level semantic features and deep visual features are extracted from class-supervised CNNs. Considering food images do not exhibit distinctive spatial layout in many cases, MSMVFA fuses multi-scale CNN activations for each type of features to make aggregated features more discriminative and invariable to geometrical deformation. Finally, the aggregated features are more robust, comprehensive, and discriminative via two-level fusion, namely multi-scale fusion for each type of features and multi-view aggregation for different types of features. In addition, MSMVFA is general and different deep networks can be easily applied into this scheme. Extensive experiments and evaluations demonstrate that our method achieves state-of-the-art recognition performance on three popular large-scale food benchmark datasets in Top-1 recognition accuracy. Furthermore, we expect this paper will further the agenda of food recognition in the community of image processing and computer vision.","keywords: {computer vision;convolutional neural nets;feature extraction;image classification;image fusion;image representation;learning (artificial intelligence);object recognition;food image;optimal recognition performance;general object recognition;multiscale multiview feature aggregation scheme;food recognition;high-level semantic features;mid-level attribute features;deep visual features;aggregated features;multiscale fusion;state-of-the-art recognition performance;large-scale food benchmark datasets;image processing;computer vision;multiscale multiview deep feature aggregation;multiscale CNN activations;Feature extraction;Visualization;Image recognition;Semantics;Object recognition;Deep learning;Computer vision;Food recognition;ingredient knowledge;feature aggregation;convolutional neural networks},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8779586&isnumber=8835130,46,,0.983/0.969 top 5,MSMVFA,,Food Recognition,VIREOFOOD-172/CHINESEFOODNET,,1,
"N. Kumar et al., ""A Multi-Organ Nucleus Segmentation Challenge,"" in IEEE Transactions on Medical Imaging, vol. 39, no. 5, pp. 1380-1391, May 2020.",doi: 10.1109/TMI.2019.2947628,"Abstract: Generalized nucleus segmentation techniques can contribute greatly to reducing the time to develop and validate visual biomarkers for new digital pathology datasets. We summarize the results of MoNuSeg 2018 Challenge whose objective was to develop generalizable nuclei segmentation techniques in digital pathology. The challenge was an official satellite event of the MICCAI 2018 conference in which 32 teams with more than 80 participants from geographically diverse institutes participated. Contestants were given a training set with 30 images from seven organs with annotations of 21,623 individual nuclei. A test dataset with 14 images taken from seven organs, including two organs that did not appear in the training set was released without annotations. Entries were evaluated based on average aggregated Jaccard index (AJI) on the test set to prioritize accurate instance segmentation as opposed to mere semantic segmentation. More than half the teams that completed the challenge outperformed a previous baseline. Among the trends observed that contributed to increased accuracy were the use of color normalization as well as heavy data augmentation. Additionally, fully convolutional networks inspired by variants of U-Net, FCN, and Mask-RCNN were popularly used, typically based on ResNet or VGG base architectures. Watershed segmentation on predicted semantic segmentation maps was a popular post-processing strategy. Several of the top techniques compared favorably to an individual human annotator and can be used with confidence for nuclear morphometrics.","keywords: {convolutional neural nets;image segmentation;learning (artificial intelligence);medical image processing;recurrent neural nets;generalized nucleus segmentation techniques;visual biomarkers;digital pathology datasets;MoNuSeg 2018 Challenge;generalizable nuclei segmentation techniques;official satellite event;MICCAI 2018 conference;geographically diverse institutes;training set;test dataset;average aggregated Jaccard index;watershed segmentation;predicted semantic segmentation maps;instance segmentation;multiorgan nucleus segmentation challenge;Image segmentation;Pathology;Image color analysis;Semantics;Machine learning algorithms;Task analysis;Deep learning;Multi-organ;nucleus segmentation;digital pathology;instance segmentation;aggregated Jaccard index},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8880654&isnumber=9084068,47,CNN,,CNN,,,MoNuSeg 2018,,,
"J. Liu et al., ""Feature Boosting Network For 3D Pose Estimation,"" in IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 42, no. 2, pp. 494-501, 1 Feb. 2020.",doi: 10.1109/TPAMI.2019.2894422,"Abstract: In this paper, a feature boosting network is proposed for estimating 3D hand pose and 3D body pose from a single RGB image. In this method, the features learned by the convolutional layers are boosted with a new long short-term dependence-aware (LSTD) module, which enables the intermediate convolutional feature maps to perceive the graphical long short-term dependency among different hand (or body) parts using the designed Graphical ConvLSTM. Learning a set of features that are reliable and discriminatively representative of the pose of a hand (or body) part is difficult due to the ambiguities, texture and illumination variation, and self-occlusion in the real application of 3D pose estimation. To improve the reliability of the features for representing each body part and enhance the LSTD module, we further introduce a context consistency gate (CCG) in this paper, with which the convolutional feature maps are modulated according to their consistency with the context representations. We evaluate the proposed method on challenging benchmark datasets for 3D hand pose estimation and 3D full body pose estimation. Experimental results show the effectiveness of our method that achieves state-of-the-art performance on both of the tasks.","keywords: {convolutional neural nets;feature extraction;image colour analysis;image enhancement;image representation;pose estimation;short-term dependence-aware module;intermediate convolutional feature maps;3D pose estimation;body part;LSTD module;feature boosting network;RGB image;convolutional layers;Graphical ConvLSTM;Three-dimensional displays;Pose estimation;Two dimensional displays;Boosting;Logic gates;Reliability;Task analysis;3D pose estimation;convolutional LSTM;long short-term dependency;context consistency gate},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8621059&isnumber=8952810,48,CNN/LSTM,0.498/0.877,LSTD/CCG,,3D Pose Estimation,Human3.6M/3DHandPose,,2,
"J. Zhu, H. Chen and W. Ye, ""A Hybrid CNN–LSTM Network for the Classification of Human Activities Based on Micro-Doppler Radar,"" in IEEE Access, vol. 8, pp. 24713-24720, 2020.",doi: 10.1109/ACCESS.2020.2971064,"Abstract: Many deep learning (DL) models have shown exceptional promise in radar-based human activity recognition (HAR) area. For radar-based HAR, the raw data is generally converted into a 2-D spectrogram by using short-time Fourier transform (STFT). All the existing DL methods treat the spectrogram as an optical image, and thus the corresponding architectures such as 2-D convolutional neural networks (2D-CNNs) are adopted in those methods. These 2-D methods that ignore temporal characteristics ordinarily lead to a complex network with a huge amount of parameters but limited recognition accuracy. In this paper, for the first time, the radar spectrogram is treated as a time sequence with multiple channels. Hence, we propose a DL model composed of 1-D convolutional neural networks (1D-CNNs) and long short-term memory (LSTM). The experiments results show that the proposed model can extract spatio-temporal characteristics of the radar data and thus achieves the best recognition accuracy and relatively low complexity compared to the existing 2D-CNN methods.","keywords: {complex networks;convolutional neural nets;Doppler radar;feature extraction;Fourier transforms;image classification;image motion analysis;learning (artificial intelligence);radar imaging;recurrent neural nets;spatiotemporal phenomena;1D convolutional neural networks;1D-CNN;spatiotemporal characteristics;radar data;recognition accuracy;hybrid CNN-LSTM network;human activity classification;microDoppler radar;deep learning models;radar-based human activity recognition area;radar-based HAR;optical image;2D convolutional neural networks;2D-CNN;complex network;radar spectrogram;time sequence;1D-CNN;2D spectrogram;short-time Fourier transform;STFT;DL methods;temporal characteristics;Feature extraction;Spectrogram;Radar;Convolution;Time-frequency analysis;Activity recognition;Convolutional neural networks;Radar signal processing;human activity recognition;convolutional neural network;recurrent neural network;deep learning},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8978926&isnumber=8948470,49,CNN/LSTM,0.9828,1D CNN/CNN/LSTM,,Classification of Human Activities,,,2,
"W. Zhang et al., ""Deep Model Based Transfer and Multi-Task Learning for Biological Image Analysis,"" in IEEE Transactions on Big Data, vol. 6, no. 2, pp. 322-333, 1 June 2020.",doi: 10.1109/TBDATA.2016.2573280,"Abstract: A central theme in learning from image data is to develop appropriate representations for the specific task at hand. Thus, a practical challenge is to determine what features are appropriate for specific tasks. For example, in the study of gene expression patterns in Drosophila, texture features were particularly effective for determining the developmental stages from in situ hybridization images. Such image representation is however not suitable for controlled vocabulary term annotation. Here, we developed feature extraction methods to generate hierarchical representations for ISH images. Our approach is based on the deep convolutional neural networks that can act on image pixels directly. To make the extracted features generic, the models were trained using a natural image set with millions of labeled examples. These models were transferred to the ISH image domain. To account for the differences between the source and target domains, we proposed a partial transfer learning scheme in which only part of the source model is transferred. We employed multi-task learning method to fine-tune the pre-trained models with labeled ISH images. Results showed that feature representations computed by deep models based on transfer and multi-task learning significantly outperformed other methods for annotating gene expression patterns at different stage ranges.","keywords: {biology computing;convolutional neural nets;feature extraction;genetics;image representation;image texture;learning (artificial intelligence);gene expression patterns;texture features;developmental stages;image representation;feature extraction;hierarchical representations;deep convolutional neural networks;image pixels;natural image;ISH image domain;partial transfer learning;source model;labeled ISH images;feature representations;deep models;model based transfer;biological image;image data;multitask learning;vocabulary term annotation;hybridization images;Feature extraction;Computational modeling;Biological system modeling;Gene expression;Data models;Training;Deep learning;transfer learning;multi-task learning;image analysis;bioinformatics},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7480825&isnumber=9098178,50,CNN,0.768/0.859,CNN,,Biological Image Analysis,,,,
"Y. Wang, Z. Li, C. Zeng, G. -S. Xia and H. Shen, ""An Urban Water Extraction Method Combining Deep Learning and Google Earth Engine,"" in IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, vol. 13, pp. 769-782, 2020.",doi: 10.1109/JSTARS.2020.2971783,"Abstract: Urban water is important for the urban ecosystem. Accurate and efficient detection of urban water with remote sensing data is of great significance for urban management and planning. In this article, we proposed a new method by combining Google Earth Engine (GEE) with a multiscale convolutional neural network (MSCNN) to extract urban water from Landsat images, which can be summarized as “offline training and online prediction” (OTOP). That is, the training of MSCNN is completed offline, and the process of urban water extraction is implemented on GEE with the trained parameters of MSCNN. The OTOP can give full play to the respective advantages of GEE and the convolutional neural network (CNN), and can make the use of deep learning method in GEE more flexible. The proposed method can process the available satellite images with high performance, without data download and storage, and the overall performance of urban water extraction in the test areas is also higher than that of the modified normalized difference water index (MNDWI) and random forest classifier. The results of the extended validation in the other major cities of China also showed that OTOP is robust and can be used to extract different types of urban water, which benefits from the structural design and training of MSCNN. Therefore, OTOP is especially suitable for the study of large-scale and long-term urban water change detection in the background of urbanization.","keywords: {convolutional neural nets;ecology;geographic information systems;geophysical image processing;hydrological techniques;learning (artificial intelligence);remote sensing;town and country planning;water resources;OTOP;GEE;deep learning method;long-term urban water change detection;Google Earth Engine;urban ecosystem;urban management;urban planning;MSCNN;urban water extraction method;remote sensing data;multiscale convolutional neural network;Landsat images;offline training and online prediction;satellite images;China;Earth;Remote sensing;Urban areas;Artificial satellites;Training;Deep learning;Feature extraction;Convolutional neural network;google earth engine;urban water;water extraction},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8989826&isnumber=8994817,51,CNN,,MSCNN,,Google earth Urban water detection,,,,
"Z. Ouyang, J. Niu, Y. Liu and M. Guizani, ""Deep CNN-Based Real-Time Traffic Light Detector for Self-Driving Vehicles,"" in IEEE Transactions on Mobile Computing, vol. 19, no. 2, pp. 300-313, 1 Feb. 2020.",doi: 10.1109/TMC.2019.2892451,"Abstract: Due to the unavailability of Vehicle-to-Infrastructure (V2I) communication in current transportation systems, Traffic Light Detection (TLD) is still considered an important module in autonomous vehicles and Driver Assistance Systems (DAS). To overcome low flexibility and accuracy of vision-based heuristic algorithms and high power consumption of deep learning-based methods, we propose a lightweight and real-time traffic light detector for the autonomous vehicle platform. Our model consists of a heuristic candidate region selection module to identify all possible traffic lights, and a lightweight Convolution Neural Network (CNN) classifier to classify the results obtained. Offline simulations on the GPU server with the collected dataset and several public datasets show that our model achieves higher average accuracy and less time consumption. By integrating our detector module on NVidia Jetson TX1/TX2, we conduct on-road tests on two full-scale self-driving vehicle platforms (a car and a bus) in normal traffic conditions. Our model can achieve an average detection accuracy of 99.3 percent (mRttld) and 99.7 percent (Rttld) at 10Hz on TX1 and TX2, respectively. The on-road tests also show that our traffic light detection module can achieve <; + 1:5m errors at stop lines when working with other selfdriving modules.","keywords: {automobiles;convolutional neural nets;driver information systems;image sensors;learning (artificial intelligence);mobile robots;object detection;pattern classification;road traffic control;full-scale self-driving vehicle platforms;traffic light detection module;selfdriving modules;vehicle-to-infrastructure communication;driver assistance systems;vision-based heuristic algorithms;high power consumption;deep learning-based methods;lightweight time traffic light detector;autonomous vehicle platform;heuristic candidate region selection module;deep CNN-based real-time traffic light detector;self-driving vehicles;lightweight convolution neural network classifier;GPU server;Computational modeling;Feature extraction;Heuristic algorithms;Hidden Markov models;Real-time systems;Machine learning;Detectors;Traffic light detection;autonomous vehicle;deep learning;machine learning;dataset},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8611202&isnumber=8952734,52,R-CNN,0.993,CNN/ROI,,Traffic Light detector,,,,
"P. Tang et al., ""PCL: Proposal Cluster Learning for Weakly Supervised Object Detection,"" in IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 42, no. 1, pp. 176-191, 1 Jan. 2020.",doi: 10.1109/TPAMI.2018.2876304,"Abstract: Weakly Supervised Object Detection (WSOD), using only image-level annotations to train object detectors, is of growing importance in object recognition. In this paper, we propose a novel deep network for WSOD. Unlike previous networks that transfer the object detection problem to an image classification problem using Multiple Instance Learning (MIL), our strategy generates proposal clusters to learn refined instance classifiers by an iterative process. The proposals in the same cluster are spatially adjacent and associated with the same object. This prevents the network from concentrating too much on parts of objects instead of whole objects. We first show that instances can be assigned object or background labels directly based on proposal clusters for instance classifier refinement, and then show that treating each cluster as a small new bag yields fewer ambiguities than the directly assigning label method. The iterative instance classifier refinement is implemented online using multiple streams in convolutional neural networks, where the first is an MIL network and the others are for instance classifier refinement supervised by the preceding one. Experiments are conducted on the PASCAL VOC, ImageNet detection, and MS-COCO benchmarks for WSOD. Results show that our method outperforms the previous state of the art significantly.","keywords: {convolutional neural nets;image classification;iterative methods;object detection;object recognition;pattern clustering;supervised learning;image classification problem;proposal cluster learning;convolutional neural networks;MIL network;WSOD;weakly supervised object detection;object detectors;object recognition;multiple instance learning;iterative process;Convolutional neural networks;image classification;Object recognition;Object detection;Pattern clusteirng;Iterative methods;Object detection;weakly supervised learning;convolutional neural network;multiple instance learning;proposal cluster},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8493315&isnumber=8922815,53,R-CNN,,CNN,,object Tracking,ImageNet/PASCAL/COCO,,,
"M. Li, W. Hsu, X. Xie, J. Cong and W. Gao, ""SACNN: Self-Attention Convolutional Neural Network for Low-Dose CT Denoising With Self-Supervised Perceptual Loss Network,"" in IEEE Transactions on Medical Imaging, vol. 39, no. 7, pp. 2289-2301, July 2020.",doi: 10.1109/TMI.2020.2968472,"Abstract: Computed tomography (CT) is a widely used screening and diagnostic tool that allows clinicians to obtain a high-resolution, volumetric image of internal structures in a non-invasive manner. Increasingly, efforts have been made to improve the image quality of low-dose CT (LDCT) to reduce the cumulative radiation exposure of patients undergoing routine screening exams. The resurgence of deep learning has yielded a new approach for noise reduction by training a deep multi-layer convolutional neural networks (CNN) to map the low-dose to normal-dose CT images. However, CNN-based methods heavily rely on convolutional kernels, which use fixed-size filters to process one local neighborhood within the receptive field at a time. As a result, they are not efficient at retrieving structural information across large regions. In this paper, we propose a novel 3D self-attention convolutional neural network for the LDCT denoising problem. Our 3D self-attention module leverages the 3D volume of CT images to capture a wide range of spatial information both within CT slices and between CT slices. With the help of the 3D self-attention module, CNNs are able to leverage pixels with stronger relationships regardless of their distance and achieve better denoising results. In addition, we propose a self-supervised learning scheme to train a domain-specific autoencoder as the perceptual loss function. We combine these two methods and demonstrate their effectiveness on both CNN-based neural networks and WGAN-based neural networks with comprehensive experiments. Tested on the AAPM-Mayo Clinic Low Dose CT Grand Challenge data set, our experiments demonstrate that self-attention (SA) module and autoencoder (AE) perceptual loss function can efficiently enhance traditional CNNs and can achieve comparable or better results than the state-of-the-art methods.","keywords: {computerised tomography;convolutional neural nets;dosimetry;edge detection;feature extraction;image denoising;learning (artificial intelligence);medical image processing;low-dose CT denoising;self-supervised perceptual loss network;computed tomography;diagnostic tool;volumetric image;internal structures;noninvasive manner;image quality;deep learning;noise reduction;multilayer convolutional neural networks;CT images;CNN-based methods;convolutional kernels;structural information;3D self-attention convolutional neural network;LDCT denoising problem;3D self-attention module;spatial information;CT slices;self-supervised learning scheme;perceptual loss function;CNN-based neural networks;WGAN-based neural networks;Computed tomography;Noise reduction;Three-dimensional displays;Image reconstruction;Feature extraction;Convolutional neural networks;Low-dose CT;denoising;self-attention;autoencoder;perceptual loss},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8964295&isnumber=9130176,54,CNN,,3D CNN/attention,,CT improvement,NIH-AAPM-Mayo,,,
"F. Yang et al., ""Deep Learning for Smartphone-Based Malaria Parasite Detection in Thick Blood Smears,"" in IEEE Journal of Biomedical and Health Informatics, vol. 24, no. 5, pp. 1427-1438, May 2020.",doi: 10.1109/JBHI.2019.2939121,"Abstract: Objective: This work investigates the possibility of automated malaria parasite detection in thick blood smears with smartphones. Methods: We have developed the first deep learning method that can detect malaria parasites in thick blood smear images and can run on smartphones. Our method consists of two processing steps. First, we apply an intensity-based Iterative Global Minimum Screening (IGMS), which performs a fast screening of a thick smear image to find parasite candidates. Then, a customized Convolutional Neural Network (CNN) classifies each candidate as either parasite or background. Together with this paper, we make a dataset of 1819 thick smear images from 150 patients publicly available to the research community. We used this dataset to train and test our deep learning method, as described in this paper. Results: A patient-level five-fold cross-evaluation demonstrates the effectiveness of the customized CNN model in discriminating between positive (parasitic) and negative image patches in terms of the following performance indicators: accuracy (93.46% ± 0.32%), AUC (98.39% ± 0.18%), sensitivity (92.59% ± 1.27%), specificity (94.33% ± 1.25%), precision (94.25% ± 1.13%), and negative predictive value (92.74% ± 1.09%). High correlation coefficients (>0.98) between automatically detected parasites and ground truth, on both image level and patient level, demonstrate the practicality of our method. Conclusion: Promising results are obtained for parasite detection in thick blood smears for a smartphone application using deep learning methods. Significance: Automated parasite detection running on smartphones is a promising alternative to manual parasite counting for malaria diagnosis, especially in areas lacking experienced parasitologists.","keywords: {blood;convolutional neural nets;diseases;image classification;iterative methods;learning (artificial intelligence);medical image processing;object detection;patient diagnosis;smart phones;smartphones;manual parasite;malaria diagnosis;malaria parasite detection;thick blood smears;automated malaria parasite detection;deep learning;blood smear images;customized Convolutional Neural Network;customized CNN;Iterative Global Minimum Screening;IGMS;Feature extraction;Blood;Diseases;Support vector machines;Deep learning;Sensitivity;Image segmentation;Deep learning;convolutional neural networks;computer-aided diagnosis;malaria},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8846750&isnumber=9086632,55,CNN,0.9346,CNN,,malaria parasite detection,,,,1
"K. Yuen and M. M. Trivedi, ""Looking at Hands in Autonomous Vehicles: A ConvNet Approach Using Part Affinity Fields,"" in IEEE Transactions on Intelligent Vehicles, vol. 5, no. 3, pp. 361-371, Sept. 2020.",doi: 10.1109/TIV.2019.2955369,"Abstract: In the context of autonomous driving, where humans may need to take over in the event where the computer may issue a takeover request, a key step towards driving safety is the monitoring of the hands to ensure the driver is ready for such a request. This work, focuses on the first step of this process, which is to locate the hands. Such a system must work in real-time and under varying harsh lighting conditions. This article introduces a fast ConvNet approach, based on the work of original work of OpenPose by Cao, et al. for full body joint estimation. The network is modified with fewer parameters and retrained using our own day-time naturalistic autonomous driving dataset to estimate joint and affinity heatmaps for driver and passenger's wrist and elbows, for a total of 8 joint classes and part affinity fields between each wrist-elbow pair. The approach runs real-time on real-world data at 40 fps on multiple drivers and passengers. The system is extensively evaluated both quantitatively and qualitatively, showing at least 95% detection performance on joint localization and arm-angle estimation.","keywords: {biomechanics;convolutional neural nets;image motion analysis;intelligent transportation systems;object detection;pose estimation;road safety;autonomous vehicles;part affinity fields;takeover request;harsh lighting conditions;body joint estimation;day-time naturalistic autonomous driving dataset;passenger;wrist-elbow pair;joint localization;arm-angle estimation;ConvNet;driving safety;hand monitoring;joint heatmap;affinity heatmap;driver wrist;driver elbows;Heating systems;Wrist;Elbow;Autonomous vehicles;Monitoring;Task analysis;Takeover;driver assistance systems;in-vehicle activity monitoring;situational awareness;joint localization},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8910347&isnumber=9178528,56,CNN,0.95,VGG19,,Pose Estimation,COCO/MPII human multi-person,,2,
"H. Jung, Y. Kim, H. Jang, N. Ha and K. Sohn, ""Unsupervised Deep Image Fusion With Structure Tensor Representations,"" in IEEE Transactions on Image Processing, vol. 29, pp. 3845-3858, 2020.",doi: 10.1109/TIP.2020.2966075,"Abstract: Convolutional neural networks (CNNs) have facilitated substantial progress on various problems in computer vision and image processing. However, applying them to image fusion has remained challenging due to the lack of the labelled data for supervised learning. This paper introduces a deep image fusion network (DIF-Net), an unsupervised deep learning framework for image fusion. The DIF-Net parameterizes the entire processes of image fusion, comprising of feature extraction, feature fusion, and image reconstruction, using a CNN. The purpose of DIF-Net is to generate an output image which has an identical contrast to high-dimensional input images. To realize this, we propose an unsupervised loss function using the structure tensor representation of the multi-channel image contrasts. Different from traditional fusion methods that involve time-consuming optimization or iterative procedures to obtain the results, our loss function is minimized by a stochastic deep learning solver with large-scale examples. Consequently, the proposed method can produce fused images that preserve source image details through a single forward network trained without reference ground-truth labels. The proposed method has broad applicability to various image fusion problems, including multi-spectral, multi-focus, and multi-exposure image fusions. Quantitative and qualitative evaluations show that the proposed technique outperforms existing state-of-the-art approaches for various applications.","keywords: {computer vision;convolutional neural nets;feature extraction;image fusion;image reconstruction;image representation;minimisation;stochastic processes;tensors;unsupervised learning;computer vision;loss function minimization;DIF-Net;multichannel image contrasts;convolutional neural networks;unsupervised deep learning framework;deep image fusion network;image fusion problems;source image details;stochastic deep learning solver;structure tensor representation;unsupervised loss function;image reconstruction;Image fusion;Tensors;Feature extraction;Transforms;Image reconstruction;Iterative methods;Imaging;Image fusion;image contrast;structure tensor;convolutional neural network;and unsupervised learning},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8962327&isnumber=8835130,57,CNN,,DIF-Net,,Unsupervised CNN,COCO,,3,
"Y. Liang, L. Lu, Q. Xiao and S. Yan, ""Evaluating Fast Algorithms for Convolutional Neural Networks on FPGAs,"" in IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, vol. 39, no. 4, pp. 857-870, April 2020.",doi: 10.1109/TCAD.2019.2897701,"Abstract: In recent years, convolutional neural networks (CNNs) have become widely adopted for computer vision tasks. Field-programmable gate arrays (FPGAs) have been adequately explored as a promising hardware accelerator for CNNs due to its high performance, energy efficiency, and reconfigurability. However, prior FPGA solutions based on the conventional convolutional algorithm is often bounded by the computational capability of FPGAs (e.g., the number of DSPs). To address this problem, the feature maps are transformed to a special domain using fast algorithms to reduce the arithmetic complexity. Winograd and fast Fourier transformation (FFT), as fast algorithm representatives, first transform input data and filter to Winograd or frequency domain, then perform element-wise multiplication, and apply inverse transformation to get the final output. In this paper, we propose a novel architecture for implementing fast algorithms on FPGAs. Our design employs line buffer structure to effectively reuse the feature map data among different tiles. We also effectively pipeline the Winograd/FFT processing element (PE) engine and initiate multiple PEs through parallelization. Meanwhile, there exists a complex design space to explore. We propose an analytical model to predict the resource usage and the performance. Then, we use the model to guide a fast design space exploration. Experiments using the state-of-the-art CNNs demonstrate the best performance and energy efficiency on FPGAs. We achieve 854.6 and 2479.6 GOP/s for AlexNet and VGG16 on Xilinx ZCU102 platform using Winograd. We achieve 130.4 GOP/s for Resnet using Winograd and 201.1 GOP/s for YOLO using FFT on Xilinx ZC706 platform.","keywords: {convolutional neural nets;electronic engineering computing;fast Fourier transforms;field programmable gate arrays;feature map data;complex design space;design space exploration;energy efficiency;convolutional neural networks;computer vision tasks;field-programmable gate arrays;hardware accelerator;FPGA solutions;fast Fourier transformation;element-wise multiplication;inverse transformation;design space exploration;arithmetic complexity;Winograd-FFT processing element;AlexNet;VGG16;Xilinx ZCU102 platform;Xilinx ZC706 platform;Field programmable gate arrays;Convolution;Space exploration;Prediction algorithms;Transforms;Analytical models;Convolutional neural networks;Convolutional neural network (CNN);fast algorithm;fast Fourier transformation (FFT);field-programmable gate array (FPGA);Winograd},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8634913&isnumber=9042369,58,CNN,,CNN,,FPGA,,,1,
"Y. S. Chernyshova, A. V. Sheshkus and V. V. Arlazarov, ""Two-Step CNN Framework for Text Line Recognition in Camera-Captured Images,"" in IEEE Access, vol. 8, pp. 32587-32600, 2020.",doi: 10.1109/ACCESS.2020.2974051,"Abstract: In this paper, we introduce an “on the device” text line recognition framework that is designed for mobile or embedded systems. We consider per-character segmentation as a language-independent problem and individual character recognition as a language-dependent one. Thus, the proposed solution is based on two separate artificial neural networks (ANN) and dynamic programming instead of employing image processing methods for the segmentation step or end-to-end ANN. To satisfy the tight constraints on memory size imposed by embedded systems and to avoid overfitting, we employ ANNs with a small number of trainable parameters. The primary purpose of our framework is the recognition of low-quality images of identity documents with complex backgrounds and a variety of languages and fonts. We demonstrate that our solution shows high recognition accuracy on natural datasets even being trained on purely synthetic data. We use MIDV-500 and Census 1961 Project datasets for text line recognition. The proposed method considerably surpasses the algorithmic method implemented in Tesseract 3.05, the LSTM method (Tesseract 4.00), and unpublished method used in the ABBYY FineReader 15 system. Also, our framework is faster than other compared solutions. We show the language-independence of our segmenter with the experiment with Cyrillic, Armenian, and Chinese text lines.","keywords: {cameras;character recognition;convolutional neural nets;document image processing;dynamic programming;embedded systems;handwritten character recognition;image segmentation;optical character recognition;recurrent neural nets;text analysis;CNN framework;camera-captured images;device text line recognition framework;embedded systems;per-character segmentation;language-independent problem;individual character recognition;language-dependent;artificial neural networks;image processing methods;segmentation step;end-to-end ANN;low-quality images;high recognition accuracy;ABBYY FineReader 15 system;language-independence;Cyrillic text lines;Chinese text lines;Armenian text lines;Optical character recognition software;Text recognition;Image segmentation;Character recognition;Image recognition;Neural networks;Computer architecture;Text recognition;artificial neural networks;character segmentation;character recognition;machine learning},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8999509&isnumber=8948470,59,RNN,,ANN/RNN/TESSERACT,,Text Line Recognition,MIDV-500/Census/MNIST,,2,
"S. Haider et al., ""A Deep CNN Ensemble Framework for Efficient DDoS Attack Detection in Software Defined Networks,"" in IEEE Access, vol. 8, pp. 53972-53983, 2020.",doi: 10.1109/ACCESS.2020.2976908,"Abstract: As novel technologies continue to reshape the digital era, cyberattacks are also increasingly becoming more commonplace and sophisticated. Distributed denial of service (DDoS) attacks are, perhaps, the most prevalent and exponentially-growing attack, targeting the varied and emerging computational network infrastructures across the globe. This necessitates the design of an efficient and early detection of large-scale sophisticated DDoS attacks. Software defined networks (SDN) point to a promising solution, as a network paradigm which decouples the centralized control intelligence from the forwarding logic. In this work, a deep convolutional neural network (CNN) ensemble framework for efficient DDoS attack detection in SDNs is proposed. The proposed framework is evaluated on a current state-of-the-art Flow-based dataset under established benchmarks. Improved accuracy is demonstrated against existing related detection approaches.","keywords: {computer network security;convolutional neural nets;software defined networking;computational network;large-scale sophisticated DDoS attacks;software defined networks;network paradigm;deep convolutional neural network;deep CNN ensemble framework;efficient DDoS attack detection;digital era;service attacks;centralized control intelligence;Computer crime;Machine learning;Software;Anomaly detection;Feature extraction;Benchmark testing;Computer architecture;Software defined network (SDN);anomaly detection;distributed denial of service (DDoS);deep learning;deep convolutional neural network (CNN)},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9016053&isnumber=8948470,60,CNN,0.9693,SDN,,DDoS Attack Detection,KDD Cup 1999/CICIDS2017,,1,
"X. Zhou et al., ""Graph Convolutional Network Hashing,"" in IEEE Transactions on Cybernetics, vol. 50, no. 4, pp. 1460-1472, April 2020.",doi: 10.1109/TCYB.2018.2883970,"Abstract: Recently, graph-based hashing that learns similarity-preserving binary codes via an affinity graph has been extensively studied for large-scale image retrieval. However, most graph-based hashing methods resort to intractable binary quadratic programs, making them unscalable to massive data. In this paper, we propose a novel graph convolutional network-based hashing framework, dubbed GCNH, which directly carries out spectral convolution operations on both an image set and an affinity graph built over the set, naturally yielding similarity-preserving binary embedding. GCNH fundamentally differs from conventional graph hashing methods which adopt an affinity graph as the only learning guidance in an objective function to pursue the binary embedding. As the core ingredient of GCNH, we introduce an intuitive asymmetric graph convolutional (AGC) layer to simultaneously convolve the anchor graph, input data, and convolutional filters. By virtue of the AGC layer, GCNH well addresses the issues of scalability and out-of-sample extension when leveraging affinity graphs for hashing. As a use case of our GCNH, we particularly study the semisupervised hashing scenario in this paper. Comprehensive image retrieval evaluations on the CIFAR-10, NUS-WIDE, and ImageNet datasets demonstrate the consistent advantages of GCNH over the state-of-the-art methods given limited labeled data.","keywords: {binary codes;convolutional neural nets;file organisation;graph theory;image retrieval;learning (artificial intelligence);quadratic programming;affinity graph;similarity-preserving binary embedding;GCNH;intuitive asymmetric graph convolutional layer;anchor graph;semisupervised hashing scenario;graph convolutional network hashing;similarity-preserving binary codes;graph-based hashing methods;intractable binary quadratic programs;spectral convolution operations;graph convolutional network-based hashing;Binary codes;Convolutional codes;Semantics;Automatic generation control;Optimization;Training;Graph convolutional network (GCN);hashing;image retrieval;nearest neighbor search},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8576642&isnumber=9011772,61,CNN,,GCN,,,CIFAR-10/NUS-WIDE/ImageNet,,,
"F. Tung and G. Mori, ""Deep Neural Network Compression by In-Parallel Pruning-Quantization,"" in IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 42, no. 3, pp. 568-579, 1 March 2020.",doi: 10.1109/TPAMI.2018.2886192,"Abstract: Deep neural networks enable state-of-the-art accuracy on visual recognition tasks such as image classification and object detection. However, modern networks contain millions of learned connections, and the current trend is towards deeper and more densely connected architectures. This poses a challenge to the deployment of state-of-the-art networks on resource-constrained systems, such as smartphones or mobile robots. In general, a more efficient utilization of computation resources would assist in deployment scenarios from embedded platforms to computing clusters running ensembles of networks. In this paper, we propose a deep network compression algorithm that performs weight pruning and quantization jointly, and in parallel with fine-tuning. Our approach takes advantage of the complementary nature of pruning and quantization and recovers from premature pruning errors, which is not possible with two-stage approaches. In experiments on ImageNet, CLIP-Q (Compression Learning by In-Parallel Pruning-Quantization) improves the state-of-the-art in network compression on AlexNet, VGGNet, GoogLeNet, and ResNet. We additionally demonstrate that CLIP-Q is complementary to efficient network architecture design by compressing MobileNet and ShuffleNet, and that CLIP-Q generalizes beyond convolutional networks by compressing a memory network for visual question answering.","keywords: {computer vision;data compression;data visualisation;learning (artificial intelligence);neural net architecture;object recognition;question answering (information retrieval);deep neural network compression algorithm;in-parallel pruning-quantization;visual recognition;resource-constrained systems;computing clusters;weight pruning;network architecture;CLIP -Q;learning framework;visual question answering;computer vision;visualization;Quantization (signal);Image coding;Neural networks;Visualization;Training;Convolution;Network architecture;Deep learning;neural network compression;weight pruning;weight quantization;Bayesian optimization},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8573867&isnumber=8984605,62,CNN,,CLIP-Q,,CNN compression,COCO,,,
"X. Nie, M. Duan, H. Ding, B. Hu and E. K. Wong, ""Attention Mask R-CNN for Ship Detection and Segmentation From Remote Sensing Images,"" in IEEE Access, vol. 8, pp. 9325-9334, 2020.",doi: 10.1109/ACCESS.2020.2964540,"Abstract: In recent years, ship detection in satellite remote sensing images has become an important research topic. Most existing methods detect ships by using a rectangular bounding box but do not perform segmentation down to the pixel level. This paper proposes a ship detection and segmentation method based on an improved Mask R-CNN model. Our proposed method can accurately detect and segment ships at the pixel level. By adding a bottom-up structure to the FPN structure of Mask R-CNN, the path between the lower layers and the topmost layer is shortened, allowing the lower layer features to be more effectively utilized at the top layer. In the bottom-up structure, we use channel-wise attention to assign weights in each channel and use the spatial attention mechanism to assign a corresponding weight at each pixel in the feature maps. This allows the feature maps to respond better to the target's features. Using our method, the detection and segmentation mAPs increased from 70.6% and 62.0% to 76.1% and 65.8%, respectively.","keywords: {convolutional neural nets;geophysical image processing;image classification;image segmentation;object detection;remote sensing;ships;ship detection;satellite remote sensing images;pixel level;segmentation method;lower layer features;channel-wise attention;feature maps;improved mask R-CNN model;Marine vehicles;Feature extraction;Image segmentation;Remote sensing;Satellites;Deep learning;Object detection;Computer vision;object detection;object segmentation;remote sensing},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8951182&isnumber=8948470,63,R-CNN,0.761,Mask R-CNN/attention,,,Airbus ship,,1,
"X. Ouyang et al., ""Dual-Sampling Attention Network for Diagnosis of COVID-19 From Community Acquired Pneumonia,"" in IEEE Transactions on Medical Imaging, vol. 39, no. 8, pp. 2595-2605, Aug. 2020.",doi: 10.1109/TMI.2020.2995508,"Abstract: The coronavirus disease (COVID-19) is rapidly spreading all over the world, and has infected more than 1,436,000 people in more than 200 countries and territories as of April 9, 2020. Detecting COVID-19 at early stage is essential to deliver proper healthcare to the patients and also to protect the uninfected population. To this end, we develop a dual-sampling attention network to automatically diagnose COVID-19 from the community acquired pneumonia (CAP) in chest computed tomography (CT). In particular, we propose a novel online attention module with a 3D convolutional network (CNN) to focus on the infection regions in lungs when making decisions of diagnoses. Note that there exists imbalanced distribution of the sizes of the infection regions between COVID-19 and CAP, partially due to fast progress of COVID-19 after symptom onset. Therefore, we develop a dual-sampling strategy to mitigate the imbalanced learning. Our method is evaluated (to our best knowledge) upon the largest multi-center CT data for COVID-19 from 8 hospitals. In the training-validation stage, we collect 2186 CT scans from 1588 patients for a 5-fold cross-validation. In the testing stage, we employ another independent large-scale testing dataset including 2796 CT scans from 2057 patients. Results show that our algorithm can identify the COVID-19 images with the area under the receiver operating characteristic curve (AUC) value of 0.944, accuracy of 87.5%, sensitivity of 86.9%, specificity of 90.1%, and F1-score of 82.0%. With this performance, the proposed algorithm could potentially aid radiologists with COVID-19 diagnosis from CAP, especially in the early stage of the COVID-19 outbreak.","keywords: {computerised tomography;diseases;health care;image classification;learning (artificial intelligence);lung;medical computing;medical diagnostic computing;medical image processing;medical information systems;neural nets;patient diagnosis;patient treatment;dual-sampling attention network;infection regions;COVID-19 images;COVID-19 diagnosis;COVID-19 outbreak;Lung;Computed tomography;Diseases;Hospitals;Radiology;Image segmentation;COVID-19;COVID-19 Diagnosis;Online Attention;Explainability;Imbalanced Distribution;Dual Sampling Strategy;Algorithms;Betacoronavirus;Community-Acquired Infections;Coronavirus Infections;Deep Learning;Humans;Image Interpretation, Computer-Assisted;Pandemics;Pneumonia, Viral;ROC Curve;Radiography, Thoracic;Tomography, X-Ray Computed},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9095328&isnumber=9153182,64,CNN,0.875,3D CNN,,CT COVID19 detection,,,,1
"O. Ozdemir, R. L. Russell and A. A. Berlin, ""A 3D Probabilistic Deep Learning System for Detection and Diagnosis of Lung Cancer Using Low-Dose CT Scans,"" in IEEE Transactions on Medical Imaging, vol. 39, no. 5, pp. 1419-1429, May 2020.",doi: 10.1109/TMI.2019.2947595,"Abstract: We introduce a new computer aided detection and diagnosis system for lung cancer screening with low-dose CT scans that produces meaningful probability assessments. Our system is based entirely on 3D convolutional neural networks and achieves state-of-the-art performance for both lung nodule detection and malignancy classification tasks on the publicly available LUNA16 and Kaggle Data Science Bowl challenges. While nodule detection systems are typically designed and optimized on their own, we find that it is important to consider the coupling between detection and diagnosis components. Exploiting this coupling allows us to develop an end-to-end system that has higher and more robust performance and eliminates the need for a nodule detection false positive reduction stage. Furthermore, we characterize model uncertainty in our deep learning systems, a first for lung CT analysis, and show that we can use this to provide well-calibrated classification probabilities for both nodule detection and patient malignancy diagnosis. These calibrated probabilities informed by model uncertainty can be used for subsequent risk-based decision making towards diagnostic interventions or disease treatments, as we demonstrate using a probability-based patient referral strategy to further improve our results.","keywords: {cancer;computerised tomography;convolutional neural nets;decision making;diseases;image classification;learning (artificial intelligence);lung;medical image processing;computer aided detection;3D probabilistic deep learning system;probability-based patient referral strategy;patient malignancy diagnosis;classification probabilities;lung CT analysis;deep learning systems;end-to-end system;diagnosis components;nodule detection systems;Kaggle Data Science Bowl;malignancy classification tasks;lung nodule detection;low-dose CT scans;lung cancer screening;diagnosis system;Solid modeling;Lung;Three-dimensional displays;Cancer;Computed tomography;Deep learning;Uncertainty;Machine learning;artificial neural networks;medical diagnostic imaging;image segmentation;image classification},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8886352&isnumber=9084068,65,CNN,0.87 AUC,3D CNN,,Lung Cancer detection,LUNA16/,,,1
"S. K. Roy, G. Krishna, S. R. Dubey and B. B. Chaudhuri, ""HybridSN: Exploring 3-D–2-D CNN Feature Hierarchy for Hyperspectral Image Classification,"" in IEEE Geoscience and Remote Sensing Letters, vol. 17, no. 2, pp. 277-281, Feb. 2020.",doi: 10.1109/LGRS.2019.2918719,"Abstract: Hyperspectral image (HSI) classification is widely used for the analysis of remotely sensed images. Hyperspectral imagery includes varying bands of images. Convolutional neural network (CNN) is one of the most frequently used deep learning-based methods for visual data processing. The use of CNN for HSI classification is also visible in recent works. These approaches are mostly based on 2-D CNN. On the other hand, the HSI classification performance is highly dependent on both spatial and spectral information. Very few methods have used the 3-D-CNN because of increased computational complexity. This letter proposes a hybrid spectral CNN (HybridSN) for HSI classification. In general, the HybridSN is a spectral-spatial 3-D-CNN followed by spatial 2-D-CNN. The 3-D-CNN facilitates the joint spatial-spectral feature representation from a stack of spectral bands. The 2-D-CNN on top of the 3-D-CNN further learns more abstract-level spatial representation. Moreover, the use of hybrid CNNs reduces the complexity of the model compared to the use of 3-D-CNN alone. To test the performance of this hybrid approach, very rigorous HSI classification experiments are performed over Indian Pines, University of Pavia, and Salinas Scene remote sensing data sets. The results are compared with the state-of-the-art hand-crafted as well as end-to-end deep learning-based methods. A very satisfactory performance is obtained using the proposed HybridSN for HSI classification. The source code can be found at https://github.com/gokriznastic/HybridSN.","keywords: {convolutional neural nets;feature extraction;geophysical image processing;hyperspectral imaging;image classification;learning (artificial intelligence);remote sensing;hyperspectral image classification;remotely sensed images;hyperspectral imagery;frequently used deep learning-based methods;HSI classification performance;spatial information;spectral information;hybrid spectral CNN;HybridSN;2D-CNN;joint spatial-spectral feature representation;spectral bands;abstract-level spatial representation;rigorous HSI classification experiments;end-to-end deep learning-based methods;3-D-2-D;spectral-spatial 3D-CNN;Salinas scene remote sensing data sets;Kernel;Feature extraction;Hyperspectral imaging;Principal component analysis;Computational modeling;IP networks;2-D-convolutional neural network (CNN);3-D-CNN;deep learning;CNNs;hybrid spectral CNN (HybridSN);hyperspectral image (HSI) classification;remote sensing;spectral–spatial},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8736016&isnumber=8964504,66,CNN,,3D-2D hybrid CNN,,Hyperspectral images(HSI),,,1,
"G. Lin, F. Liu, A. Milan, C. Shen and I. Reid, ""RefineNet: Multi-Path Refinement Networks for Dense Prediction,"" in IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 42, no. 5, pp. 1228-1242, 1 May 2020.",doi: 10.1109/TPAMI.2019.2893630,"Abstract: Recently, very deep convolutional neural networks (CNNs) have shown outstanding performance in object recognition and have also been the first choice for dense prediction problems such as semantic segmentation and depth estimation. However, repeated subsampling operations like pooling or convolution striding in deep CNNs lead to a significant decrease in the initial image resolution. Here, we present RefineNet, a generic multi-path refinement network that explicitly exploits all the information available along the down-sampling process to enable high-resolution prediction using long-range residual connections. In this way, the deeper layers that capture high-level semantic features can be directly refined using fine-grained features from earlier convolutions. The individual components of RefineNet employ residual connections following the identity mapping mindset, which allows for effective end-to-end training. Further, we introduce chained residual pooling, which captures rich background context in an efficient manner. We carry out comprehensive experiments on semantic segmentation which is a dense classification problem and achieve good performance on seven public datasets. We further apply our method for depth estimation and demonstrate the effectiveness of our method on dense regression problems.","keywords: {convolutional neural nets;feature extraction;image classification;image resolution;image segmentation;object recognition;regression analysis;dense regression problems;dense classification problem;residual pooling;effective end-to-end training;RefineNet employ residual connections;fine-grained features;high-level semantic features;long-range residual connections;high-resolution prediction;multipath refinement network;initial image resolution;deep CNNs;depth estimation;semantic segmentation;dense prediction problems;object recognition;deep convolutional neural networks;Semantics;Estimation;Image segmentation;Task analysis;Convolution;Training;Visualization;Convolutional neural network;semantic segmentation;object parsing;human parsing;scene parsing;depth estimation;dense prediction},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8618363&isnumber=9055268,67,R-CNN,,CNN,https://github.com/guosheng/refinenet,,NYUDv2/SUN-RGBD/Cityscapes/ADE20K/parsing Person-Parts/PASCAL VOC 2012/PASCAL-Context,,1,
"K. Grm, W. J. Scheirer and V. Štruc, ""Face Hallucination Using Cascaded Super-Resolution and Identity Priors,"" in IEEE Transactions on Image Processing, vol. 29, pp. 2150-2165, 2020.",doi: 10.1109/TIP.2019.2945835,"Abstract: In this paper we address the problem of hallucinating high-resolution facial images from low-resolution inputs at high magnification factors. We approach this task with convolutional neural networks (CNNs) and propose a novel (deep) face hallucination model that incorporates identity priors into the learning procedure. The model consists of two main parts: i) a cascaded super-resolution network that upscales the low-resolution facial images, and ii) an ensemble of face recognition models that act as identity priors for the super-resolution network during training. Different from most competing super-resolution techniques that rely on a single model for upscaling (even with large magnification factors), our network uses a cascade of multiple SR models that progressively upscale the low-resolution images using steps of $2	imes $ . This characteristic allows us to apply supervision signals (target appearances) at different resolutions and incorporate identity constraints at multiple-scales. The proposed C-SRIP model (Cascaded Super Resolution with Identity Priors) is able to upscale (tiny) low-resolution images captured in unconstrained conditions and produce visually convincing results for diverse low-resolution inputs. We rigorously evaluate the proposed model on the Labeled Faces in the Wild (LFW), Helen and CelebA datasets and report superior performance compared to the existing state-of-the-art.","keywords: {convolutional neural nets;face recognition;image enhancement;image reconstruction;image resolution;learning (artificial intelligence);Labeled Faces;upscale low-resolution images;C-SRIP model;incorporate identity constraints;multiple SR models;super-resolution techniques;face recognition models;low-resolution facial images;super-resolution network;novel face hallucination model;convolutional neural networks;high magnification factors;low-resolution inputs;hallucinating high-resolution facial images;identity priors;Face;Training;Face recognition;Signal resolution;Task analysis;Face hallucination;deep learning;CNN;identity;Algorithms;Databases, Factual;Deep Learning;Face;Humans;Image Processing, Computer-Assisted;Neural Networks, Computer},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8866753&isnumber=8835130,68,CNN,,C-SRIP,,face generation,Wild (LFW)/Helen/CelebA,,1,
"Y. Sun, H. Wang, B. Xue, Y. Jin, G. G. Yen and M. Zhang, ""Surrogate-Assisted Evolutionary Deep Learning Using an End-to-End Random Forest-Based Performance Predictor,"" in IEEE Transactions on Evolutionary Computation, vol. 24, no. 2, pp. 350-364, April 2020.",doi: 10.1109/TEVC.2019.2924461,"Abstract: Convolutional neural networks (CNNs) have shown remarkable performance in various real-world applications. Unfortunately, the promising performance of CNNs can be achieved only when their architectures are optimally constructed. The architectures of state-of-the-art CNNs are typically handcrafted with extensive expertise in both CNNs and the investigated data, which consequently hampers the widespread adoption of CNNs for less experienced users. Evolutionary deep learning (EDL) is able to automatically design the best CNN architectures without much expertise. However, the existing EDL algorithms generally evaluate the fitness of a new architecture by training from scratch, resulting in the prohibitive computational cost even operated on high-performance computers. In this paper, an end-to-end offline performance predictor based on the random forest is proposed to accelerate the fitness evaluation in EDL. The proposed performance predictor shows the promising performance in term of the classification accuracy and the consumed computational resources when compared with 18 state-of-the-art peer competitors by integrating into an existing EDL algorithm as a case study. The proposed performance predictor is also compared with the other two representatives of existing performance predictors. The experimental results show the proposed performance predictor not only significantly speeds up the fitness evaluations but also achieves the best prediction among the peer performance predictors.","keywords: {convolutional neural nets;evolutionary computation;learning (artificial intelligence);offline performance predictor;surrogate-assisted evolutionary deep learning;peer performance predictors;fitness evaluation;EDL algorithm;CNN architectures;evolutionary deep learning;convolutional neural networks;end-to-end random forest-based performance predictor;Computer architecture;Training;Prediction algorithms;Optimization;Sociology;Statistics;Convolutional neural network (CNN);evolutionary deep learning (EDL);performance predictor;random forest;surrogate model},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8744404&isnumber=9051613,69,EDL,,E2EPP,,Evolutionary deep learning,,,1,
"W. Xia, G. Zheng, Y. Zhu, J. Zhang, J. Wang and A. P. Petropulu, ""A Deep Learning Framework for Optimization of MISO Downlink Beamforming,"" in IEEE Transactions on Communications, vol. 68, no. 3, pp. 1866-1880, March 2020.",doi: 10.1109/TCOMM.2019.2960361,"Abstract: Beamforming is an effective means to improve the quality of the received signals in multiuser multiple-input-single-output (MISO) systems. Traditionally, finding the optimal beamforming solution relies on iterative algorithms, which introduces high computational delay and is thus not suitable for real-time implementation. In this paper, we propose a deep learning framework for the optimization of downlink beamforming. In particular, the solution is obtained based on convolutional neural networks and exploitation of expert knowledge, such as the uplink-downlink duality and the known structure of optimal solutions. Using this framework, we construct three beamforming neural networks (BNNs) for three typical optimization problems, i.e., the signal-to-interference-plus-noise ratio (SINR) balancing problem, the power minimization problem, and the sum rate maximization problem. For the former two problems the BNNs adopt the supervised learning approach, while for the sum rate maximization problem a hybrid method of supervised and unsupervised learning is employed. Simulation results show that the BNNs can achieve near-optimal solutions to the SINR balancing and power minimization problems, and a performance close to that of the weighted minimum mean squared error algorithm for the sum rate maximization problem, while in all cases enjoy significantly reduced computational complexity. In summary, this work paves the way for fast realization of optimal beamforming in multiuser MISO systems.","keywords: {array signal processing;computational complexity;convolutional neural nets;iterative methods;learning (artificial intelligence);least mean squares methods;minimisation;MISO communication;optimisation;telecommunication computing;unsupervised learning;expert knowledge exploitation;weighted minimum mean squared error;multiuser MISO systems;power minimization problems;near-optimal solutions;unsupervised learning;supervised learning approach;sum rate maximization problem;power minimization problem;signal-to-interference-plus-noise ratio balancing problem;typical optimization problems;BNN;beamforming neural networks;uplink-downlink duality;convolutional neural networks;deep learning framework;high computational delay;iterative algorithms;optimal beamforming solution;multiuser multiple-input-single-output systems;received signals;MISO downlink beamforming;Array signal processing;Signal to noise ratio;Interference;Optimization;Minimization;Neural networks;MISO communication;Deep learning;beamforming;MISO;beamforming neural network},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8935405&isnumber=9039763,70,CNN,,beamforming NN,,multiple-input-singleoutput,,,,
"H. Chen, G. Hu, Z. Lei, Y. Chen, N. M. Robertson and S. Z. Li, ""Attention-Based Two-Stream Convolutional Networks for Face Spoofing Detection,"" in IEEE Transactions on Information Forensics and Security, vol. 15, pp. 578-593, 2020.",doi: 10.1109/TIFS.2019.2922241,"Abstract: Since the human face preserves the richest information for recognizing individuals, face recognition has been widely investigated and achieved great success in various applications in the past decades. However, face spoofing attacks (e.g., face video replay attack) remain a threat to modern face recognition systems. Though many effective methods have been proposed for anti-spoofing, we find that the performance of many existing methods is degraded by illuminations. It motivates us to develop illumination-invariant methods for anti-spoofing. In this paper, we propose a two-stream convolutional neural network (TSCNN), which works on two complementary spaces: RGB space (original imaging space) and multi-scale retinex (MSR) space (illumination-invariant space). Specifically, the RGB space contains the detailed facial textures, yet it is sensitive to illumination; MSR is invariant to illumination, yet it contains less detailed facial information. In addition, the MSR images can effectively capture the high-frequency information, which is discriminative for face spoofing detection. Images from two spaces are fed to the TSCNN to learn the discriminative features for anti-spoofing. To effectively fuse the features from two sources (RGB and MSR), we propose an attention-based fusion method, which can effectively capture the complementarity of two features. We evaluate the proposed framework on various databases, i.e., CASIA-FASD, REPLAY-ATTACK, and OULU, and achieve very competitive performance. To further verify the generalization capacity of the proposed strategies, we conduct cross-database experiments, and the results show the great effectiveness of our method.","keywords: {convolutional neural nets;face recognition;feature extraction;image colour analysis;image texture;face spoofing detection;human face;face spoofing attacks;face video replay attack;modern face recognition systems;anti-spoofing;illumination-invariant methods;two-stream convolutional neural network;complementary spaces;RGB space;original imaging space;multiscale retinex space;illumination-invariant space;detailed facial textures;MSR images;high-frequency information;attention-based fusion method;REPLAY-ATTACK;facial information;attention-based two-stream convolutional networks;Face;Feature extraction;Lighting;Face recognition;Fuses;Deep learning;Three-dimensional displays;Face spoofing;multi-scale retinex;deep learning;attention model;feature fusion},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8737949&isnumber=8833568,71,LSTM/CNN,,two-stream convolutional neural network,,Face Spoofing Detection,,,1,
"A. M. Shaker, M. Tantawi, H. A. Shedeed and M. F. Tolba, ""Generalization of Convolutional Neural Networks for ECG Classification Using Generative Adversarial Networks,"" in IEEE Access, vol. 8, pp. 35592-35605, 2020.",doi: 10.1109/ACCESS.2020.2974712,"Abstract: Electrocardiograms (ECGs) play a vital role in the clinical diagnosis of heart diseases. An ECG record of the heart signal over time can be used to discover numerous arrhythmias. Our work is based on 15 different classes from the MIT-BIH arrhythmia dataset. But the MIT-BIH dataset is strongly imbalanced, which impairs the accuracy of deep learning models. We propose a novel data-augmentation technique using generative adversarial networks (GANs) to restore the balance of the dataset. Two deep learning approaches-an end-to-end approach and a two-stage hierarchical approach-based on deep convolutional neural networks (CNNs) are used to eliminate hand-engineering features by combining feature extraction, feature reduction, and classification into a single learning method. Results show that augmenting the original imbalanced dataset with generated heartbeats by using the proposed techniques more effectively improves the performance of ECG classification than using the same techniques trained only with the original dataset. Furthermore, we demonstrate that augmenting the heartbeats using GANs outperforms other common data augmentation techniques. Our experiments with these techniques achieved overall accuracy above 98.0%, precision above 90.0%, specificity above 97.4%, and sensitivity above 97.7% after the dataset had been balanced using GANs, results that outperform several other ECG classification methods.","keywords: {convolutional neural nets;diseases;electrocardiography;feature extraction;learning (artificial intelligence);medical signal processing;pattern classification;signal classification;generative adversarial networks;heart diseases;heart signal;arrhythmias;MIT-BIH arrhythmia dataset;deep learning;deep convolutional neural networks;hand-engineering features;feature extraction;feature reduction;single learning method;heartbeats;data augmentation;ECG classification;Electrocardiography;Feature extraction;Heart beat;Heart rate variability;Gallium nitride;Machine learning;Generative adversarial networks;Class imbalance;convolution neural networks (CNNs);ECG classification;generative adversarial networks (GANs)},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9000871&isnumber=8948470,72,CNN,0.98,CNN/GAN,,ECG Classification,MIT-BIH,,,4
"T. Akilan, Q. J. Wu, A. Safaei, J. Huo and Y. Yang, ""A 3D CNN-LSTM-Based Image-to-Image Foreground Segmentation,"" in IEEE Transactions on Intelligent Transportation Systems, vol. 21, no. 3, pp. 959-971, March 2020.",doi: 10.1109/TITS.2019.2900426,"Abstract: The video-based separation of foreground (FG) and background (BG) has been widely studied due to its vital role in many applications, including intelligent transportation and video surveillance. Most of the existing algorithms are based on traditional computer vision techniques that perform pixel-level processing assuming that FG and BG possess distinct visual characteristics. Recently, state-of-the-art solutions exploit deep learning models targeted originally for image classification. Major drawbacks of such a strategy are the lacking delineation of FG regions due to missing temporal information as they segment the FG based on a single frame object detection strategy. To grapple with this issue, we excogitate a 3D convolutional neural network (3D CNN) with long short-term memory (LSTM) pipelines that harness seminal ideas, viz., fully convolutional networking, 3D transpose convolution, and residual feature flows. Thence, an FG-BG segmenter is implemented in an encoder-decoder fashion and trained on representative FG-BG segments. The model devises a strategy called double encoding and slow decoding, which fuses the learned spatio-temporal cues with appropriate feature maps both in the down-sampling and up-sampling paths for achieving well generalized FG object representation. Finally, from the Sigmoid confidence map generated by the 3D CNN-LSTM model, the FG is identified automatically by using Nobuyuki Otsu's method and an empirical global threshold. The analysis of experimental results via standard quantitative metrics on 16 benchmark datasets including both indoor and outdoor scenes validates that the proposed 3D CNN-LSTM achieves competitive performance in terms of figure of merit evaluated against prior and state-of-the-art methods. Besides, a failure analysis is conducted on 20 video sequences from the DAVIS 2016 dataset.","keywords: {computer vision;convolutional neural nets;feature extraction;image classification;image segmentation;image sequences;learning (artificial intelligence);object detection;recurrent neural nets;video signal processing;fully convolutional networking;3D transpose convolution;FG-BG segmenter;learned spatio-temporal cues;FG object representation;3D CNN-LSTM model;3D CNN-LSTM-based image-to-image foreground segmentation;video-based separation;intelligent transportation;video surveillance;computer vision techniques;pixel-level processing;visual characteristics;deep learning models;image classification;FG regions;single frame object detection strategy;3D convolutional neural network;FG-BG segments;long short-term memory pipelines;feature maps;down-sampling paths;up-sampling paths;Sigmoid confidence map;Three-dimensional displays;Solid modeling;Image segmentation;Visualization;Decoding;Encoding;Computational modeling;Deep learning;foreground-background segmentation;intelligent systems;LSTM;spatiotemporal cues},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8671459&isnumber=9018398,73,LSTM,,3D CNN-LSTM,,Foreground Segmentation,DAVIS 2016,,,
"Y. Jiang, J. Xu, B. Yang, J. Xu and J. Zhu, ""Image Inpainting Based on Generative Adversarial Networks,"" in IEEE Access, vol. 8, pp. 22884-22892, 2020.",doi: 10.1109/ACCESS.2020.2970169,"Abstract: Image inpainting aims to fill missing regions of a damaged image with plausibly synthesized content. Existing methods for image inpainting either fill the missing regions by borrowing information from surrounding areas or generating semantically coherent content from region context. They often produce ambiguous or semantically incoherent content when the missing region is large or with complex structures. In this paper, we present an approach for image inpainting. The completion model based on our proposed algorithm contains one generator, one global discriminator, and one local discriminator. The generator is responsible for inpainting the missing area, the global discriminator aims evaluating whether the repair result has global consistency, and the local discriminator is responsible for identifying whether the repair area is correct. The architecture of the generator is an auto-encoder. We use the skip-connection in the generator to improve the prediction power of the model. Also, we use Wasserstein GAN loss to ensure the stability of training. Experiments on CelebA dataset and LFW dataset demonstrate that our proposed model can deal with large-scale missing pixels and generate realistic completion results.","keywords: {convolutional neural nets;feature extraction;image matching;image restoration;image texture;local discriminator;global discriminator;image inpainting;generative adversarial networks;missing image regions;repair area;autoencoder;Wasserstein GAN loss;image features;convolution neural networks;patch-match method;texture information;Generators;Generative adversarial networks;Decoding;Training;Gallium nitride;Image edge detection;Neural networks;AutoEncoder;image inpainting;skip-connection;stable training;wasserstein GAN},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8974211&isnumber=8948470,74,GAN,,GAN,,Image Inpainting,CelebA/LFW,,,
"T. Ahmad, H. Mao, L. Lin and G. Tang, ""Action Recognition Using Attention-Joints Graph Convolutional Neural Networks,"" in IEEE Access, vol. 8, pp. 305-313, 2020.",doi: 10.1109/ACCESS.2019.2961770,"Abstract: Human skeleton contains significant information about actions, therefore, it is quite intuitive to incorporate skeletons in human action recognition. Human skeleton resembles to a graph where body joints and bones mimic to graph nodes and edges. This resemblance of human skeleton to graph structure is the main motivation to apply graph convolutional neural network for human action recognition. Results show that the discriminant contribution of different joints is not equal for different actions. Therefore, we propose to use attention-joints that correspond to joints significantly contributing to the specific actions. Features corresponding to only these attention-joints are computed and assigned as node features of the graph. In our method, node features (also termed as attention-joint features) include the i) distances of attention-joints from the center-of-gravity of human body, ii) distances between adjacent attention-joints and iii) joints flow features. The proposed method gives a simple but more efficient representation of skeleton sequences by concatenating more relative distances and relative coordinates to other joints. The proposed methodology has been evaluated on single image Stanford 40-Actions dataset, as well as on temporal skeleton-based action recognition PKU-MDD and NTU-RGBD datasets. Results show that this framework outperforms existing state-of-the-art methods.","keywords: {bone;convolutional neural nets;feature extraction;graph theory;image motion analysis;image representation;image sequences;human action recognition;human skeleton;body joints;graph nodes;graph structure;node features;attention-joint features;human body;adjacent attention-joints;joints flow features;skeleton sequences;single image Stanford 40-Actions dataset;temporal skeleton-based action recognition PKU-MDD;attention-joints graph convolutional neural networks;Convolution;Convolutional neural networks;Joints;Videos;Image edge detection;Human action recognition;attention-joints;graph convolutional neural network},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8939357&isnumber=8948470,75,GNN,,CNN/GNN,,Pose Estimation,PKU-MDD/NTU-RGBD,,2,
"K. Xia, J. Huang and H. Wang, ""LSTM-CNN Architecture for Human Activity Recognition,"" in IEEE Access, vol. 8, pp. 56855-56866, 2020.",doi: 10.1109/ACCESS.2020.2982225,"Abstract: In the past years, traditional pattern recognition methods have made great progress. However, these methods rely heavily on manual feature extraction, which may hinder the generalization model performance. With the increasing popularity and success of deep learning methods, using these techniques to recognize human actions in mobile and wearable computing scenarios has attracted widespread attention. In this paper, a deep neural network that combines convolutional layers with long short-term memory (LSTM) was proposed. This model could extract activity features automatically and classify them with a few model parameters. LSTM is a variant of the recurrent neural network (RNN), which is more suitable for processing temporal sequences. In the proposed architecture, the raw data collected by mobile sensors was fed into a two-layer LSTM followed by convolutional layers. In addition, a global average pooling layer (GAP) was applied to replace the fully connected layer after convolution for reducing model parameters. Moreover, a batch normalization layer (BN) was added after the GAP layer to speed up the convergence, and obvious results were achieved. The model performance was evaluated on three public datasets (UCI, WISDM, and OPPORTUNITY). Finally, the overall accuracy of the model in the UCI-HAR dataset is 95.78%, in the WISDM dataset is 95.85%, and in the OPPORTUNITY dataset is 92.63%. The results show that the proposed model has higher robustness and better activity detection capability than some of the reported results. It can not only adaptively extract activity features, but also has fewer parameters and higher accuracy.","keywords: {feature extraction;learning (artificial intelligence);pattern recognition;recurrent neural nets;wearable computers;WISDM dataset;OPPORTUNITY dataset;activity detection capability;UCI-HAR dataset;public datasets;GAP layer;batch normalization layer;fully connected layer;global average pooling layer;two-layer LSTM;mobile sensors;raw data;temporal sequences;recurrent neural network;activity features;short-term memory;convolutional layers;deep neural network;wearable computing scenarios;mobile computing scenarios;human actions;deep learning methods;generalization model performance;manual feature extraction;pattern recognition methods;human activity recognition;LSTM-CNN architecture;Feature extraction;Activity recognition;Acceleration;Deep learning;Sensor phenomena and characterization;Accelerometers;Human activity recognition;convolution;long short-term memory;mobile sensors},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9043535&isnumber=8948470,76,LSTM/CNN,.9578/.9585/.9263,LSTM/CNN,,Pose Estimation,UCI-HAR/WISDM/OPPORTUNITY,,2,
"A. Essien and C. Giannetti, ""A Deep Learning Model for Smart Manufacturing Using Convolutional LSTM Neural Network Autoencoders,"" in IEEE Transactions on Industrial Informatics, vol. 16, no. 9, pp. 6069-6078, Sept. 2020.",doi: 10.1109/TII.2020.2967556,"Abstract: Time-series forecasting is applied to many areas of smart factories, including machine health monitoring, predictive maintenance, and production scheduling. In smart factories, machine speed prediction can be used to dynamically adjust production processes based on different system conditions, optimize production throughput, and minimize energy consumption. However, making accurate data-driven machine speed forecasts is challenging. Given the complex nature of industrial manufacturing process data, predictive models that are robust to noise and can capture the temporal and spatial distributions of input time-series signals are prerequisites for accurate forecasting. Motivated by recent deep learning studies in smart manufacturing, in this article, we propose an end-to-end model for multistep machine speed prediction. The model comprises a deep convolutional LSTM encoder-decoder architecture. Extensive empirical analyses using real-world data obtained from a metal packaging plant in the United Kingdom demonstrate the value of the proposed method when compared with the state-of-the-art predictive models.","keywords: {convolutional neural nets;intelligent manufacturing systems;learning (artificial intelligence);manufacturing processes;production engineering computing;production facilities;recurrent neural nets;time series;smart manufacturing;convolutional LSTM neural network autoencoders;time-series forecasting;smart factories;machine health monitoring;predictive maintenance;production scheduling;industrial manufacturing process data;temporal distributions;spatial distributions;multistep machine speed prediction;deep convolutional LSTM encoder-decoder architecture;data-driven machine speed forecasts;Forecasting;Convolution;Smart manufacturing;Predictive models;Logic gates;Manufacturing processes;Convolutional long short-term memory (ConvLSTM);deep learning (DL);industry 4.0;stacked autoencoders;time-series forecasting},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8967003&isnumber=9106618,77,CNN/LSTM,,CNN/LSTM,,Time-series forecasting,,,,
"A. Masood et al., ""Cloud-Based Automated Clinical Decision Support System for Detection and Diagnosis of Lung Cancer in Chest CT,"" in IEEE Journal of Translational Engineering in Health and Medicine, vol. 8, pp. 1-13, 2020, Art no. 4300113.",doi: 10.1109/JTEHM.2019.2955458,"Abstract: Lung cancer is a major cause for cancer-related deaths. The detection of pulmonary cancer in the early stages can highly increase survival rate. Manual delineation of lung nodules by radiologists is a tedious task. We developed a novel computer-aided decision support system for lung nodule detection based on a 3D Deep Convolutional Neural Network (3DDCNN) for assisting the radiologists. Our decision support system provides a second opinion to the radiologists in lung cancer diagnostic decision making. In order to leverage 3-dimensional information from Computed Tomography (CT) scans, we applied median intensity projection and multi-Region Proposal Network (mRPN) for automatic selection of potential region-of-interests. Our Computer Aided Diagnosis (CAD) system has been trained and validated using LUNA16, ANODE09, and LIDC-IDR datasets; the experiments demonstrate the superior performance of our system, attaining sensitivity, specificity, AUROC, accuracy, of 98.4%, 92%, 96% and 98.51% with 2.1 FPs per scan. We integrated cloud computing, trained and validated our Cloud-Based 3DDCNN on the datasets provided by Shanghai Sixth People's Hospital, as well as LUNA16, ANODE09, and LIDC-IDR. Our system outperformed the state-of-the-art systems and obtained an impressive 98.7% sensitivity at 1.97 FPs per scan. This shows the potentials of deep learning, in combination with cloud computing, for accurate and efficient lung nodule detection via CT imaging, which could help doctors and radiologists in treating lung cancer patients.","keywords: {cancer;cloud computing;computerised tomography;convolutional neural nets;decision support systems;diagnostic radiography;feature extraction;image classification;image reconstruction;image segmentation;learning (artificial intelligence);lung;medical image processing;patient diagnosis;tumours;LIDC-IDR dataset;ANODE09 dataset;cloud-based 3DDCNN;multiregion proposal network;computer-aided decision support system;pulmonary cancer;cancer-related deaths;clinical decision support system;lung cancer patients;lung nodule detection;integrated cloud computing;LUNA16 dataset;computer aided diagnosis system;potential region-of-interests;computed tomography scans;3-dimensional information;lung cancer diagnostic decision making;radiologists;3D deep convolutional neural network;Cancer;Lung;Computed tomography;Training;Solid modeling;Cloud computing;Machine learning;Computer-aided diagnosis;nodule detection;cloud computing;computed tomography;lung cancer},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8922769&isnumber=8943243,78,CNN,0.9851,3D CNN,,Lung Cancer detection,Shanghai Sixth People's Hospital/LUNA16/ANODE09/LIDC-IDR.,,,1
"C. Li et al., ""An Underwater Image Enhancement Benchmark Dataset and Beyond,"" in IEEE Transactions on Image Processing, vol. 29, pp. 4376-4389, 2020.",doi: 10.1109/TIP.2019.2955241,"Abstract: Underwater image enhancement has been attracting much attention due to its significance in marine engineering and aquatic robotics. Numerous underwater image enhancement algorithms have been proposed in the last few years. However, these algorithms are mainly evaluated using either synthetic datasets or few selected real-world images. It is thus unclear how these algorithms would perform on images acquired in the wild and how we could gauge the progress in the field. To bridge this gap, we present the first comprehensive perceptual study and analysis of underwater image enhancement using large-scale real-world images. In this paper, we construct an Underwater Image Enhancement Benchmark (UIEB) including 950 real-world underwater images, 890 of which have the corresponding reference images. We treat the rest 60 underwater images which cannot obtain satisfactory reference images as challenging data. Using this dataset, we conduct a comprehensive study of the state-of-the-art underwater image enhancement algorithms qualitatively and quantitatively. In addition, we propose an underwater image enhancement network (called Water-Net) trained on this benchmark as a baseline, which indicates the generalization of the proposed UIEB for training Convolutional Neural Networks (CNNs). The benchmark evaluations and the proposed Water-Net demonstrate the performance and limitations of state-of-the-art algorithms, which shed light on future research in underwater image enhancement. The dataset and code are available at https://li-chongyi.github.io/proj_benchmark.html.","keywords: {convolutional neural nets;image enhancement;learning (artificial intelligence);marine engineering;object detection;statistical analysis;CNN;convolutional neural networks;Water-Net;UIEB;underwater image enhancement benchmark dataset;satisfactory reference images;reference images;real-world underwater images;underwater image enhancement algorithms;underwater image enhancement network;Image enhancement;Convolutional neural networks;Deep learning;Image restoration;Object detection;Statistical analysis;Underwater technology;Underwater image enhancement;real-world underwater images;comprehensive evaluation;deep learning},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8917818&isnumber=8835130,79,CNN,,UIEB,https://li-chongyi.github.io/proj_benchmark.html,Underwater Image Enhancement,https://li-chongyi.github.io/proj_benchmark.html,,,
"X. Xu and H. Liu, ""ECG Heartbeat Classification Using Convolutional Neural Networks,"" in IEEE Access, vol. 8, pp. 8614-8619, 2020.",doi: 10.1109/ACCESS.2020.2964749,"Abstract: Electrocardiogram (ECG) data recorded by Holter monitors are extremely hard to analyze manually. Therefore, it is necessary to automatically analyze and categorize each heartbeat using a computer-aid method. Because convolutional neural networks (CNNs) can classify ECG signals automatically without trivial manual feature extractions, they have received extensive attention. However, it is anticipated that improving the existing CNN classifiers might provide better overall accuracy, sensitivity, positive predictivity, etc. In this study, we proposed a CNN based ECG heartbeat classification method. Based on the MIT-BIH arrhythmia database, our proposed method achieved a sensitivity of 99.2% and positive predictivity of 99.4% in VEB detection; a sensitivity of 97.5% and positive predictivity of 99.1% in SVEB detection; and an overall accuracy of 99.43%. Our proposed system can be directly implemented on wearable devices to monitor long-term ECG data.","keywords: {convolutional neural nets;electrocardiography;medical signal detection;signal classification;positive predictivity;long-term ECG data;convolutional neural networks;electrocardiogram data;Holter monitors;computer-aid method;ECG signals;CNN classifiers;MIT-BIH arrhythmia database;CNN based ECG heartbeat classification method;SVEB detection;Heart beat;Training;Electrocardiography;Neurons;Convolution;Databases;Convolutional neural networks;Heartbeats;Holter;convolutional neural networks;MIT-BIH arrhythmia database;electrocardiogram signals},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8952723&isnumber=8948470,80,CNN,0.9943,CNN,,ECG Heartbeat Classification,,,,4
"S. Ma, X. Zhang, C. Jia, Z. Zhao, S. Wang and S. Wang, ""Image and Video Compression With Neural Networks: A Review,"" in IEEE Transactions on Circuits and Systems for Video Technology, vol. 30, no. 6, pp. 1683-1698, June 2020.",doi: 10.1109/TCSVT.2019.2910119,"Abstract: In recent years, the image and video coding technologies have advanced by leaps and bounds. However, due to the popularization of image and video acquisition devices, the growth rate of image and video data is far beyond the improvement of the compression ratio. In particular, it has been widely recognized that there are increasing challenges of pursuing further coding performance improvement within the traditional hybrid coding framework. Deep convolution neural network which makes the neural network resurge in recent years and has achieved great success in both artificial intelligent and signal processing fields, also provides a novel and promising solution for image and video compression. In this paper, we provide a systematic, comprehensive and up-to-date review of neural network-based image and video compression techniques. The evolution and development of neural network-based compression methodologies are introduced for images and video respectively. More specifically, the cutting-edge video coding techniques by leveraging deep learning and HEVC framework are presented and discussed, which promote the state-of-the-art video coding performance substantially. Moreover, the end-to-end image and video coding frameworks based on neural networks are also reviewed, revealing interesting explorations on next generation image and video coding frameworks/standards. The most significant research works on the image and video coding related topics using neural networks are highlighted, and future trends are also envisioned. In particular, the joint compression on semantic and visual information is tentatively explored to formulate high efficiency signal representation structure for both human vision and machine vision, which are the two dominant signal receptors in the age of artificial intelligence.","keywords: {computer vision;convolutional neural nets;data compression;learning (artificial intelligence);signal representation;video coding;end-to-end image coding;cutting-edge video coding;neural network-based compression methodologies;neural network-based image;convolution neural network;hybrid coding framework;Image coding;Biological neural networks;Video coding;Video compression;Redundancy;Transform coding;Neural network;deep learning;CNN;image compression;video coding},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8693636&isnumber=9108324,81,CNN,,HEVC,,Image and Video Compression,,,,
"F. Aziz, A. Ul Haq, S. Ahmad, Y. Mahmoud, M. Jalal and U. Ali, ""A Novel Convolutional Neural Network-Based Approach for Fault Classification in Photovoltaic Arrays,"" in IEEE Access, vol. 8, pp. 41889-41904, 2020.",doi: 10.1109/ACCESS.2020.2977116,"Abstract: Fault diagnosis in photovoltaic (PV) arrays is essential in enhancing power output as well as the useful life span of a PV system. Severe faults such as Partial Shading (PS) and high impedance faults, low location mismatch, and the presence of Maximum Power Point Tracking (MPPT) make fault detection challenging in harsh environmental conditions. In this regard, there have been several attempts made by various researchers to identify PV array faults. However, most of the previous work has focused on fault detection and classification in only a few faulty scenarios. This paper presents a novel approach that utilizes deep two-dimensional (2-D) Convolutional Neural Networks (CNN) to extract features from 2-D scalograms generated from PV system data in order to effectively detect and classify PV system faults. An in-depth quantitative evaluation of the proposed approach is presented and compared with previous classification methods for PV array faults - both classical machine learning based and deep learning based. Unlike contemporary work, five different faulty cases (including faults in PS - on which no work has been done before in the machine learning domain) have been considered in our study, along with the incorporation of MPPT. We generate a consistent dataset over which to compare ours and previous approaches, to make for the first (to the best of our knowledge) comprehensive and meaningful comparative evaluation of fault diagnosis. It is observed that the proposed method involving fine-tuned pre-trained CNN outperforms existing techniques, achieving a high fault detection accuracy of 73.53%. Our study also highlights the importance of representative and discriminative features to classify faults (as opposed to the use of raw data), especially in the noisy scenario, where our method achieves the best performance of 70.45%. We believe that our work will serve to guide future research in PV system fault diagnosis.","keywords: {convolutional neural nets;fault diagnosis;feature extraction;learning (artificial intelligence);maximum power point trackers;pattern classification;photovoltaic power systems;power engineering computing;power generation faults;solar cell arrays;MPPT;high fault detection accuracy;PV system fault diagnosis;convolutional neural network-based approach;fault classification;photovoltaic arrays;power output;useful life span;severe faults;high impedance faults;low location mismatch;maximum power point tracking;harsh environmental conditions;convolutional neural networks;PV system data;PV system faults;classification methods;PV array faults;deep learning;machine learning domain;Circuit faults;Fault detection;Fault diagnosis;Machine learning;Impedance;Maximum power point trackers;Feature extraction;Photovoltaic array;maximum power point tracking;fault classification;convolutional neural network;scalograms;transfer learning},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9018018&isnumber=8948470,82,R-CNN,0.73,CNN,,Photovoltaic Arrays Classification,,,,
"S. Zhai, D. Shang, S. Wang and S. Dong, ""DF-SSD: An Improved SSD Object Detection Algorithm Based on DenseNet and Feature Fusion,"" in IEEE Access, vol. 8, pp. 24344-24357, 2020.",doi: 10.1109/ACCESS.2020.2971026,"Abstract: In view of the lack of feature complementarity between the feature layers of Single Shot MultiBox Detector (SSD) and the weak detection ability of SSD for small objects, we propose an improved SSD object detection algorithm based on Dense Convolutional Network (DenseNet) and feature fusion, which is called DF-SSD. On the basis of SSD, we design the feature extraction network DenseNet-S-32-1 with reference to the dense connection of DenseNet, and replace the original backbone network VGG-16 of SSD with DenseNet-S-32-1 to enhance the feature extraction ability of the model. In the part of multi-scale detection, a fusion mechanism of multi-scale feature layers is introduced to organically combine low-level visual features and high-level semantic features in the network structure. Finally, a residual block is established before the object prediction to further improve the model performance. We train the DF-SSD model from scratch. The experimental results show that our model DF-SSD with 300 × 300 input achieves 81.4% mAP, 79.0% mAP, and 29.5% mAP on PASCAL VOC 2007, VOC 2012, and MS COCO datasets, respectively. Compared with SSD, the detection accuracy of DF-SSD on VOC 2007 is improved by 3.1% mAP. DF-SSD requires only 1/2 parameters to SSD and 1/9 parameters to Faster RCNN. We inject more semantic information into DF-SSD, which makes it have advanced detection effect on small objects and objects with specific relationships.","keywords: {computer vision;convolutional neural nets;feature extraction;image fusion;learning (artificial intelligence);object detection;feature extraction network;DenseNet-S-32-1;weak detection ability;feature complementarity;improved SSD object detection algorithm;DF-SSD model;high-level semantic features;low-level visual features;multiscale feature layers;multiscale detection;feature extraction ability;feature fusion;Feature extraction;Object detection;Semantics;Convolution;Detectors;Task analysis;Adaptation models;DenseNet;feature fusion;multi-scale object detection;SSD},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8978787&isnumber=8948470,83,R-CNN,0.814,Dense CNN,,Object Detection,COCO,,1,
"W. Zhang, K. Ma, J. Yan, D. Deng and Z. Wang, ""Blind Image Quality Assessment Using a Deep Bilinear Convolutional Neural Network,"" in IEEE Transactions on Circuits and Systems for Video Technology, vol. 30, no. 1, pp. 36-47, Jan. 2020.",doi: 10.1109/TCSVT.2018.2886771,"Abstract: We propose a deep bilinear model for blind image quality assessment that works for both synthetically and authentically distorted images. Our model constitutes two streams of deep convolutional neural networks (CNNs), specializing in two distortion scenarios separately. For synthetic distortions, we first pre-train a CNN to classify the distortion type and the level of an input image, whose ground truth label is readily available at a large scale. For authentic distortions, we make use of a pre-train CNN (VGG-16) for the image classification task. The two feature sets are bilinearly pooled into one representation for a final quality prediction. We fine-tune the whole network on the target databases using a variant of stochastic gradient descent. The extensive experimental results show that the proposed model achieves state-of-the-art performance on both synthetic and authentic IQA databases. Furthermore, we verify the generalizability of our method on the large-scale Waterloo Exploration Database, and demonstrate its competitiveness using the group maximum differentiation competition methodology.","keywords: {convolutional neural nets;feature extraction;gradient methods;image classification;image representation;learning (artificial intelligence);natural scenes;stochastic processes;visual databases;blind image quality assessment;deep bilinear convolutional neural network;authentically distorted images;deep convolutional neural networks;distortion scenarios;synthetic distortions;distortion type;input image;authentic distortions;pre-train CNN;image classification task;final quality prediction;synthetic IQA databases;authentic IQA databases;Databases;Degradation;Nonlinear distortion;Image quality;Image coding;Convolutional neural networks;Blind image quality assessment;convolutional neural networks;bilinear pooling;gMAD competition;perceptual image processing},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8576582&isnumber=8951039,84,CNN,,biCNN,,dehazing,Waterloo Exploration Database,,2,
"A. M. Elbir and A. K. Papazafeiropoulos, ""Hybrid Precoding for Multiuser Millimeter Wave Massive MIMO Systems: A Deep Learning Approach,"" in IEEE Transactions on Vehicular Technology, vol. 69, no. 1, pp. 552-563, Jan. 2020.",doi: 10.1109/TVT.2019.2951501,"Abstract: In multi-user millimeter wave (mmWave) multiple-input-multiple-output (MIMO) systems, hybrid precoding is a crucial task to lower the complexity and cost while achieving a sufficient sum-rate. Previous works on hybrid precoding were usually based on optimization or greedy approaches. These methods either provide higher complexity or have sub-optimum performance. Moreover, the performance of these methods mostly relies on the quality of the channel data. In this work, we propose a deep learning (DL) framework to improve the performance and provide less computation time as compared to conventional techniques. In fact, we design a convolutional neural network for MIMO (CNN-MIMO) that accepts as input an imperfect channel matrix and gives the analog precoder and combiners at the output. The procedure includes two main stages. First, we develop an exhaustive search algorithm to select the analog precoder and combiners from a predefined codebook maximizing the achievable sum-rate. Then, the selected precoder and combiners are used as output labels in the training stage of CNN-MIMO where the input-output pairs are obtained. We evaluate the performance of the proposed method through numerous and extensive simulations and show that the proposed DL framework outperforms conventional techniques. Overall, CNN-MIMO provides a robust hybrid precoding scheme in the presence of imperfections regarding the channel matrix. On top of this, the proposed approach exhibits less computation time with comparison to the optimization and codebook based approaches.","keywords: {convolutional neural nets;learning (artificial intelligence);matrix algebra;millimetre wave communication;MIMO communication;multiuser channels;network coding;optimisation;precoding;telecommunication computing;wireless channels;multiple-input-multiple-output systems;multiuser mmWave MIMO systems;CNN-MIMO;output labels;predefined codebook;combiner selection;exhaustive search algorithm;output combining;analog precoder selection;imperfect channel matrix;convolutional neural network;computation time;channel data quality;sum-rate;deep learning;massive MIMO systems;multiuser millimeter wave systems;hybrid precoding;Precoding;MIMO communication;Radio frequency;Training;Antennas;Phase shifters;Channel estimation;Hybrid precoding;mmWave systems;multi-user MIMO transmission;deep learning;convolutional neural networks},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8890805&isnumber=8961346,85,CNN,,CNN-MIMO,,Multiuser Millimeter Wave Massive MIMO Systems,,FPGA,,
"B. Du et al., ""Deep Irregular Convolutional Residual LSTM for Urban Traffic Passenger Flows Prediction,"" in IEEE Transactions on Intelligent Transportation Systems, vol. 21, no. 3, pp. 972-985, March 2020.",doi: 10.1109/TITS.2019.2900481,"Abstract: Urban traffic passenger flows prediction is practically important to facilitate many real applications including transportation management and public safety. Recently, deep learning based approaches are proposed to learn the spatio-temporal characteristics of the traffic passenger flows. However, it is still very challenging to handle some complex factors such as hybrid transportation lines, mixed traffic, transfer stations, and some extreme weathers. Considering the multi-channel and irregularity properties of urban traffic passenger flows in different transportation lines, a more efficient and fine-grained deep spatio-temporal feature learning model is necessary. In this paper, we propose a deep irregular convolutional residual LSTM network model called DST-ICRL for urban traffic passenger flows prediction. We first model the passenger flows among different traffic lines in a transportation network into multi-channel matrices analogous to the RGB pixel matrices of an image. Then, we propose a deep learning framework that integrates irregular convolutional residential network and LSTM units to learn the spatial-temporal feature representations. To fully utilize the historical passenger flows, we sample both the short-term and long-term historical traffic data, which can capture the periodicity and trend of the traffic passenger flows. In addition, we also fuse other external factors further to facilitate a real-time prediction. We conduct extensive experiments on different types of traffic passenger flows datasets including subway, taxi and bus flows in Beijing as well as bike flows in New York. The results show that the proposed DST-ICRL significantly outperforms both traditional and deep learning based urban traffic passenger flows prediction methods.","keywords: {automobiles;convolutional neural nets;learning (artificial intelligence);recurrent neural nets;road traffic;traffic engineering computing;transportation;real-time prediction;transportation network;DST-ICRL;urban traffic passenger flow prediction;deep irregular convolutional residual LSTM network model;fine-grained deep spatio-temporal feature;spatio-temporal feature;deep learning based approaches;bus flows;taxi;traffic passenger flows;long-term historical traffic data;irregular convolutional residential network;traffic lines;Predictive models;Deep learning;Market research;Data models;Convolution;Public transportation;Traffic passenger flows prediction;irregular convolutional neural network;LSTM;importance sampling;urban computing},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8664646&isnumber=9018398,86,LSTM,,CNN-LSTM,https://github.com/RingBDStack/Deep-Convolutional-Residual-LSTM,,"BIKENYC, SUBWAYBJ, BUSBJ, TAXIBJ",,,
"L. Li et al., ""Semi-Supervised Image Dehazing,"" in IEEE Transactions on Image Processing, vol. 29, pp. 2766-2779, 2020.",doi: 10.1109/TIP.2019.2952690,"Abstract: We present an effective semi-supervised learning algorithm for single image dehazing. The proposed algorithm applies a deep Convolutional Neural Network (CNN) containing a supervised learning branch and an unsupervised learning branch. In the supervised branch, the deep neural network is constrained by the supervised loss functions, which are mean squared, perceptual, and adversarial losses. In the unsupervised branch, we exploit the properties of clean images via sparsity of dark channel and gradient priors to constrain the network. We train the proposed network on both the synthetic data and real-world images in an end-to-end manner. Our analysis shows that the proposed semi-supervised learning algorithm is not limited to synthetic training datasets and can be generalized well to real-world images. Extensive experimental results demonstrate that the proposed algorithm performs favorably against the state-of-the-art single image dehazing algorithms on both benchmark datasets and real-world images.","keywords: {convolutional neural nets;image restoration;supervised learning;unsupervised learning;semisupervised image dehazing;semisupervised learning algorithm;deep convolutional neural network;unsupervised learning branch;supervised loss functions;mean squared losses;perceptual losses;adversarial losses;clean images;real-world images;deep CNN;dark channel;Training;Semisupervised learning;Image color analysis;Image restoration;Convolution;Atmospheric modeling;Deep learning;Image dehazing;deep learning;semi-supervised learning},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8902220&isnumber=8835130,87,CNN,,CNN,,dehazing,"SOTS, RTTS",,,
"B. K. Savaş and Y. Becerikli, ""Real Time Driver Fatigue Detection System Based on Multi-Task ConNN,"" in IEEE Access, vol. 8, pp. 12491-12498, 2020.",doi: 10.1109/ACCESS.2020.2963960,"Abstract: Changes and progresses in information technologies have played an important role in the development of intelligent vehicle systems in recent years. Driver fatigue is an important factor in vehicle accidents. For this reason, traffic accidents involving driver fatigue and driver carelessness have been followed by researchers. In this article, a Multi-tasking Convulational Neural Network (ConNN*) model is proposed to detect driver drowsiness/fatigue. Eye and mouth characteristics are utilized for driver's behavior model. Changes to these characteristics are used to monitor driver fatigue. With the proposed Multi-task ConNN model, unlike the studies in the literature, both mouth and eye information are classified into a single model at the same time. Driver fatigue is determined by calculating eyes' closure duration/Percentage of eye closure (PERCLOS) and yawning frequency/frequency of mouth (FOM). In this study, the fatigue degree of the driver is divided into 3 classes. The proposed model achieved 98.81% fatigue detection on YawdDD and NthuDDD dataset. The success of the model is presented comparatively.","keywords: {behavioural sciences computing;convolutional neural nets;face recognition;road accidents;road safety;road vehicles;traffic engineering computing;NthuDDD dataset;YawdDD dataset;frequency of mouth;yawning frequency;percentage of eye closure;PERCLOS;multitasking convulational neural network model;driver carelessness;intelligent vehicle systems;time driver fatigue detection system;fatigue degree;Multitask ConNN model;Fatigue;Vehicles;Videos;Mouth;Face;Accidents;Neural networks;Convolutional neural network;driver fatigue detection;PERCLOS;FOM},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8949469&isnumber=8948470,88,CNN,0.988,MT-CNN,,Driver Fatigue Detection,"YawDD, NTHU-DDD",,2,
"S. S. Sarwar, A. Ankit and K. Roy, ""Incremental Learning in Deep Convolutional Neural Networks Using Partial Network Sharing,"" in IEEE Access, vol. 8, pp. 4615-4628, 2020.",doi: 10.1109/ACCESS.2019.2963056,"Abstract: Deep convolutional neural network (DCNN) based supervised learning is a widely practiced approach for large-scale image classification. However, retraining these large networks to accommodate new, previously unseen data demands high computational time and energy requirements. Also, previously seen training samples may not be available at the time of retraining. We propose an efficient training methodology and incrementally growing DCNN to learn new tasks while sharing part of the base network. Our proposed methodology is inspired by transfer learning techniques, although it does not forget previously learned tasks. An updated network, for learning new set of classes, is formed using previously learned convolutional layers (shared from initial part of base network) with addition of few newly added convolutional kernels included in the later layers of the network. We employed a `clone-and-branch' technique with calibration, which allows the network to learn new tasks (containing classes with similar features as old tasks) one after another without any performance loss in old tasks. We evaluated the proposed scheme on several recognition applications. The classification accuracy achieved by our approach is comparable to the regular incremental learning approach (where networks are updated with new training samples only, without any network sharing), while achieving energy efficiency, reduction in storage requirements, memory access and training time.","keywords: {convolutional neural nets;image classification;learning (artificial intelligence);learned convolutional layers;convolutional kernels;regular incremental learning approach;deep convolutional neural networks;partial network sharing;DCNN;supervised learning;large-scale image classification;transfer learning techniques;clone-and-branch technique;Task analysis;Training;Memory management;Convolutional neural networks;Energy consumption;Feature extraction;Training data;Incremental learning;catastrophic forgetting;lifelong learning;energy-efficient learning;network sharing},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8945358&isnumber=8948470,89,CNN,0.7423,CNN,,Incremental Learning,ImageNet,,1,
"Y. Ma, Y. Cao, S. Vrudhula and J. Seo, ""Performance Modeling for CNN Inference Accelerators on FPGA,"" in IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, vol. 39, no. 4, pp. 843-856, April 2020.",doi: 10.1109/TCAD.2019.2897634,"Abstract: The recently reported successes of convolutional neural networks (CNNs) in many areas have generated wide interest in the development of field-programmable gate array (FPGA)-based accelerators. To achieve high performance and energy efficiency, an FPGA-based accelerator must fully utilize the limited computation resources and minimize the data communication and memory access, both of which are impacted and constrained by a variety of design parameters, e.g., the degree and dimension of parallelism, the size of on-chip buffers, the bandwidth of the external memory, and many more. The large design space of the accelerator makes it impractical to search for the optimal design in the implementation phase. To address this problem, a performance model is described to estimate the performance and resource utilization of an FPGA implementation. By this means, the performance bottleneck and design bound can be identified and the optimal design option can be explored early in the design phase. The proposed performance model is validated using a variety of CNN algorithms comparing the results with on-board test results on two different FPGAs.","keywords: {convolutional neural nets;energy conservation;field programmable gate arrays;inference mechanisms;integrated circuit modelling;low-power electronics;on-chip buffers;CNN algorithms;resource utilization;memory access;data communication;computation resources;FPGA-based accelerator;energy efficiency;field-programmable gate array-based accelerators;convolutional neural networks;CNN inference accelerators;Random access memory;Field programmable gate arrays;Computational modeling;Convolution;System-on-chip;Delays;Kernel;Analytical modeling;convolutional neural networks (CNNs);field-programmable gate array (FPGA)},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8634939&isnumber=9042369,90,CNN,,CNN,,FPGA perfomence modeling,,FPGA,,
"Y. Zhang, S. Liu, C. Dong, X. Zhang and Y. Yuan, ""Multiple Cycle-in-Cycle Generative Adversarial Networks for Unsupervised Image Super-Resolution,"" in IEEE Transactions on Image Processing, vol. 29, pp. 1101-1112, 2020.",doi: 10.1109/TIP.2019.2938347,"Abstract: With the help of convolutional neural networks (CNN), the single image super-resolution problem has been widely studied. Most of these CNN based methods focus on learning a model to map a low-resolution (LR) image to a highresolution (HR) image, where the LR image is downsampled from the HR image with a known model. However, in a more general case when the process of the down-sampling is unknown and the LR input is degraded by noises and blurring, it is difficult to acquire the LR and HR image pairs for traditional supervised learning. Inspired by the recent unsupervised imagestyle translation applications using unpaired data, we propose a multiple Cycle-in-Cycle network structure to deal with the more general case using multiple generative adversarial networks (GAN) as the basis components. The first network cycle aims at mapping the noisy and blurry LR input to a noise-free LR space, then a new cycle with a well-trained x2 network model is orderly introduced to super-resolve the intermediate output of the former cycle. The number of total cycles depends on the different up-sampling factors (x2, x4, x8). Finally, all modules are trained in an end-to-end manner to get the desired HR output. Quantitative indexes and qualitative results show that our proposed method achieves comparable performance with the state-of-the-art supervised models.","keywords: {convolutional neural nets;image resolution;image restoration;learning (artificial intelligence);image blurring;supervised learning;multiple generative adversarial networks;noise-free LR space;cycle-in-cycle generative adversarial networks;unsupervised image super-resolution;convolutional neural networks;multiple cycle-in-cycle network structure;Training;Kernel;Degradation;Interpolation;Deep learning;Super resolution;unsupervised learning;generative adversarial networks},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8825849&isnumber=8835130,91,GAN,,MCinCGAN,,,DIV2K,,,
"F. Jiang et al., ""Deep Learning Based Multi-Channel Intelligent Attack Detection for Data Security,"" in IEEE Transactions on Sustainable Computing, vol. 5, no. 2, pp. 204-212, 1 April-June 2020.",doi: 10.1109/TSUSC.2018.2793284,"Abstract: Deep learning methods, e.g., convolutional neural networks (CNNs) and Recurrent Neural Networks (RNNs), have achieved great success in image processing and natural language processing especially in high level vision applications such as recognition and understanding. However, it is rarely used to solve information security problems such as attack detection studied in this paper. Here, we move forward a step and propose a novel multi-channel intelligent attack detection method based on long short term memory recurrent neural networks (LSTM-RNNs). To achieve high detection rate, data preprocessing, feature abstraction, and multi-channel training and detection are seamlessly integrated into an end-to-end detection framework. Data preprocessing provides high-quality data for subsequent processing, then different types of features are extracted from the processed data. Multi-channel processing is used to generate classifiers by training neural networks with different types of features, which preserve attack features of input vectors and classify the attack from normal data. With the results of the classifier's attack detection, we introduce a voting algorithm to decide whether the input data is an attack or not. Experimental results validate that the proposed attack detection method greatly outperforms several attack detection methods that use feature detection and Bayesian or SVM classifiers.","keywords: {computer vision;convolutional neural nets;learning (artificial intelligence);natural language processing;recurrent neural nets;security of data;support vector machines;vectors;LSTM-RNNs;data preprocessing;feature abstraction;end-to-end detection framework;high-quality data;multichannel processing;attack features;normal data;feature detection;data security;convolutional neural networks;image processing;natural language processing;high level vision applications;information security problems;long short term memory recurrent neural networks;multichannel intelligent attack detection method;voting algorithm;input vectors;Feature extraction;Training;Recurrent neural networks;Machine learning;Intrusion detection;Data preprocessing;Deep learning;attack detection;data security;sustainable computing;recurrent neural networks (RNNs)},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8259310&isnumber=9113128,92,LSTM,0.9894,LSTM/CNN,,Attack Detection for Data Security,,,,
"M. P. Akhter, Z. Jiangbin, I. R. Naqvi, M. Abdelmajeed, A. Mehmood and M. T. Sadiq, ""Document-Level Text Classification Using Single-Layer Multisize Filters Convolutional Neural Network,"" in IEEE Access, vol. 8, pp. 42689-42707, 2020.",doi: 10.1109/ACCESS.2020.2976744,"Abstract: The rapid growth of electronic documents are causing problems like unstructured data that need more time and effort to search a relevant document. Text Document Classification (TDC) has a great significance in information processing and retrieval where unstructured documents are organized into pre-defined classes. Urdu is the most favorite research language in South Asian languages because of its complex morphology, unique features, and lack of linguistic resources like standard datasets. As compared to short text, like sentiment analysis, long text classification needs more time and effort because of large vocabulary, more noise, and redundant information. Machine Learning (ML) and Deep Learning (DL) models have been widely used in text processing. Despite the major limitations of ML models, like learn directed features, these are the favorite methods for Urdu TDC. To the best of our knowledge, it is the first study of Urdu TDC using DL model. In this paper, we design a large multi-purpose and multi-format dataset that contain more than ten thousand documents organize into six classes. We use Single-layer Multisize Filters Convolutional Neural Network (SMFCNN) for classification and compare its performance with sixteen ML baseline models on three imbalanced datasets of various sizes. Further, we analyze the effects of preprocessing methods on SMFCNN performance. SMFCNN outperformed the baseline classifiers and achieved 95.4%, 91.8%, and 93.3% scores of accuracy on medium, large and small size dataset respectively. The designed dataset would be publically and freely available in different formats for future research in Urdu text processing.","keywords: {convolutional neural nets;learning (artificial intelligence);natural language processing;pattern classification;text analysis;word processing;deep learning models;single-layer multisize filters convolutional neural network;document-level text classification;Urdu text processing;designed dataset;small size dataset;sixteen ML baseline models;thousand documents;multiformat dataset;Urdu TDC;favorite methods;learn directed features;ML models;redundant information;short text;standard datasets;South Asian languages;pre-defined classes;unstructured documents;information processing;text document classification;relevant document;unstructured data;electronic documents;Feature extraction;Text categorization;Convolutional neural networks;Machine learning;Text processing;Training;Analytical models;Convolutional neural network;deep learning;machine learning;natural language processing;text document classification;Urdu text classification},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9016261&isnumber=8948470,93,CNN,0.93,CNN,,Text Classification,,,1,
"Y. Yu, C. Wu, T. Zhao, K. Wang and L. He, ""OPU: An FPGA-Based Overlay Processor for Convolutional Neural Networks,"" in IEEE Transactions on Very Large Scale Integration (VLSI) Systems, vol. 28, no. 1, pp. 35-47, Jan. 2020.",doi: 10.1109/TVLSI.2019.2939726,"Abstract: Field-programmable gate array (FPGA) provides rich parallel computing resources with high energy efficiency, making it ideal for deep convolutional neural network (CNN) acceleration. In recent years, automatic compilers have been developed to generate network-specific FPGA accelerators. However, with more cascading deep CNN algorithms adapted by various complicated tasks, reconfiguration of FPGA devices during runtime becomes unavoidable when network-specific accelerators are employed. Such reconfiguration can be difficult for edge devices. Moreover, network-specific accelerator means regeneration of RTL code and physical implementation whenever the network is updated. This is not easy for CNN end users. In this article, we propose a domain-specific FPGA overlay processor, named OPU to accelerate CNN networks. It offers software-like programmability for CNN end users, as CNN algorithms are automatically compiled into executable codes, which are loaded and executed by OPU without reconfiguration of FPGA for switch or update of CNN networks. Our OPU instructions have complicated functions with variable runtimes but a uniform length. The granularity of instruction is optimized to provide good performance and sufficient flexibility, while reducing complexity to develop microarchitecture and compiler. Experiments show that OPU can achieve an average of 91% runtime multiplication and accumulation unit (MAC) efficiency (RME) among nine different networks. Moreover, for VGG and YOLO networks, OPU outperforms automatically compiled network-specific accelerators in the literature. In addition, OPU shows 5.35× better power efficiency compared with Titan Xp. For a real-time cascaded CNN networks scenario, OPU is 2.9× faster compared with edge computing GPU Jetson Tx2, which has a similar amount of computing resources.","keywords: {convolutional neural nets;field programmable gate arrays;OPU;FPGA-based overlay processor;field-programmable gate array;deep convolutional neural network acceleration;network-specific FPGA accelerators;cascading deep CNN algorithms;domain-specific FPGA overlay processor;CNN networks;parallel computing resources;multiplication and accumulation unit;edge computing GPU Jetson;Field programmable gate arrays;Runtime;Computer architecture;Microarchitecture;Acceleration;Convolutional neural networks;Parallel processing;Convolutional neural network (CNN) overlay processor;field-programmable gate array (FPGA) acceleration;hardware–software codesign},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8863128&isnumber=8945454,94,,,,,OPU FPGA processor,,FPGA,,
"M. Opitz, G. Waltner, H. Possegger and H. Bischof, ""Deep Metric Learning with BIER: Boosting Independent Embeddings Robustly,"" in IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 42, no. 2, pp. 276-290, 1 Feb. 2020.",doi: 10.1109/TPAMI.2018.2848925,"Abstract: Learning similarity functions between image pairs with deep neural networks yields highly correlated activations of embeddings. In this work, we show how to improve the robustness of such embeddings by exploiting the independence within ensembles. To this end, we divide the last embedding layer of a deep network into an embedding ensemble and formulate the task of training this ensemble as an online gradient boosting problem. Each learner receives a reweighted training sample from the previous learners. Further, we propose two loss functions which increase the diversity in our ensemble. These loss functions can be applied either for weight initialization or during training. Together, our contributions leverage large embedding sizes more effectively by significantly reducing correlation of the embedding and consequently increase retrieval accuracy of the embedding. Our method works with any differentiable loss function and does not introduce any additional parameters during test time. We evaluate our metric learning method on image retrieval tasks and show that it improves over state-of-the-art methods on the CUB-200-2011, Cars-196, Stanford Online Products, In-Shop Clothes Retrieval and VehicleID datasets. Therefore, our findings suggest that by dividing deep networks at the end into several smaller and diverse networks, we can significantly reduce overfitting.","keywords: {convolutional neural nets;gradient methods;image retrieval;learning (artificial intelligence);deep metric learning;boosting independent embeddings robustly;similarity functions;deep neural networks;embedding layer;deep network;embedding ensemble;online gradient boosting problem;reweighted training sample;differentiable loss function;metric learning method;image retrieval tasks;correlated activations;BIER;image pairs;deep convolutional neural network;Measurement;Training;Boosting;Correlation;Feature extraction;Robustness;Task analysis;Metric learning;deep learning;convolutional neural network},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8395046&isnumber=8952810,95,CNN,,BIER,,,,learning approch,,
"A. Sayal, S. S. T. Nibhanupudi, S. Fathima and J. P. Kulkarni, ""A 12.08-TOPS/W All-Digital Time-Domain CNN Engine Using Bi-Directional Memory Delay Lines for Energy Efficient Edge Computing,"" in IEEE Journal of Solid-State Circuits, vol. 55, no. 1, pp. 60-75, Jan. 2020.",doi: 10.1109/JSSC.2019.2939888,"Abstract: In this article, we demonstrate an energy efficient convolutional neural network (CNN) engine by performing multiply-and-accumulate (MAC) operations in the time domain. The multi-bit inputs are compactly represented as a single pulse width encoded input. This translates into reduced switching capacitance (CDYN), compared to baseline digital implementation, and can enable low power neural network computing in an edge device. The time-domain CNN engine employs a novel bi-directional memory delay line (MDL) unit to perform signed accumulation of input and weight products. The proposed MDL design leverages standard digital circuits and does not require any capacitors and complex analog-to-digital converters (ADCs) to realize the convolution operation, thereby enabling easy scaling across the process technology nodes. Four speed-up modes and a configurable MDL length are supported to address throughput versus accuracy trade-off of the time-domain computing approach. Delay calibration units have been accommodated to mitigate the process variation induced delay mismatch among concurrently operating MDL units. The proposed time-domain MDL design implements a LeNet-5 CNN engine in a commercial 40-nm CMOS process achieving an energy efficiency of 12.08 TOPS/W, a throughput of 0.365 GOPS at 537 mV in the 16× speed-up mode. 40-nm CMOS test-chip measurements over 100 MNIST images show 97% classification accuracy. Simulation results over the entire 10 000 MNIST validation dataset images taking into account the circuit non-ideal effects of the MDL-based time-domain approach show a classification accuracy of 98.42%. The test-chip is operational down to the near-threshold voltage (up to 375 mV) while maintaining the classification accuracy over 90% in the 1× speed-up mode. Furthermore, two methods of scaling MDLs to multi-bit weights are proposed. Simulation results for 1000-class AlexNet over 50 000 ImageNet validation dataset images show classification accuracy loss within 1% when compared with software implementation. The proposed MDL based time-domain approach performing 1-bit/8-bit weight and 8-bit input MAC operations when compared with the corresponding baseline digital implementations shows 2.09× -2.32× higher energy efficiency and 2.22×-3.45× smaller area.","keywords: {CMOS digital integrated circuits;convolutional neural nets;delay lines;distributed processing;low-power electronics;neural chips;semiconductor storage;low power neural network computing;time-domain computing approach;process variation induced delay mismatch;all-digital time-domain CNN engine;bidirectional memory delay lines;energy efficient edge computing;energy efficient convolutional neural network engine;MAC operations;multiply-and-accumulate operations;reduced switching capacitance;CMOS process;CMOS process;voltage 537.0 mV;word length 8 bit;Time-domain analysis;Convolution;Capacitors;Engines;Bidirectional control;Feature extraction;Random access memory;AlexNet;bi-directional memory delay line (MDL);binary neural network;convolutional neural network (CNN);energy efficient edge computing;ImageNet;LeNet-5;MNIST;multiply-and-accumulate (MAC);time-domain processing},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8867969&isnumber=8944135,96,CNN,,CNN,,,ImageNet,CNN engine,,
"R. Hwang, M. Peng, C. Huang, P. Lin and V. Nguyen, ""An Unsupervised Deep Learning Model for Early Network Traffic Anomaly Detection,"" in IEEE Access, vol. 8, pp. 30387-30399, 2020.",doi: 10.1109/ACCESS.2020.2973023,"Abstract: Various attacks have emerged as the major threats to the success of a connected world like the Internet of Things (IoT), in which billions of devices interact with each other to facilitate human life. By exploiting the vulnerabilities of cheap and insecure devices such as IP cameras, an attacker can create hundreds of thousands of zombie devices and then launch massive volume attacks to take down any target. For example, in 2016, a record large-scale DDoS attack launched by millions of Mirai-injected IP cameras and smart printers blocked the accessibility of several high-profile websites. To date, the state-of-the-art defense systems against such attacks rely mostly on pre-defined features extracted from the entire flows or signatures. The feature definitions are manual, and it would be too late to block a malicious flow after extracting the flow features. In this work, we present an effective anomaly traffic detection mechanism, namely D-PACK, which consists of a Convolutional Neural Network (CNN) and an unsupervised deep learning model (e.g., Autoencoder) for auto-profiling the traffic patterns and filtering abnormal traffic. Notably, D-PACK inspects only the first few bytes of the first few packets in each flow for early detection. Our experimental results show that, by examining just the first two packets in each flow, D-PACK still performs with nearly 100% accuracy, while features an extremely low false-positive rate, e.g., 0.83%. The design can inspire the emerging efforts towards online anomaly detection systems that feature reducing the volume of processed packets and blocking malicious flows in time.","keywords: {computer network security;convolutional neural nets;feature extraction;IP networks;telecommunication traffic;unsupervised learning;Web sites;connected world;insecure devices;zombie devices;massive volume attacks;large-scale DDoS attack;Mirai-injected IP cameras;smart printers;state-of-the-art defense systems;predefined features;feature definitions;malicious flow;effective anomaly traffic detection mechanism;convolutional neural networks;unsupervised deep learning model;traffic patterns;online anomaly detection systems;processed packets;D-PACK;abnormal traffic filtering;autoprofiling;high-profile Web sites;early network traffic anomaly detection;Anomaly detection;Feature extraction;Deep learning;Internet of Things;Buildings;Telecommunication traffic;IP networks;IoT security;anomaly detection;convolutional neural network;autoendcoder;online DL-based anomaly detection},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8990084&isnumber=8948470,97,CNN,0.9996,CNN,,Intrusion Detection,USTC-TFC 2016,,,
"J. Park, J. Jang, G. Lee, H. Koh, C. Kim and T. W. Kim, ""A Time Domain Artificial Intelligence Radar System Using 33-GHz Direct Sampling for Hand Gesture Recognition,"" in IEEE Journal of Solid-State Circuits, vol. 55, no. 4, pp. 879-888, April 2020.",doi: 10.1109/JSSC.2020.2967547,"Abstract: This article introduces a time-domain-based artificial intelligence (AI) radar system for gesture recognition using 33-GS/s direct sampling technique. High-speed sampling using a time-extension method allows AI learning to be applied to a time-domain radar signal reflecting information on both dynamic and static gestures, and thus can recognize not only dynamic but also static gestures. The Vernier clock generators and high-speed active samplers applied with the time-extension technique makes sampling at 33 GS/s possible. A 1-D convolutional neural network and long short-term memory are employed for both static and dynamic gestures and recognition rates of 93.2% and 90.5% are obtained, respectively. The radar system is implemented using a 65-nm CMOS process with a power consumption of 95 mW.","keywords: {clocks;convolutional neural nets;gesture recognition;learning (artificial intelligence);radar computing;radar signal processing;recurrent neural nets;signal sampling;time-domain analysis;dynamic gestures;recognition rates;time domain artificial intelligence radar system;hand gesture recognition;time-domain-based artificial intelligence radar system;direct sampling technique;high-speed sampling;time-extension method;time-domain radar signal;static gestures;time-extension technique;AI learning;Vernier clock generators;1-D convolutional neural network;long short-term memory;power 95.0 mW;Radar;Clocks;Timing;Artificial intelligence;Time-domain analysis;Capacitors;Generators;Artificial intelligence (AI) radar;gesture recognition;high-speed sampling;impulse radar ultra-wideband (IR-UWB);radar;sampler;time-to-digital converter (TDC);time-extension;transceiver;wireless sensing},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8976307&isnumber=9048008,98,CNN,0.905,CNN,,Hand Gesture Recognition,,signal,1,
"A. Loquercio, E. Kaufmann, R. Ranftl, A. Dosovitskiy, V. Koltun and D. Scaramuzza, ""Deep Drone Racing: From Simulation to Reality With Domain Randomization,"" in IEEE Transactions on Robotics, vol. 36, no. 1, pp. 1-14, Feb. 2020.",doi: 10.1109/TRO.2019.2942989,"Abstract: Dynamically changing environments, unreliable state estimation, and operation under severe resource constraints are fundamental challenges that limit the deployment of small autonomous drones. We address these challenges in the context of autonomous, vision-based drone racing in dynamic environments. A racing drone must traverse a track with possibly moving gates at high speed. We enable this functionality by combining the performance of a state-of-the-art planning and control system with the perceptual awareness of a convolutional neural network. The resulting modular system is both platform independent and domain independent: it is trained in simulation and deployed on a physical quadrotor without any fine-tuning. The abundance of simulated data, generated via domain randomization, makes our system robust to changes of illumination and gate appearance. To the best of our knowledge, our approach is the first to demonstrate zero-shot sim-to-real transfer on the task of agile drone flight. We extensively test the precision and robustness of our system, both in simulation and on a physical platform, and show significant improvements over the state of the art.","keywords: {autonomous aerial vehicles;collision avoidance;convolutional neural nets;helicopters;robot vision;perceptual awareness;convolutional neural network;resulting modular system;physical quadrotor;domain randomization;illumination;gate appearance;zero-shot sim-to-real transfer;agile drone flight;physical platform;deep drone racing;unreliable state estimation;severe resource constraints;autonomous drones;autonomous vision-based drone;dynamic environments;racing drone;control system;Drones;Navigation;Trajectory;State estimation;Training;Robot sensing systems;Drone racing;learning agile flight;learning for control},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8877728&isnumber=8984601,99,CNN,.16 loss,DroNet,,Imporving drone vision,,,2,
"H. Korkalainen et al., ""Accurate Deep Learning-Based Sleep Staging in a Clinical Population With Suspected Obstructive Sleep Apnea,"" in IEEE Journal of Biomedical and Health Informatics, vol. 24, no. 7, pp. 2073-2081, July 2020.",doi: 10.1109/JBHI.2019.2951346,"Abstract: The identification of sleep stages is essential in the diagnostics of sleep disorders, among which obstructive sleep apnea (OSA) is one of the most prevalent. However, manual scoring of sleep stages is time-consuming, subjective, and costly. To overcome this shortcoming, we aimed to develop an accurate deep learning approach for automatic classification of sleep stages and to study the effect of OSA severity on the classification accuracy. Overnight polysomnographic recordings from a public dataset of healthy individuals (Sleep-EDF, n = 153) and from a clinical dataset (n = 891) of patients with suspected OSA were used to develop a combined convolutional and long short-term memory neural network. On the public dataset, the model achieved sleep staging accuracy of 83.7% (κ = 0.77) with a single frontal EEG channel and 83.9% (κ = 0.78) when supplemented with EOG. For the clinical dataset, the model achieved accuracies of 82.9% (κ = 0.77) and 83.8% (κ = 0.78) with a single EEG channel and two channels (EEG+EOG), respectively. The sleep staging accuracy decreased with increasing OSA severity. The single-channel accuracy ranged from 84.5% (κ = 0.79) for individuals without OSA diagnosis to 76.5% (κ = 0.68) for patients with severe OSA. In conclusion, deep learning enables automatic sleep staging for suspected OSA patients with high accuracy and expectedly, the accuracy decreased with increasing OSA severity. Furthermore, the accuracies achieved in the public dataset were superior to previously published state-of-the-art methods. Adding an EOG channel did not significantly increase the accuracy. The automatic, single-channel-based sleep staging could enable easy, accurate, and cost-efficient integration of EEG recording into diagnostic ambulatory recordings.","keywords: {convolutional neural nets;electroencephalography;electro-oculography;learning (artificial intelligence);medical disorders;medical signal processing;neurophysiology;signal classification;sleep;clinical dataset;OSA severity;single-channel accuracy;automatic sleep staging;suspected OSA patients;public dataset;single-channel-based sleep staging;sleep disorders;suspected obstructive sleep apnea;deep learning-based sleep staging;automatic classification;overnight polysomnographic recordings;convolutional neural network;long short-term memory neural network;single frontal EEG channel;EOG;diagnostic ambulatory recordings;Sleep apnea;Electroencephalography;Hospitals;Training;Deep learning;Deep learning;Electroencephalography;Obstructive sleep apnea;Recurrent neural network;Sleep staging},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8936942&isnumber=9130988,100,LSTM,0.83,CNN/LSTM,,Sleep Staging,"Sleep-EDF, ",,1,
"L. Wang, ""Fast Training Algorithms for Deep Convolutional Fuzzy Systems With Application to Stock Index Prediction,"" in IEEE Transactions on Fuzzy Systems, vol. 28, no. 7, pp. 1301-1314, July 2020.",doi: 10.1109/TFUZZ.2019.2930488,"Abstract: A deep convolutional fuzzy system (DCFS) on a high-dimensional input space is a multilayer connection of many low-dimensional fuzzy systems, where the input variables to the low-dimensional fuzzy systems are selected through a moving window across the input spaces of the layers. To design the DCFS based on an input-output data pairs, we propose a bottom-up layer-by-layer scheme. Specifically, by viewing each of the first-layer fuzzy systems as a weak estimator of the output based only on a very small portion of the input variables, we design these fuzzy systems using the Wang-Mendel method. After the first-layer fuzzy systems are designed, we pass the data through the first layer to form a new dataset and design the second-layer fuzzy systems based on this new dataset in the same way as designing the first-layer fuzzy systems. Repeating this process layer-by-layer, we design the whole DCFS. We also propose a DCFS with parameter sharing to save memory and computation. We apply the DCFS models to predict a synthetic chaotic plus random time-series and the real Hang Seng Index of the Hong Kong stock market.","keywords: {chaos;convolutional neural nets;financial data processing;fuzzy set theory;random processes;stock markets;time series;second-layer fuzzy systems;bottom-up layer-by-layer scheme;stock index prediction;chaotic plus random time-series;first-layer fuzzy systems;input-output data pairs;DCFS;deep convolutional fuzzy system;Fuzzy systems;Training;Input variables;Windows;Prediction algorithms;Computational modeling;Fuzzy sets;Deep learning;hierarchical fuzzy systems;stock index prediction;Wang–Mendel (WM) method},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8788632&isnumber=9130783,101,fuzzy,,DCFS,,,,,,
"J. Zhang, Z. Xie, J. Sun, X. Zou and J. Wang, ""A Cascaded R-CNN With Multiscale Attention and Imbalanced Samples for Traffic Sign Detection,"" in IEEE Access, vol. 8, pp. 29742-29754, 2020.",doi: 10.1109/ACCESS.2020.2972338,"Abstract: In recent years, the deep learning is applied to the field of traffic sign detection methods which achieves excellent performance. However, there are two main challenges in traffic sign detection to be solve urgently. For one thing, some traffic signs of small size are more difficult to detect than those of large size so that the small traffic signs are undetected. For another, some false signs are always detected because of interferences caused by the illumination variation, bad weather and some signs similar to the true traffic signs. Therefore, to solve the undetection and false detection, we first propose a cascaded R-CNN to obtain the multiscale features in pyramids. Each layer of the cascaded network except the first layer fuses the output bounding box of the previous one layer for joint training. This method contributes to the traffic sign detection. Then, we propose a multiscale attention method to obtain the weighted multiscale features by dot-product and softmax, which is summed to fine the features to highlight the traffic sign features and improve the accuracy of the traffic sign detection. Finally, we increase the number of difficult negative samples for dataset balance and data augmentation in the training to relieve the interference by complex environment and similar false traffic signs. The data augment method expands the German traffic sign training dataset by simulation of complex environment changes. We conduct numerous experiments to verify the effectiveness of our proposed algorithm. The accuracy and recall rate of our method are 98.7% and 90.5% in GTSDB, 99.7% and 83.62% in CCTSDB and 98.9% and 85.6% in Lisa dataset respectively.","keywords: {convolutional neural nets;feature extraction;image recognition;learning (artificial intelligence);object detection;object recognition;traffic engineering computing;traffic sign detection methods;false signs;false detection;traffic sign features;German traffic sign training dataset;false traffic signs;cascaded R-CNN;multiscale attention;Feature extraction;Object detection;Image color analysis;Deep learning;Detection algorithms;Training;Shape;Traffic sign detection;convolutional neural network;attention;object detection;Multiscale},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8986614&isnumber=8948470,102,R-CNN,0.98,,,Traffic Sign Detection,"GTSDB, CCTSDB",,,
"M. D. Bah, A. Hafiane and R. Canals, ""CRowNet: Deep Network for Crop Row Detection in UAV Images,"" in IEEE Access, vol. 8, pp. 5189-5200, 2020.",doi: 10.1109/ACCESS.2019.2960873,"Abstract: Nowadays, the development of robots and smart tractors for the automation of sowing, harvesting, weeding etc. is transforming agriculture. Farmers are moving from an agriculture where everything is applied uniformly to a much more targeted farming. This new kind of farming is commonly referred to as precision agriculture. However for autonomous guidance of these agricultural machines and even sometimes for weed detection an accurate detection of crop rows is required. In this paper we propose a new method called CRowNet which uses a convolutional neural network (CNN) and the Hough transform to detect crop rows in images taken by an unmanned aerial vehicle (UAV). The method consists of a model formed with SegNet (S-SegNet) and a CNN based Hough transform (HoughCNet). The performance of the proposed method was quantitatively compared to traditional approaches and it showed the best and most robust result. A good crop row detection rate of 93.58% was obtained with an IoU score per crop row above 70%. Moreover the model trained on a given crop field is able to detect rows in images of different types of crops.","keywords: {agricultural machinery;agriculture;autonomous aerial vehicles;convolutional neural nets;crops;Hough transforms;learning (artificial intelligence);object detection;robot vision;CRowNet;deep network;UAV images;smart tractors;farming;precision agriculture;agricultural machines;weed detection;convolutional neural network;CNN;Hough transform;crop row detection;S-SegNet;unmanned aerial vehicle images;HoughCNet;Agriculture;Transforms;Strips;Unmanned aerial vehicles;Image segmentation;Robots;Soil;Crop row detection;deep learning;weed detection;Hough transform;image processing},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8936895&isnumber=8948470,103,SegNet/CNN,.7 recall 0.9 presision,CRowNet:,,Crop Row Detection in UAV Images,,,,
"M. Khodayar, S. Mohammadi, M. E. Khodayar, J. Wang and G. Liu, ""Convolutional Graph Autoencoder: A Generative Deep Neural Network for Probabilistic Spatio-Temporal Solar Irradiance Forecasting,"" in IEEE Transactions on Sustainable Energy, vol. 11, no. 2, pp. 571-583, April 2020.",doi: 10.1109/TSTE.2019.2897688,"Abstract: Machine learning on graphs is an important and omnipresent task for a vast variety of applications including anomaly detection and dynamic network analysis. In this paper, a deep generative model is introduced to capture continuous probability densities corresponding to the nodes of an arbitrary graph. In contrast to all learning formulations in the area of discriminative pattern recognition, we propose a scalable generative optimization/algorithm theoretically proved to capture distributions at the nodes of a graph. Our model is able to generate samples from the probability densities learned at each node. This probabilistic data generation model, i.e., convolutional graph autoencoder (CGAE), is devised based on the localized first-order approximation of spectral graph convolutions, deep learning, and the variational Bayesian inference. We apply the CGAE to anew problem, the spatio-temporal probabilistic solar irradiance prediction. Multiple solar radiation measurement sites in a wide area in northern states of the U.S. are modeled as an undirected graph. Using our proposed model, the distribution of future irradiance given historical radiation observations is estimated for every site/node. Numerical results on the national solar radiation database show state-of-the-art performance for probabilistic radiation prediction on geographically distributed irradiance data in terms of reliability, sharpness, and continuous ranked probability score.","keywords: {Bayes methods;graph theory;learning (artificial intelligence);neural nets;pattern recognition;power engineering computing;probability;solar power stations;solar radiation;spatiotemporal phenomena;sunlight;convolutional graph autoencoder;generative deep neural network;probabilistic spatio-temporal;machine learning;omnipresent task;anomaly detection;dynamic network analysis;deep generative model;continuous probability densities;arbitrary graph;learning formulations;discriminative pattern recognition;probabilistic data generation model;CGAE;spectral graph convolutions;deep learning;spatio-temporal probabilistic solar irradiance prediction;multiple solar radiation measurement sites;undirected graph;future irradiance;national solar radiation database;probabilistic radiation prediction;geographically distributed irradiance data;Predictive models;Probabilistic logic;Forecasting;Data models;Mathematical model;Solar radiation;Computational modeling;Deep neural network;spatio-temporal forecasting;probabilistic forecasting;spectral graph convolutions;variational Bayesian inference},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8663347&isnumber=9043622,104,CNN,,CGAE,,Graph Autoencoder,,,,
"R. A. Farrugia and C. Guillemot, ""Light Field Super-Resolution Using a Low-Rank Prior and Deep Convolutional Neural Networks,"" in IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 42, no. 5, pp. 1162-1175, 1 May 2020.",doi: 10.1109/TPAMI.2019.2893666,"Abstract: Light field imaging has recently known a regain of interest due to the availability of practical light field capturing systems that offer a wide range of applications in the field of computer vision. However, capturing high-resolution light fields remains technologically challenging since the increase in angular resolution is often accompanied by a significant reduction in spatial resolution. This paper describes a learning-based spatial light field super-resolution method that allows the restoration of the entire light field with consistency across all angular views. The algorithm first uses optical flow to align the light field and then reduces its angular dimension using low-rank approximation. We then consider the linearly independent columns of the resulting low-rank model as an embedding, which is restored using a deep convolutional neural network (DCNN). The super-resolved embedding is then used to reconstruct the remaining views. The original disparities are restored using inverse warping where missing pixels are approximated using a novel light field inpainting algorithm. Experimental results show that the proposed method outperforms existing light field super-resolution algorithms, achieving PSNR gains of 0.23 dB over the second best performing method. The performance is shown to be further improved using iterative back-projection as a post-processing step.","keywords: {computer vision;convolutional neural nets;image reconstruction;image resolution;image sampling;image sensors;image sequences;learning (artificial intelligence);deep convolutional neural network;light field imaging;practical light field;high-resolution light fields;angular resolution;spatial resolution;learning-based spatial light field super-resolution method;entire light field;angular views;low-rank approximation;resulting low-rank model;super-resolved embedding;light field super-resolution algorithms;Spatial resolution;Cameras;Image restoration;Matrix decomposition;Sparse matrices;Light fields;Deep convolutional neural networks;light field;low-rank matrix approximation;super-resolution},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8620368&isnumber=9055268,105,CNN,,CNN,,Light Field," INRIA dataset: https://goo.gl/st8xRt , HCI dataset: http://hci-lightfield.iwr.uni-heidelberg.de/ , 6. Stanford dataset: http://lightfield.stanford.edu/",,,
"B. Lin, X. Tao and J. Lu, ""Hyperspectral Image Denoising via Matrix Factorization and Deep Prior Regularization,"" in IEEE Transactions on Image Processing, vol. 29, pp. 565-578, 2020.",doi: 10.1109/TIP.2019.2928627,"Abstract: Deep learning has been successfully introduced for 2D-image denoising, but it is still unsatisfactory for hyperspectral image (HSI) denoising due to the unacceptable computational complexity of the end-to-end training process and the difficulty of building a universal 3D-image training dataset. In this paper, instead of developing an end-to-end deep learning denoising network, we propose an HSI denoising framework for the removal of mixed Gaussian impulse noise, in which the denoising problem is modeled as a convolutional neural network (CNN) constrained non-negative matrix factorization problem. Using the proximal alternating linearized minimization, the optimization can be divided into three steps: the update of the spectral matrix, the update of the abundance matrix, and the estimation of the sparse noise. Then, we design the CNN architecture and proposed two training schemes, which can allow the CNN to be trained with a 2D-image dataset. Compared with the state-of-the-art denoising methods, the proposed method has a relatively good performance on the removal of the Gaussian and mixed Gaussian impulse noises. More importantly, the proposed model can be only trained once by a 2D-image dataset but can be used to denoise HSIs with different numbers of channel bands.","keywords: {cellular neural nets;Gaussian noise;hyperspectral imaging;image denoising;impulse noise;learning (artificial intelligence);matrix decomposition;minimisation;hyperspectral image denoising;matrix factorization;deep prior regularization;deep learning;computational complexity;end-to-end training process;convolutional neural network;proximal alternating linearized minimization;optimization;abundance matrix;spectral matrix;sparse noise estimation;training schemes;channel bands;mixed Gaussian impulse noise removal;Noise reduction;Training;Sparse matrices;Optimization;Hyperspectral imaging;Computational modeling;Image denoising;Hyperspectral image denoising;nonnegative matrix factorization (NMF);deep prior regularization (DPR);convolutional neural networks (CNN)},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8767025&isnumber=8835130,106,CNN,0.98 SSIM,CNN,,dehazing,http://vision.seas.harvard.edu/hyperspec/download.html,,,
"Z. Wang, J. Jiang, Y. Wu, M. Ye, X. Bai and S. Satoh, ""Learning Sparse and Identity-Preserved Hidden Attributes for Person Re-Identification,"" in IEEE Transactions on Image Processing, vol. 29, pp. 2013-2025, 2020.",doi: 10.1109/TIP.2019.2946975,"Abstract: Person re-identification (Re-ID) aims at matching person images captured in non-overlapping camera views. To represent person appearance, low-level visual features are sensitive to environmental changes, while high-level semantic attributes, such as “short-hair” or “long-hair”, are relatively stable. Hence, researches have started to design semantic attributes to reduce the visual ambiguity. However, to train a prediction model for semantic attributes, it requires plenty of annotations, which are hard to obtain in practical large-scale applications. To alleviate the reliance on annotation efforts, we propose to incrementally generate Deep Hidden Attribute (DHA) based on baseline deep network for newly uncovered annotations. In particular, we propose an auto-encoder model that can be plugged into any deep network to mine latent information in an unsupervised manner. To optimize the effectiveness of DHA, we reform the auto-encoder model with additional orthogonal generation module, along with identity-preserving and sparsity constraints. 1) Orthogonally generating: In order to make DHAs different from each other, Singular Vector Decomposition (SVD) is introduced to generate DHAs orthogonally. 2) Identity-preserving constraint: The generated DHAs should be distinct for telling different persons, so we associate DHAs with person identities. 3) Sparsity constraint: To enhance the discriminability of DHAs, we also introduce the sparsity constraint to restrict the number of effective DHAs for each person. Experiments conducted on public datasets have validated the effectiveness of the proposed network. On two large-scale datasets, i.e., Market-1501 and DukeMTMC-reID, the proposed method outperforms the state-of-the-art methods.","keywords: {cameras;convolutional neural nets;feature extraction;image representation;image retrieval;learning (artificial intelligence);singular value decomposition;DukeMTMC-reID dataset;Market-1501 dataset;singular vector decomposition;identity-preserved hidden attributes;deep hidden attribute;orthogonal generation module;sparsity constraint;auto-encoder model;DHA;annotation efforts;prediction model;visual ambiguity;high-level semantic attributes;low-level visual features;person appearance;nonoverlapping camera views;person images;Semantics;Deep learning;Visualization;Feature extraction;Image reconstruction;Clothing;Training;Person re-identification;attribute learning;generation;discrimination;Biometric Identification;Deep Learning;Female;Humans;Image Processing, Computer-Assisted;Male},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8874954&isnumber=8835130,107,CNN,.7595 mAP,DHA-NET,,Pose ID,"DukeMTMC, MARKET-1501",DHA,2,
"X. Tao, D. Zhang, Z. Wang, X. Liu, H. Zhang and D. Xu, ""Detection of Power Line Insulator Defects Using Aerial Images Analyzed With Convolutional Neural Networks,"" in IEEE Transactions on Systems, Man, and Cybernetics: Systems, vol. 50, no. 4, pp. 1486-1498, April 2020.",doi: 10.1109/TSMC.2018.2871750,"Abstract: As the failure of power line insulators leads to the failure of power transmission systems, an insulator inspection system based on an aerial platform is widely used. Insulator defect detection is performed against complex backgrounds in aerial images, presenting an interesting but challenging problem. Traditional methods, based on handcrafted features or shallow learning techniques, can only localize insulators and detect faults under specific detection conditions, such as when sufficient prior knowledge is available, with low background interference, at certain object scales, or under specific illumination conditions. This paper discusses the automatic detection of insulator defects using aerial images, accurately localizing insulator defects appearing in input images captured from real inspection environments. We propose a novel deep convolutional neural network (CNN) cascading architecture for performing localization and detecting defects in insulators. The cascading network uses a CNN based on a region proposal network to transform defect inspection into a two-level object detection problem. To address the scarcity of defect images in a real inspection environment, a data augmentation method is also proposed that includes four operations: 1) affine transformation; 2) insulator segmentation and background fusion; 3) Gaussian blur; and 4) brightness transformation. Defect detection precision and recall of the proposed method are 0.91 and 0.96 using a standard insulator dataset, and insulator defects under various conditions can be successfully detected. Experimental results demonstrate that this method meets the robustness and accuracy requirements for insulator defect detection.","keywords: {automatic optical inspection;computer vision;convolutional neural nets;fault diagnosis;feature extraction;image classification;image segmentation;learning (artificial intelligence);object detection;power system faults;defect inspection;two-level object detection problem;defect images;insulator defect detection;power line insulator defects;convolutional neural networks;power line insulators;power transmission systems;insulator inspection system;aerial platform;specific detection conditions;specific illumination conditions;automatic detection;input images;deep convolutional neural network cascading architecture;region proposal network;Insulators;Inspection;Feature extraction;Object detection;Shape;Support vector machines;Convolutional neural networks;Aerial image;convolutional neural network (CNN);data augmentation;defect detection;insulators},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8492359&isnumber=9039765,108,R-CNN,,multi-stage CNN,,Power Line Insulator detection,https://github.com/InsulatorData/InsulatorDataSet,,,
"H. -Y. Lai, G. Saavedra-Peña, C. G. Sodini, V. Sze and T. Heldt, ""Measuring Saccade Latency Using Smartphone Cameras,"" in IEEE Journal of Biomedical and Health Informatics, vol. 24, no. 3, pp. 885-897, March 2020.",doi: 10.1109/JBHI.2019.2913846,"Abstract: Objective: Accurate quantification of neurodegenerative disease progression is an ongoing challenge that complicates efforts to understand and treat these conditions. Clinical studies have shown that eye movement features may serve as objective biomarkers to support diagnosis and tracking of disease progression. Here, we demonstrate that saccade latency-an eye movement measure of reaction time-can be measured robustly outside of the clinical environment with a smartphone camera. Methods: To enable tracking of saccade latency in large cohorts of patients and control subjects, we combined a deep convolutional neural network for gaze estimation with a model-based approach for saccade onset determination that provides automated signal-quality quantification and artifact rejection. Results: Simultaneous recordings with a smartphone and a high-speed camera resulted in negligible differences in saccade latency distributions. Furthermore, we demonstrated that the constraint of chinrest support can be removed when recording healthy subjects. Repeat smartphone-based measurements of saccade latency in 11 self-reported healthy subjects resulted in an intraclass correlation coefficient of 0.76, showing our approach has good to excellent test-retest reliability. Additionally, we conducted more than 19000 saccade latency measurements in 29 self-reported healthy subjects and observed significant intra- and inter-subject variability, which highlights the importance of individualized tracking. Lastly, we showed that with around 65 measurements we can estimate mean saccade latency to within less-than-10-ms precision, which takes within 4 min with our setup. Conclusion and Significance: By enabling repeat measurements of saccade latency and its distribution in individual subjects, our framework opens the possibility of quantifying patient state on a finer timescale in a broader population than previously possible.","keywords: {biomechanics;biomedical optical imaging;cameras;convolutional neural nets;diseases;eye;medical image processing;smart phones;smartphone;artifact rejection;gaze estimation;saccade latency measurements;saccade latency distributions;high-speed camera;automated signal-quality quantification;deep convolutional neural network;eye movement;neurodegenerative disease progression;smartphone camera;time 4.0 min;Diseases;Cameras;Task analysis;Visualization;Portable computers;Biomedical measurement;Face;Eye tracking;convolutional neural networks;health monitoring;saccade latency;mobile imaging},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8703178&isnumber=9025311,109,R-CNN,,CNN,,,,,1,
"A. Dudhane and S. Murala, ""RYF-Net: Deep Fusion Network for Single Image Haze Removal,"" in IEEE Transactions on Image Processing, vol. 29, pp. 628-640, 2020.",doi: 10.1109/TIP.2019.2934360,"Abstract: Haze removal from a single image is a challenging task. Estimation of accurate scene transmission map (TrMap) is the key to reconstruct the haze-free scene. In this paper, we propose a convolutional neural network based architecture to estimate the TrMap of the hazy scene. The proposed network takes the hazy image as an input and extracts the haze relevant features using proposed RNet and YNet through RGB and YCbCr color spaces respectively and generates two TrMaps. Further, we propose a novel TrMap fusion network (FNet) to integrate two TrMaPs and estimate robust TrMap for the hazy scene. To analyze the robustness of FNet, we tested it on combinations of TrMaps obtained from existing state-of-the-art methods. Performance evaluation of the proposed approach has been carried out using the structural similarity index, mean square error and peak signal to noise ratio. We conduct experiments on five datasets namely: D-HAZY, Imagenet, Indoor SOTS, HazeRD and set of real-world hazy images. Performance analysis shows that the proposed approach outperforms the existing state-of-the-art methods for single image dehazing. Further, we extended our work to address high-level vision task such as object detection in hazy scenes. It is observed that there is a significant improvement in accurate object detection in hazy scenes using proposed approach.","keywords: {computer vision;convolutional neural nets;feature extraction;image colour analysis;image denoising;image enhancement;image restoration;object detection;D-HAZY;real-world hazy images;single image dehazing;hazy scene;deep fusion network;single image haze removal;accurate scene transmission map;haze-free scene;convolutional neural network;haze relevant features;TrMap fusion network;TrMap fusion network;YCbCr color spaces;RGB color spaces;structural similarity index;mean square error;peak signal to noise ratio;Image color analysis;Feature extraction;Atmospheric modeling;Optical attenuators;Optical imaging;Computational modeling;Integrated optics;Dehazing;transmission map;dark channel prior;fusion;CNN},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8802288&isnumber=8835130,110,CNN,,RYFNet,,dehazing,"D-HAZY, Imagenet, Indoor SOTS, HazeRD",,,
"J. Hsu, C. Kuo and D. Chen, ""Image Super-Resolution Using Capsule Neural Networks,"" in IEEE Access, vol. 8, pp. 9751-9759, 2020.",doi: 10.1109/ACCESS.2020.2964292,"Abstract: Convolutional neural networks (CNNs) have been widely applied in super-resolution (SR) and other image restoration tasks. Recently, Hinton et al. proposed capsule neural networks to resolve the problem of viewpoint variations in image classification tasks. Each capsule is represented as either a vector or a matrix to encode more object information, such as position, size, direction, etc. Instead of detecting specific features, these capsule neural networks search for the most relevant features using an iterative process. Therefore, capsule neural networks require fewer parameters compared to traditional neural networks. Inspired by these advances, we make use of a capsule neural network to exploit more potential features for image SR. In this paper, we develope two frameworks: the Capsule Image Restoration Neural Network (CIRNN) and the Capsule Attention and Reconstruction Neural Network (CARNN), to incorporate capsules into image SR convolutional neural networks. The CIRNN takes advantage of the rich information encoded in the capsules to reconstruct accurate high-resolution images. The CARNN generates SR attention features by utilizing the robust segmentation capability of the capsules. Our experiments show that both frameworks can enhance SR for most testing datasets. The CIRNN performs better than the CARNN and can achieve better performance than other traditional CNN methods with a similar amount of parameters.","keywords: {convolutional neural nets;image classification;image resolution;image restoration;image segmentation;high-resolution images;image SR convolutional neural networks;Reconstruction Neural Network;Capsule Attention;Capsule Image Restoration Neural Network;traditional neural networks;capsule neural networks search;image classification tasks;image restoration tasks;super-resolution;Routing;Image reconstruction;Biological neural networks;Image restoration;Feature extraction;Super resolution;deep learning;convolutional neural network;capsule neural network},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8950449&isnumber=8948470,111,CNN,,CNN,,image super-resolustion,,,,
"A. Kwasigroch, M. Grochowski and A. Mikołajczyk, ""Neural Architecture Search for Skin Lesion Classification,"" in IEEE Access, vol. 8, pp. 9061-9071, 2020.",doi: 10.1109/ACCESS.2020.2964424,"Abstract: Deep neural networks have achieved great success in many domains. However, successful deployment of such systems is determined by proper manual selection of the neural architecture. This is a tedious and time-consuming process that requires expert knowledge. Different tasks need very different architectures to obtain satisfactory results. The group of methods called the neural architecture search (NAS) helps to find effective architecture in an automated manner. In this paper, we present the use of an architecture search framework to solve the medical task of malignant melanoma detection. Unlike many other methods tested on benchmark datasets, we tested it on practical problem, which differs greatly in terms of difficulty in distinguishing between classes, resolution of images, data balance within the classes, and the number of data available. In order to find a suitable network structure, the hill-climbing search strategy was employed along with network morphism operations to explore the search space. The network morphism operations allow for incremental increases in the network size with the use of the previously trained network. This kind of knowledge reusing allows significantly reducing the computational cost. The proposed approach produces structures that achieve similar results to those provided by manually designed structures, at the same time making use of almost 20 times fewer parameters. What is more, the search process lasts on average only 18h on single GPU.","keywords: {cancer;image classification;medical image processing;neural nets;search problems;skin;neural architecture search;skin lesion classification;deep neural networks;architecture search framework;hill-climbing search strategy;network morphism operations;search space;trained network;image resolution;malignant melanoma detection;Computer architecture;Training;Space exploration;Task analysis;Neural networks;Deep learning;Image processing;Deep learning;convolutional neural network;neural architecture search;network morphism;malignant melanoma},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8950333&isnumber=8948470,112,NAS,,NAS,,Skin Lesion Classification,,Neural Architecture Search,,1
"X. Li, J. Li, X. Hu and J. Yang, ""Line-CNN: End-to-End Traffic Line Detection With Line Proposal Unit,"" in IEEE Transactions on Intelligent Transportation Systems, vol. 21, no. 1, pp. 248-258, Jan. 2020.",doi: 10.1109/TITS.2019.2890870,"Abstract: The task of traffic line detection is a fundamental yet challenging problem. Previous approaches usually conduct traffic line detection via a two-stage way, namely the line segment detection followed by a segment clustering, which is very likely to ignore the global semantic information of an entire line. To address the problem, we propose an end-to-end system called Line-CNN (L-CNN), in which the key component is a novel line proposal unit (LPU). The LPU utilizes line proposals as references to locate accurate traffic curves, which forces the system to learn the global feature representation of the entire traffic lines. We benchmark the proposed L-CNN on two public datasets including MIKKI and TuSimple, and the results suggest that L-CNN outperforms the state-of-the-art methods. In addition, L-CNN can run at approximately 30 f/s on a Titan X GPU, which indicates the practicability and effectiveness of L-CNN for real-time intelligent self-driving systems.","keywords: {convolutional neural nets;feature extraction;image representation;image segmentation;learning (artificial intelligence);traffic engineering computing;Line-CNN;line proposal unit;line segment detection;traffic lines;L-CNN;traffic curves;end-to-end traffic line detection;MIKKI dataset;TuSimple dataset;Titan X GPU;Proposals;Task analysis;Detectors;Feature extraction;Benchmark testing;Real-time systems;Shape;Traffic line detection;Line-CNN;line proposal unit;self-driving;convolutional neural network},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8624563&isnumber=8946909,113,R-CNN,0.86,Line-CNN,https://github.com/mohamedadaly/caltech-lane-detection,Traffic Line Detection,"MIKKI, TuSimple",,2,
"Y. Wei et al., ""A Review of Algorithm & Hardware Design for AI-Based Biomedical Applications,"" in IEEE Transactions on Biomedical Circuits and Systems, vol. 14, no. 2, pp. 145-163, April 2020.",doi: 10.1109/TBCAS.2020.2974154,"Abstract: This paper reviews the state of the arts and trends of the AI-Based biomedical processing algorithms and hardware. The algorithms and hardware for different biomedical applications such as ECG, EEG and hearing aid have been reviewed and discussed. For algorithm design, various widely used biomedical signal classification algorithms have been discussed including support vector machine (SVM), back propagation neural network (BPNN), convolutional neural networks (CNN), probabilistic neural networks (PNN), recurrent neural networks (RNN), Short-term Memory Network (LSTM), fuzzy neural network and etc. The pros and cons of the classification algorithms have been analyzed and compared in the context of application scenarios. The research trends of AI-Based biomedical processing algorithms and applications are also discussed. For hardware design, various AI-Based biomedical processors have been reviewed and discussed, including ECG classification processor, EEG classification processor, EMG classification processor and hearing aid processor. Various techniques on architecture and circuit level have been analyzed and compared. The research trends of the AI-Based biomedical processor have also been discussed.","keywords: {backpropagation;electrocardiography;electroencephalography;electromyography;fuzzy neural nets;hearing aids;medical signal processing;recurrent neural nets;reviews;signal classification;support vector machines;EMG classification processor;EEG classification processor;short-term memory network;LSTM;RNN;recurrent neural networks;PNN;probabilistic neural networks;CNN;convolutional neural networks;BPNN;back propagation neural network;SVM;support vector machine;hardware design;hearing aid processor;ECG classification processor;AI-Based biomedical processor;fuzzy neural network;biomedical signal classification algorithms;Electrocardiography;Support vector machines;Signal processing algorithms;Neural networks;Program processors;Electroencephalography;Hardware;AI;algorithm;biomedical application;proce-ssor},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9000730&isnumber=9049430,114,,,,,"EEG, ECG",,review,,4
"S. Rajaraman, J. Siegelman, P. O. Alderson, L. S. Folio, L. R. Folio and S. K. Antani, ""Iteratively Pruned Deep Learning Ensembles for COVID-19 Detection in Chest X-Rays,"" in IEEE Access, vol. 8, pp. 115041-115050, 2020.",doi: 10.1109/ACCESS.2020.3003810,"Abstract: We demonstrate use of iteratively pruned deep learning model ensembles for detecting pulmonary manifestations of COVID-19 with chest X-rays. This disease is caused by the novel Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) virus, also known as the novel Coronavirus (2019-nCoV). A custom convolutional neural network and a selection of ImageNet pretrained models are trained and evaluated at patient-level on publicly available CXR collections to learn modality-specific feature representations. The learned knowledge is transferred and fine-tuned to improve performance and generalization in the related task of classifying CXRs as normal, showing bacterial pneumonia, or COVID-19-viral abnormalities. The best performing models are iteratively pruned to reduce complexity and improve memory efficiency. The predictions of the best-performing pruned models are combined through different ensemble strategies to improve classification performance. Empirical evaluations demonstrate that the weighted average of the best-performing pruned models significantly improves performance resulting in an accuracy of 99.01% and area under the curve of 0.9972 in detecting COVID-19 findings on CXRs. The combined use of modality-specific knowledge transfer, iterative model pruning, and ensemble learning resulted in improved predictions. We expect that this model can be quickly adopted for COVID-19 screening using chest radiographs.","keywords: {convolutional neural nets;diagnostic radiography;diseases;image classification;learning (artificial intelligence);medical image processing;bacterial pneumonia;CXR collections;Severe Acute Respiratory Syndrome Coronavirus 2 virus;chest radiographs;COVID-19 screening;iterative model pruning;modality-specific knowledge transfer;COVID-19-viral abnormalities;modality-specific feature representations;convolutional neural network;SARS-CoV-2;pulmonary manifestations;iteratively pruned deep learning model ensembles;chest X-rays;COVID-19 detection;Lung;COVID-19;Microorganisms;Computational modeling;National Institutes of Health;Predictive models;COVID-19;convolutional neural network;deep learning;ensemble;iterative pruning},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9121222&isnumber=8948470,115,R-CNN,0.99,CNN,,Covid-19 detection,"PEDIATRIC CXR, RSNA CXR, TWITTER COVID-19 CXR, MONTREAL COVID-19 CXR",,,
"A. Mobiny, H. Lu, H. V. Nguyen, B. Roysam and N. Varadarajan, ""Automated Classification of Apoptosis in Phase Contrast Microscopy Using Capsule Network,"" in IEEE Transactions on Medical Imaging, vol. 39, no. 1, pp. 1-10, Jan. 2020.",doi: 10.1109/TMI.2019.2918181,"Abstract: Automatic and accurate classification of apoptosis, or programmed cell death, will facilitate cell biology research. The state-of-the-art approaches in apoptosis classification use deep convolutional neural networks (CNNs). However, these networks are not efficient in encoding the part-whole relationships, thus requiring a large number of training samples to achieve robust generalization. This paper proposes an efficient variant of capsule networks (CapsNets) as an alternative to CNNs. Extensive experimental results demonstrate that the proposed CapsNets achieve competitive performances in target cell apoptosis classification, while significantly outperforming CNNs when the number of training samples is small. To utilize temporal information within microscopy videos, we propose a recurrent CapsNet constructed by stacking a CapsNet and a bi-directional long short-term recurrent structure. Our experiments show that when considering temporal constraints, the recurrent CapsNet achieves 93.8% accuracy and makes significantly more consistent prediction than NNs.","keywords: {biomedical optical imaging;cellular biophysics;image classification;learning (artificial intelligence);medical image processing;neural nets;training samples;microscopy videos;recurrent CapsNet;short-term recurrent structure;phase contrast microscopy;capsule network;cell death;cell biology research;deep convolutional neural networks;CNNs;part-whole relationships;robust generalization;efficient variant;target cell apoptosis classification;Routing;Task analysis;Training;Microscopy;Face;Feature extraction;Pediatrics;Apoptosis;capsule network;cell classification;Apoptosis;Cell Line, Tumor;Cells;Cytological Techniques;Humans;Image Processing, Computer-Assisted;Microscopy, Phase-Contrast;Neural Networks, Computer},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8720196&isnumber=8946770,116,CapsE,88.2 F1,Capse net,,,"FashionMNIST, CIFAR-10",,,
"Q. Zhu, B. Du and P. Yan, ""Boundary-Weighted Domain Adaptive Neural Network for Prostate MR Image Segmentation,"" in IEEE Transactions on Medical Imaging, vol. 39, no. 3, pp. 753-763, March 2020.",doi: 10.1109/TMI.2019.2935018,"Abstract: Accurate segmentation of the prostate from magnetic resonance (MR) images provides useful information for prostate cancer diagnosis and treatment. However, automated prostate segmentation from 3D MR images faces several challenges. The lack of clear edge between the prostate and other anatomical structures makes it challenging to accurately extract the boundaries. The complex background texture and large variation in size, shape and intensity distribution of the prostate itself make segmentation even further complicated. Recently, as deep learning, especially convolutional neural networks (CNNs), emerging as the best performed methods for medical image segmentation, the difficulty in obtaining large number of annotated medical images for training CNNs has become much more pronounced than ever. Since large-scale dataset is one of the critical components for the success of deep learning, lack of sufficient training data makes it difficult to fully train complex CNNs. To tackle the above challenges, in this paper, we propose a boundary-weighted domain adaptive neural network (BOWDA-Net). To make the network more sensitive to the boundaries during segmentation, a boundary-weighted segmentation loss is proposed. Furthermore, an advanced boundary-weighted transfer leaning approach is introduced to address the problem of small medical imaging datasets. We evaluate our proposed model on three different MR prostate datasets. The experimental results demonstrate that the proposed model is more sensitive to object boundaries and outperformed other state-of-the-art methods.","keywords: {biological organs;biomedical MRI;cancer;convolutional neural nets;feature extraction;image segmentation;learning (artificial intelligence);medical image processing;annotated medical images;training CNN;deep learning;boundary-weighted domain adaptive neural network;boundary-weighted segmentation loss;medical imaging datasets;magnetic resonance images;prostate cancer diagnosis;automated prostate segmentation;intensity distribution;convolutional neural networks;medical image segmentation;prostate MR image segmentation;prostate cancer treatment;3D MR images;complex background texture;advanced boundary-weighted transfer leaning approach;Image segmentation;Biomedical imaging;Feature extraction;Neural networks;Shape;Training data;Adaptive systems;Image segmentation;prostate MR image;domain adaptation;convolutional neural network;boundary-weighted loss},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8795525&isnumber=9023440,117,R-CNN,0.95,BOWDANet,https://github.com/ahukui/BOWDANet,MR Image Segmentation,PROMISE12 CHALLENGE,,,1
"Y. Zhang, P. David, H. Foroosh and B. Gong, ""A Curriculum Domain Adaptation Approach to the Semantic Segmentation of Urban Scenes,"" in IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 42, no. 8, pp. 1823-1841, 1 Aug. 2020.",doi: 10.1109/TPAMI.2019.2903401,"Abstract: During the last half decade, convolutional neural networks (CNNs) have triumphed over semantic segmentation, which is one of the core tasks in many applications such as autonomous driving and augmented reality. However, to train CNNs requires a considerable amount of data, which is difficult to collect and laborious to annotate. Recent advances in computer graphics make it possible to train CNNs on photo-realistic synthetic imagery with computer-generated annotations. Despite this, the domain mismatch between real images and the synthetic data hinders the models' performance. Hence, we propose a curriculum-style learning approach to minimizing the domain gap in urban scene semantic segmentation. The curriculum domain adaptation solves easy tasks first to infer necessary properties about the target domain; in particular, the first task is to learn global label distributions over images and local distributions over landmark superpixels. These are easy to estimate because images of urban scenes have strong idiosyncrasies (e.g., the size and spatial relations of buildings, streets, cars, etc.). We then train a segmentation network, while regularizing its predictions in the target domain to follow those inferred properties. In experiments, our method outperforms the baselines on two datasets and three backbone networks. We also report extensive ablation studies about our approach.","keywords: {augmented reality;computer graphics;convolutional neural nets;geographic information systems;image segmentation;learning (artificial intelligence);curriculum domain adaptation approach;urban scenes;convolutional neural networks;CNN;core tasks;autonomous driving;computer graphics;photo-realistic synthetic imagery;computer-generated annotations;domain mismatch;synthetic data;curriculum-style learning approach;domain gap;urban scene semantic segmentation;target domain;global label distributions;local distributions;segmentation network;inferred properties;backbone networks;Semantics;Image segmentation;Task analysis;Adaptation models;Neural networks;Training;Buildings;Domain adaptation;semantic segmentation;curriculum learning;curriculum domain adaptation;deep learning;self-driving},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8661514&isnumber=9130977,118,R-CNN,,,,Semantic Segmentation,"VOC2012, COCO, GTA dataset",,,
"F. van Wyk, Y. Wang, A. Khojandi and N. Masoud, ""Real-Time Sensor Anomaly Detection and Identification in Automated Vehicles,"" in IEEE Transactions on Intelligent Transportation Systems, vol. 21, no. 3, pp. 1264-1276, March 2020.",doi: 10.1109/TITS.2019.2906038,"Abstract: Connected and automated vehicles (CAVs) are expected to revolutionize the transportation industry, mainly through allowing for a real-time and seamless exchange of information between vehicles and roadside infrastructure. Although connectivity and automation are projected to bring about a vast number of benefits, they can give rise to new challenges in terms of safety, security, and privacy. To navigate roadways, CAVs need to heavily rely on their sensor readings and the information received from other vehicles and roadside units. Hence, anomalous sensor readings caused by either malicious cyber attacks or faulty vehicle sensors can result in disruptive consequences and possibly lead to fatal crashes. As a result, before the mass implementation of CAVs, it is important to develop methodologies that can detect anomalies and identify their sources seamlessly and in real time. In this paper, we develop an anomaly detection approach through combining a deep learning method, namely convolutional neural network (CNN), with a well-established anomaly detection method, and Kalman filtering with a χ2-detector, to detect and identify anomalous behavior in CAVs. Our numerical experiments demonstrate that the developed approach can detect anomalies and identify their sources with high accuracy, sensitivity, and F1 score. In addition, this developed approach outperforms the anomaly detection and identification capabilities of both CNNs and Kalman filtering with a χ2-detector method alone. It is envisioned that this research will contribute to the development of safer and more resilient CAV systems that implement a holistic view toward intelligent transportation system (ITS) concepts.","keywords: {convolutional neural nets;fault diagnosis;Kalman filters;learning (artificial intelligence);sensor fusion;traffic engineering computing;convolutional neural network;sensor anomaly identification;Kalman filtering;deep learning method;roadside units;roadside infrastructure;connected and automated vehicles;sensor anomaly detection;CAV systems;Anomaly detection;Cyberattack;Real-time systems;Robot sensing systems;Kalman filters;Deep learning;Safety;Cyber-physical systems;fault diagnosis;intelligent vehicles;intrusion detection;vehicle safety},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8684317&isnumber=9018398,119,CNN-KF,92 F1,CNN-KF,,,,,,
"L. Deng et al., ""Tianjic: A Unified and Scalable Chip Bridging Spike-Based and Continuous Neural Computation,"" in IEEE Journal of Solid-State Circuits, vol. 55, no. 8, pp. 2228-2246, Aug. 2020.",doi: 10.1109/JSSC.2020.2970709,"Abstract: Toward the long-standing dream of artificial intelligence, two successful solution paths have been paved: 1) neuromorphic computing and 2) deep learning. Recently, they tend to interact for simultaneously achieving biological plausibility and powerful accuracy. However, models from these two domains have to run on distinct substrates, i.e., neuromorphic platforms and deep learning accelerators, respectively. This architectural incompatibility greatly compromises the modeling flexibility and hinders promising interdisciplinary research. To address this issue, we build a unified model description framework and a unified processing architecture (Tianjic), which covers the full stack from software to hardware. By implementing a set of integration and transformation operations, Tianjic is able to support spiking neural networks, biological dynamic neural networks, multilayered perceptron, convolutional neural networks, recurrent neural networks, and so on. A compatible routing infrastructure enables homogeneous and heterogeneous scalability on a decentralized many-core network. Several optimization methods are incorporated, such as resource and data sharing, near-memory processing, compute/access skipping, and intra-/inter-core pipeline, to improve performance and efficiency. We further design streaming mapping schemes for efficient network deployment with a flexible tradeoff between execution throughput and resource overhead. A 28-nm prototype chip is fabricated with >610-GB/s internal memory bandwidth. A variety of benchmarks are evaluated and compared with GPUs and several existing specialized platforms. In summary, the fully unfolded mapping can achieve significantly higher throughput and power efficiency; the semi-folded mapping can save 30x resources while still presenting comparable performance on average. Finally, two hybrid-paradigm examples, a multimodal unmanned bicycle and a hybrid neural network, are demonstrated to show the potential of our unified architecture. This article paves a new way to explore neural computing.","keywords: {bicycles;convolutional neural nets;learning (artificial intelligence);multilayer perceptrons;pipeline processing;recurrent neural nets;Tianjic;continuous neural computation;artificial intelligence;biological plausibility;powerful accuracy;neuromorphic platforms;deep learning accelerators;architectural incompatibility;unified model description framework;unified processing architecture;transformation operations;biological dynamic neural networks;multilayered perceptron;convolutional neural networks;recurrent neural networks;compatible routing infrastructure;heterogeneous scalability;many-core network;optimization methods;data sharing;near-memory processing;network deployment;flexible tradeoff;execution throughput;internal memory bandwidth;fully unfolded mapping;power efficiency;semifolded mapping;hybrid neural network;unified chip bridging spike-based neural computation;scalable chip bridging spike-based neural computation;streaming mapping schemes;inter-core pipeline;intra-core pipeline;multimodal unmanned bicycle;Machine learning;Neuromorphics;Biological neural networks;Computational modeling;Computer architecture;Deep learning accelerator;hybrid paradigm;neuromorphic chip;unified/scalable architecture},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8998338&isnumber=9146394,120,,,Tianjic,,,,,1,
"J. Chang, K. Kang and S. Kang, ""An Energy-Efficient FPGA-Based Deconvolutional Neural Networks Accelerator for Single Image Super-Resolution,"" in IEEE Transactions on Circuits and Systems for Video Technology, vol. 30, no. 1, pp. 281-295, Jan. 2020.",doi: 10.1109/TCSVT.2018.2888898,"Abstract: Convolutional neural networks (CNNs) demonstrate excellent performance in various computer vision applications. In recent years, FPGA-based CNN accelerators have been proposed for optimizing performance and power efficiency. Most accelerators are designed for object detection and recognition algorithms that are performed on low-resolution images. However, real-time image super-resolution (SR) cannot be implemented on a typical accelerator because of the long execution cycles required to generate high-resolution (HR) images, such as those used in ultra-high-definition systems. In this paper, we propose a novel CNN accelerator with efficient parallelization methods for SR applications. First, we propose a new methodology for optimizing the deconvolutional neural networks (DCNNs) used for increasing feature maps. Second, we propose a novel method to optimize CNN dataflow so that the SR algorithm can be driven at low power in display applications. Finally, we quantize and compress a DCNN-based SR algorithm into an optimal model for efficient inference using on-chip memory. We present an energy-efficient architecture for SR and validate our architecture on a mobile panel with quad-high-definition resolution. Our experimental results show that, with the same hardware resources, the proposed DCNN accelerator achieves a throughput up to 108 times greater than that of a conventional DCNN accelerator. In addition, our SR system achieves an energy efficiency of 144.9, 293.0, and 500.2 GOPS/W at SR scale factors of 2, 3, and 4, respectively. Furthermore, we demonstrate that our system can restore HR images to a high quality while greatly reducing the data bit-width and the number of parameters compared with conventional SR algorithms.","keywords: {computer vision;convolutional neural nets;field programmable gate arrays;image resolution;object detection;conventional SR algorithms;energy-efficient FPGA-based deconvolutional neural networks;single image super-resolution;convolutional neural networks;computer vision applications;FPGA-based CNN accelerators;optimizing performance;power efficiency;object detection;recognition algorithms;low-resolution images;real-time image super-resolution;typical accelerator;long execution cycles;high-resolution images;ultra-high-definition systems;novel CNN accelerator;parallelization methods;SR applications;CNN dataflow;display applications;DCNN-based SR algorithm;optimal model;energy-efficient architecture;quad-high-definition resolution;conventional DCNN accelerator;SR system;energy efficiency;SR scale factors;HR images;System-on-chip;Neural networks;Hardware;Memory management;Object detection;Inference algorithms;Accelerator architectures;deep neural networks (DNNs);deep learning;super-resolution;system architecture},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8584497&isnumber=8951039,121,,,,,,,FPGA,,
"Y. Zhang, Y. Huang, S. Yu and L. Wang, ""Cross-View Gait Recognition by Discriminative Feature Learning,"" in IEEE Transactions on Image Processing, vol. 29, pp. 1001-1015, 2020.",doi: 10.1109/TIP.2019.2926208,"Abstract: Recently, deep learning-based cross-view gait recognition has become popular owing to the strong capacity of convolutional neural networks (CNNs). Current deep learning methods often rely on loss functions used widely in the task of face recognition, e.g., contrastive loss and triplet loss. These loss functions have the problem of hard negative mining. In this paper, a robust, effective, and gait-related loss function, called angle center loss (ACL), is proposed to learn discriminative gait features. The proposed loss function is robust to different local parts and temporal window sizes. Different from center loss which learns a center for each identity, the proposed loss function learns multiple sub-centers for each angle of the same identity. Only the largest distance between the anchor feature and the corresponding cross-view sub-centers is penalized, which achieves better intra-subject compactness. We also propose to extract discriminative spatial-temporal features by local feature extractors and a temporal attention model. A simplified spatial transformer network is proposed to localize the suitable horizontal parts of the human body. Local gait features for each horizontal part are extracted and then concatenated as the descriptor. We introduce long short-term memory (LSTM) units as the temporal attention model to learn the attention score for each frame, e.g., focusing more on discriminative frames and less on frames with bad quality. The temporal attention model shows better performance than the temporal average pooling or gait energy images (GEI). By combing the three aspects, we achieve state-of-the-art results on several cross-view gait recognition benchmarks.","keywords: {convolutional neural nets;face recognition;feature extraction;gait analysis;learning (artificial intelligence);recurrent neural nets;local feature extractors;temporal attention model;local gait features;cross-view gait recognition;discriminative feature learning;deep learning;loss function;discriminative spatial-temporal feature extraction;angle center loss;discriminative gait feature learning;LSTM;long short-term memory;convolutional neural networks;CNN;face recognition;Gait recognition;Feature extraction;Three-dimensional displays;Generative adversarial networks;Face recognition;Deep learning;Clothing;Gait recognition;discriminative feature learning;angle center loss;spatial-temporal features},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8759096&isnumber=8835130,122,CNN/LSTM/Attention,,CNN/LSTM/Attention,,"CASIA-B, OULP, OUMVLP",,,2,
"Q. Xu, R. Lin, H. Yue, H. Huang, Y. Yang and Z. Yao, ""Research on Small Target Detection in Driving Scenarios Based on Improved Yolo Network,"" in IEEE Access, vol. 8, pp. 27574-27583, 2020.",doi: 10.1109/ACCESS.2020.2966328,"Abstract: The obtainment of road condition information during driving is extremely important for a driver. However, drivers usually cannot notice multiple information at the same time, which definitely increases certain safety risks. Considering this problem, this paper designs a road information collection plus alarm system based on artificial intelligence to monitor road information. The underlying core algorithm of this system adopts the YOLO v3 network with the best comprehensive detection performance in the end-to-end network. We use this network's advantage of fast detection speed to optimize on its original basis, and propose to “copy” part of the backbone network to build an auxiliary network, which enhances its feature extraction capability. Further, we apply the attention mechanism to the feature information fusion of the auxiliary network and the backbone network, suppress the invalid information channel, and improve the network processing efficiency. Besides, the training part of the network is optimized, and the mAP (mean Average Precision) is improved by setting the scale that meets the target to be detected. Through the test, the average test accuracy of the optimized network model reaches 84.76%, and the real-time detection speed on the 2080Ti reaches 41FPS. Compared with the previous network, the detection accuracy increases by 5.43% after optimization.","keywords: {convolutional neural nets;driver information systems;feature extraction;object detection;optimisation;road safety;target detection;driving scenarios;improved YOLO network;road condition information;safety risks;road information collection;alarm system;artificial intelligence;YOLO v3 network;end-to-end network;fast detection speed;backbone network;feature extraction capability;feature information fusion;information channel;mAP;mean average precision;Feature extraction;Object detection;Roads;Vehicles;Training;Real-time systems;Convolutional neural networks;Convolutional neural network;residual network;target detection;YOLO v3},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8957514&isnumber=8948470,123,YOLO,0.8476,,,Detection in Driving Scenarios,,,2,
"N. Colnerič and J. Demšar, ""Emotion Recognition on Twitter: Comparative Study and Training a Unison Model,"" in IEEE Transactions on Affective Computing, vol. 11, no. 3, pp. 433-446, 1 July-Sept. 2020.",doi: 10.1109/TAFFC.2018.2807817,"Abstract: Despite recent successes of deep learning in many fields of natural language processing, previous studies of emotion recognition on Twitter mainly focused on the use of lexicons and simple classifiers on bag-of-words models. The central question of our study is whether we can improve their performance using deep learning. To this end, we exploit hashtags to create three large emotion-labeled data sets corresponding to different classifications of emotions. We then compare the performance of several word- and character-based recurrent and convolutional neural networks with the performance on bag-of-words and latent semantic indexing models. We also investigate the transferability of the final hidden state representations between different classifications of emotions, and whether it is possible to build a unison model for predicting all of them using a shared representation. We show that recurrent neural networks, especially character-based ones, can improve over bag-of-words and latent semantic indexing models. Although the transfer capabilities of these models are poor, the newly proposed training heuristic produces a unison model with performance comparable to that of the three single models.","keywords: {convolutional neural nets;emotion recognition;indexing;learning (artificial intelligence);natural language processing;pattern classification;recurrent neural nets;social networking (online);Twitter;unison model;deep learning;natural language processing;emotion recognition;simple classifiers;bag-of-words models;central question;emotion-labeled data sets;latent semantic indexing models;final hidden state representations;recurrent neural networks;character-based ones;single models;convolutional neural networks;Twitter;Tagging;Mood;Machine learning;Training;Emotion recognition;Convolutional neural networks;Emotion recognition;text mining;twitter;recurrent neural networks;convolutional neural networks},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8295234&isnumber=9167328,124,RNN/CNN,70 f1,RNN/CNN,https://github.com/nikicc/twitter-emotion-recognition,Emotion Recognition,,https://github.com/nikicc/twitter-emotion-recognition,1,
"H. Liu et al., ""Deep Learning-Based Picture-Wise Just Noticeable Distortion Prediction Model for Image Compression,"" in IEEE Transactions on Image Processing, vol. 29, pp. 641-656, 2020.",doi: 10.1109/TIP.2019.2933743,"Abstract: Picture Wise Just Noticeable Difference (PW-JND), which accounts for the minimum difference of a picture that human visual system can perceive, can be widely used in perception-oriented image and video processing. However, the conventional Just Noticeable Difference (JND) models calculate the JND threshold for each pixel or sub-band separately, which may not reflect the total masking effect of a picture accurately. In this paper, we propose a deep learning based PW-JND prediction model for image compression. Firstly, we formulate the task of predicting PW-JND as a multi-class classification problem, and propose a framework to transform the multi-class classification problem to a binary classification problem solved by just one binary classifier. Secondly, we construct a deep learning based binary classifier named perceptually lossy/lossless predictor which can predict whether an image is perceptually lossy to another or not. Finally, we propose a sliding window based search strategy to predict PW-JND based on the prediction results of the perceptually lossy/lossless predictor. Experimental results show that the mean accuracy of the perceptually lossy/lossless predictor reaches 92%, and the absolute prediction error of the proposed PW-JND model is 0.79 dB on average, which show the superiority of the proposed PW-JND model to the conventional JND models.","keywords: {data compression;error statistics;image coding;learning (artificial intelligence);neural nets;deep learning-based picture-wise just noticeable distortion prediction;image compression;video processing;Just Noticeable Difference models;total masking effect;multiclass classification problem transformation;binary classification problem;perceptually lossy-lossless predictor;sliding window search strategy;absolute prediction error;Image coding;Predictive models;Streaming media;Adaptation models;Bit rate;Distortion;Visualization;Just noticeable distortion;convolutional neural network;visual perception;image quality assessment},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8796396&isnumber=8835130,125,CNN,0.92,PW-JND,,Distortion Prediction,,MCL-JCI,1,
"Z. Yuan et al., ""STICKER: An Energy-Efficient Multi-Sparsity Compatible Accelerator for Convolutional Neural Networks in 65-nm CMOS,"" in IEEE Journal of Solid-State Circuits, vol. 55, no. 2, pp. 465-477, Feb. 2020.",doi: 10.1109/JSSC.2019.2946771,"Abstract: STICKER is an energy-efficient convolutional neural network (NN) processor. It mainly improves energy efficiency by making full use of sparsity. The network sparsity can potentially lower storage and computation requirements. However, the sparsity distribution of both activations and weights ranges from 2% to 99% in different layers or models. Therefore, good support for the sparsity distribution is the key to improve the energy efficiency. Three new features are proposed in this article to support wide sparsity distribution efficiently. First, multi-sparsity control and data flow are implemented for finer sparsity granularity support. It can automatically switch the processor among nine sparsity modes for higher energy efficiency. Second, a multi-mode hierarchical data memory which can be reconfigured for networks with different sparsity modes is designed for higher storage efficiency. Third, a multi-sparsity-compatible set-associative convolution processing element (PE) array is designed to efficiently carry out convolution operations under different sparsity modes, especially when both activations and weights are sparse. STICKER was implemented in a 65-nm CMOS technology. With its wide-range sparsity-supported capacity, the peak energy efficiency reaches 62.1 TOPS/W when sparsity ratios of both activations and weights are 5%. In a completely pruned Alexnet model, STICKER achieves 2.82 TOPS/W energy efficiency 1.8× higher than that of the state-of-the-art processors.","keywords: {CMOS integrated circuits;convolutional neural nets;energy conservation;microprocessor chips;power aware computing;multisparsity control;multimode hierarchical data memory;multisparsity-compatible set-associative convolution processing element array;STICKER;energy-efficient multisparsity compatible accelerator;energy-efficient convolutional neural network processor;data flow;65-nm CMOS technology;size 65 nm;Convolution;Arrays;Silicon;Convolutional neural networks;Indexes;Quantization (signal);Accelerator;neural network (NN);sparsity},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8890710&isnumber=8972639,126,CNN,,,,hardware improvement,,,,
"M. Simon, E. Rodner, T. Darrell and J. Denzler, ""The Whole Is More Than Its Parts? From Explicit to Implicit Pose Normalization,"" in IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 42, no. 3, pp. 749-763, 1 March 2020.",doi: 10.1109/TPAMI.2018.2885764,"Abstract: Fine-grained classification describes the automated recognition of visually similar object categories like birds species. Previous works were usually based on explicit pose normalization, i.e., the detection and description of object parts. However, recent models based on a final global average or bilinear pooling have achieved a comparable accuracy without this concept. In this paper, we analyze the advantages of these approaches over generic CNNs and explicit pose normalization approaches. We also show how they can achieve an implicit normalization of the object pose. A novel visualization technique called activation flow is introduced to investigate limitations in pose handling in traditional CNNs like AlexNet and VGG. Afterward, we present and compare the explicit pose normalization approach neural activation constellations and a generalized framework for the final global average and bilinear pooling called α-pooling. We observe that the latter often achieves a higher accuracy improving common CNN models by up to 22.9 percent, but lacks the interpretability of the explicit approaches. We present a visualization approach for understanding and analyzing predictions of the model to address this issue. Furthermore, we show that our approaches for fine-grained recognition are beneficial for other fields like action recognition.","keywords: {convolutional neural nets;data visualisation;image classification;neural net architecture;object recognition;pose estimation;image classification;automated object recognition;visualization technique;α-pooling;action recognition;visually similar object recognition;CNN models;activation flow;pose handling;feature extraction;generic convolutional neural network;CNN architectures;explicit pose normalization;implicit pose normalization;Task analysis;Detectors;Analytical models;Visualization;Encoding;Proposals;Birds;Fine-grained classification;object recognition;convolutional neural networks},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8580407&isnumber=8984605,127,CNN,,"AlexNet, VGG-VD, ResNet-50",,Pose estimation,,"Oxford Flowers 102, Oxford-IIIT, Pets Stanford 40 actions",2,
"T. -E. Kam, H. Zhang, Z. Jiao and D. Shen, ""Deep Learning of Static and Dynamic Brain Functional Networks for Early MCI Detection,"" in IEEE Transactions on Medical Imaging, vol. 39, no. 2, pp. 478-487, Feb. 2020.",doi: 10.1109/TMI.2019.2928790,"Abstract: While convolutional neural network (CNN) has been demonstrating powerful ability to learn hierarchical spatial features from medical images, it is still difficult to apply it directly to resting-state functional MRI (rs-fMRI) and the derived brain functional networks (BFNs). We propose a novel CNN framework to simultaneously learn embedded features from BFNs for brain disease diagnosis. Since BFNs can be built by considering both static and dynamic functional connectivity (FC), we first decompose rs-fMRI into multiple static BFNs with modified independent component analysis. Then, the voxel-wise variability in dynamic FC is used to quantify BFN dynamics. A set of paired 3D images representing static/dynamic BFNs can be fed into 3D CNNs, from which we can hierarchically and simultaneously learn static/dynamic BFN features. As a result, the dynamic BFN features can complement static BFN features and, at the meantime, different BFNs can help each other toward a joint and better classification. We validate our method with a publicly accessible, large cohort of rs-fMRI dataset in early-stage mild cognitive impairment (eMCI) diagnosis, which is one of the most challenging problems to the clinicians. By comparing with a conventional method, our method shows significant diagnostic performance improvement by almost 10%. This result demonstrates the effectiveness of deep learning in preclinical Alzheimer's disease diagnosis, based on the complex and high-dimensional voxel-wise spatiotemporal patterns of the resting-state brain functional connectomics. The framework provides a new but intuitive way to fully exploit deeply embedded diagnostic features from rs-fMRI for a better-individualized diagnosis of various neurological diseases.","keywords: {biomedical MRI;brain;cognition;convolutional neural nets;diseases;feature extraction;image classification;independent component analysis;learning (artificial intelligence);medical image processing;neurophysiology;modified independent component analysis;voxel-wise variability;BFN dynamics;paired 3D images;3D CNNs;static BFN features;rs-fMRI dataset;early-stage mild cognitive impairment diagnosis;deep learning;preclinical Alzheimer's disease diagnosis;high-dimensional voxel-wise;resting-state brain functional connectomics;diagnostic features;dynamic brain functional networks;early MCI detection;convolutional neural network;hierarchical spatial features;medical images;resting-state functional MRI;CNN framework;brain disease diagnosis;static functional connectivity;dynamic functional connectivity;multiple static BFNs;Convolutional neural networks;Neurophysiology;Brain;Deep learning;Feature extraction;Functional magnetic resonance imaging;Image classification;Diagnosis;convolutional neural networks;brain network;independent component analysis;mild cognitive impairment;deep learning;resting state;functional MRI},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8765628&isnumber=8979213,128,CNN,0.7607,MB-CNN,,MCI Detection,,,,1
"A. Bulat and G. Tzimiropoulos, ""Hierarchical Binary CNNs for Landmark Localization with Limited Resources,"" in IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 42, no. 2, pp. 343-356, 1 Feb. 2020.",doi: 10.1109/TPAMI.2018.2866051,"Abstract: Our goal is to design architectures that retain the groundbreaking performance of Convolutional Neural Networks (CNNs) for landmark localization and at the same time are lightweight, compact and suitable for applications with limited computational resources. To this end, we make the following contributions: (a) we are the first to study the effect of neural network binarization on localization tasks, namely human pose estimation and face alignment. We exhaustively evaluate various design choices, identify performance bottlenecks, and more importantly propose multiple orthogonal ways to boost performance. (b) Based on our analysis, we propose a novel hierarchical, parallel and multi-scale residual architecture that yields large performance improvement over the standard bottleneck block while having the same number of parameters, thus bridging the gap between the original network and its binarized counterpart. (c) We perform a large number of ablation studies that shed light on the properties and the performance of the proposed block. (d) We present results for experiments on the most challenging datasets for human pose estimation and face alignment, reporting in many cases state-of-the-art performance. (e) We further provide additional results for the problem of facial part segmentation. Code can be downloaded from https://www.adrianbulat.com/binary-cnn-landmarks.","keywords: {neural nets;pose estimation;prediction theory;real-time systems;landmark localization;groundbreaking performance;convolutional neural networks;neural network binarization;localization tasks;face alignment;performance bottlenecks;multiscale residual architecture;performance improvement;standard bottleneck block;binarized counterpart;ablation studies;hierarchical binary CNN;https://www.adrianbulat.com/binary-cnn-landmarks;human pose estimation;facial part segmentation;Pose estimation;Computer architecture;Face;Task analysis;Quantization (signal);Neural networks;Training;Binary convolutional neural networks;residual learning;landmark localization;human pose estimation;face alignment},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8444745&isnumber=8952810,129,binary CNN,0.9791,binary CNN,https://www.adrianbulat.com/binary-cnn-landmarks,"Landmark Localization, pose estimation",,"MPII, AFLW, AFLW-PIFA, AFLW2000-3D",2,
"A. M. Elbir and K. V. Mishra, ""Joint Antenna Selection and Hybrid Beamformer Design Using Unquantized and Quantized Deep Learning Networks,"" in IEEE Transactions on Wireless Communications, vol. 19, no. 3, pp. 1677-1688, March 2020.",doi: 10.1109/TWC.2019.2956146,"Abstract: In millimeter-wave communications, multiple-input-multiple-output (MIMO) systems use large antenna arrays to achieve high gain and spectral efficiency. These massive MIMO systems employ hybrid beamformers to reduce power consumption associated with fully digital beamforming in large arrays. Further savings in cost and power are possible through the use of subarrays. Unlike prior works that resort to large latency methods such as optimization and greedy search for subarray selection, we propose a deep-learning-based approach in order to overcome the complexity issue without causing significant performance loss. We formulate antenna selection and hybrid beamformer design as a classification/prediction problem for convolutional neural networks (CNNs). For antenna selection, the CNN accepts the channel matrix as input and outputs a subarray with optimal spectral efficiency. The resultant subarray channel matrix is then again fed to a CNN to obtain analog and baseband beamformers. We train the CNNs with several noisy channel matrices that have different channel statistics in order to achieve a robust performance at the network output. Numerical experiments show that our CNN framework provides an order better spectral efficiency and is 10 times faster than the conventional techniques. Further investigations with quantized-CNNs show that the proposed network, saved in no more than 5 bits, is also suited for digital mobile devices.","keywords: {array signal processing;convolutional neural nets;learning (artificial intelligence);millimetre wave communication;MIMO communication;power consumption;telecommunication computing;quantized-CNN;antenna arrays;multiple-input-multiple-output systems;millimeter-wave communications;unquantized quantized deep learning networks;joint antenna selection;network output;channel statistics;noisy channel matrices;baseband beamformers;resultant subarray channel matrix;optimal spectral efficiency;CNN;convolutional neural networks;hybrid beamformer design;performance loss;subarray selection;fully digital beamforming;power consumption;hybrid beamformers;massive MIMO systems;Antenna arrays;Phase shifters;Radio frequency;MIMO communication;Receiving antennas;Optimization;Antenna selection;CNN;deep learning;hybrid beamforming;massive MIMO},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8924932&isnumber=9031617,130,CNN,,,,,,MIMO,,
"J. Wang, L. Yu, K. R. Lai and X. Zhang, ""Tree-Structured Regional CNN-LSTM Model for Dimensional Sentiment Analysis,"" in IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 28, pp. 581-591, 2020.",doi: 10.1109/TASLP.2019.2959251,"Abstract: Dimensional sentiment analysis aims to recognize continuous numerical values in multiple dimensions such as the valence-arousal (VA) space. Compared to the categorical approach that focuses on sentiment classification such as binary classification (i.e., positive and negative), the dimensional approach can provide a more fine-grained sentiment analysis. This article proposes a tree-structured regional CNN-LSTM model consisting of two parts: regional CNN and LSTM to predict the VA ratings of texts. Unlike a conventional CNN which considers a whole text as input, the proposed regional CNN uses a part of the text as a region, dividing an input text into several regions such that the useful affective information in each region can be extracted and weighted according to their contribution to the VA prediction. Such regional information is sequentially integrated across regions using LSTM for VA prediction. By combining the regional CNN and LSTM, both local (regional) information within sentences and long-distance dependencies across sentences can be considered in the prediction process. To further improve performance, a region division strategy is proposed to discover task-relevant phrases and clauses to incorporate structured information into VA prediction. Experimental results on different corpora show that the proposed method outperforms lexicon-, regression-, conventional NN and other structured NN methods proposed in previous studies.","keywords: {convolutional neural nets;pattern classification;sentiment analysis;region division strategy;local information;regional information;VA prediction;conventional CNN;fine-grained sentiment analysis;sentiment classification;valence-arousal space;dimensional sentiment analysis;tree-structured regional CNN-LSTM model;Sentiment analysis;Feature extraction;Artificial neural networks;Predictive models;Analytical models;Kernel;Dimensional sentiment analysis;valence-arousal prediction;regional CNN-LSTM model;structured parsing},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8930925&isnumber=8938144,131,R-CNN-LSTM,,"wAM and wGM, AVR and MVR, CNN, RNN, LSTM, AttentionLSTM, Tree-Structured LSTM, CNN-LSTM, Two-LayerAttentionLSTM, Regional CNN-LSTM",,Sentiment Analysis,,"Stanford SentimentTreebank, EmoBank, The Valence and Arousal Facebook Posts, Chinese Valence-Arousal Texts",2,
"D. Karimi and S. E. Salcudean, ""Reducing the Hausdorff Distance in Medical Image Segmentation With Convolutional Neural Networks,"" in IEEE Transactions on Medical Imaging, vol. 39, no. 2, pp. 499-513, Feb. 2020.",doi: 10.1109/TMI.2019.2930068,"Abstract: The Hausdorff Distance (HD) is widely used in evaluating medical image segmentation methods. However, the existing segmentation methods do not attempt to reduce HD directly. In this paper, we present novel loss functions for training convolutional neural network (CNN)-based segmentation methods with the goal of reducing HD directly. We propose three methods to estimate HD from the segmentation probability map produced by a CNN. One method makes use of the distance transform of the segmentation boundary. Another method is based on applying morphological erosion on the difference between the true and estimated segmentation maps. The third method works by applying circular/spherical convolution kernels of different radii on the segmentation probability maps. Based on these three methods for estimating HD, we suggest three loss functions that can be used for training to reduce HD. We use these loss functions to train CNNs for segmentation of the prostate, liver, and pancreas in ultrasound, magnetic resonance, and computed tomography images and compare the results with commonly-used loss functions. Our results show that the proposed loss functions can lead to approximately 18-45% reduction in HD without degrading other segmentation performance criteria such as the Dice similarity coefficient. The proposed loss functions can be used for training medical image segmentation methods in order to reduce the large segmentation errors.","keywords: {biomedical MRI;biomedical ultrasonics;computerised tomography;convolutional neural nets;image segmentation;learning (artificial intelligence);liver;medical image processing;probability;convolutional neural network training;segmentation probability map;segmentation boundary;segmentation performance criteria;medical image segmentation;Hausdorff distance reduction;HD reduction;segmentation map estimation;CNN training;distance transform;morphological erosion;circular/spherical convolution kernels;ultrasound images;magnetic resonance images;computed tomography images;Image segmentation;Biomedical imaging;Training;Two dimensional displays;Sensitivity;Convolutional neural networks;Transforms;Hausdorff distance;loss functions;medical image segmentation;convolutional neural networks},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8767031&isnumber=8979213,132,CNN,,3D CNN,,,,,,1
"Y. Hong, J. J. F. Martinez and A. C. Fajardo, ""Day-Ahead Solar Irradiation Forecasting Utilizing Gramian Angular Field and Convolutional Long Short-Term Memory,"" in IEEE Access, vol. 8, pp. 18741-18753, 2020.",doi: 10.1109/ACCESS.2020.2967900,"Abstract: The operations of power systems are becoming more challenging on account of the high penetration of renewable power generation, including photovoltaic systems. One method for improving the power system operation involves making accurate forecasts of day-ahead solar irradiation, enabling operators to minimize uncertainty in managing the balance between generation and load. To overcome the limitations of Long Short-term Memory (LSTM) in a one-dimensional forecasting problem, this work proposes a novel method in forecasting solar irradiation by encoding time-series data into images using the Gramian Angular Field and the Convolutional LSTM (ConvLSTM) network. The pre-processed data become a five-dimensional input tensor that is perfectly suitable for ConvLSTM. The ConvLSTM network uses convolution operations in its input-to-state transition and state-to-state transition. The network thus enables time-series forecasting by a feature-rich approach, which ultimately provides competitive forecasting performance despite the use of a small dataset. The proposed method was evaluated in day-ahead solar irradiation forecasting using a univariate dataset of Global Horizontal Irradiation (GHI) data from Fuhai in Taiwan. The proposed method was resampled using 5×2-fold cross-validation, and assessed using the Wilcoxon signed-rank test to determine the statistical significance of the result. It outperformed benchmark methods such as Autoregressive Integrated Moving Average (ARIMA), Convolutional Neural Network cascaded with Long Short-term Memory (CNN-LSTM), and LSTM cascaded with a fully-connected (FC) network.","keywords: {convolutional neural nets;load forecasting;photovoltaic power systems;power engineering computing;recurrent neural nets;tensors;time series;power system operation;time-series data;convolutional LSTM network;five-dimensional input tensor;ConvLSTM network;convolution operations;time-series forecasting;Global Horizontal Irradiation data;convolutional neural network;day-ahead solar Irradiation forecasting;Gramian angular field;photovoltaic systems;renewable power generation;convolutional long short-term memory;Forecasting;Radiation effects;Logic gates;Training;Power generation;Graphics processing units;Weather forecasting;Day-ahead forecasting;ConvLSTM;gramian-angular field;global horizontal irradiation},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8963606&isnumber=8948470,133,CNN/LSTM,,,,,,,,
"P. Pisantanaroj et al., ""Automated Firearm Classification From Bullet Markings Using Deep Learning,"" in IEEE Access, vol. 8, pp. 78236-78251, 2020.",doi: 10.1109/ACCESS.2020.2989673,"Abstract: Firearm violence is one of the leading causes of death in many countries around the world, including Thailand. This work proposes a fast and accurate automated method to classify firearm brands from bullet markings. Specifically, a panoramic image of a bullet collected from a crime scene was captured using a developed mobile phone application and custom-built portable hardware. The top three state-of-the-art CNNs pretrained on ImageNet-DenseNet121, ResNet50, and Xception-were further trained on the same training set, which was composed of 718 bullets collected from eight different firearm brands-Beretta, Browning, CZ, Glock, Norinco, Ruger, Sig Sauer, and Smith & Wesson-using a five-fold cross validation technique. DenseNet121 provided the highest AUC of 0.99 for CZ classification (the most common registered firearm brand in Thailand) and the highest average AUC for the eight firearm brands (0.9780 ± 0.0130 SD), which was significantly higher than those of ResNet50 and Xception. In addition, there were no interaction effects between the CNN model and firearm brand on AUC. DenseNet121, which had the highest AUC, was evaluated on the test set (72 bullets), and the results showed that the Beretta and CZ classifications had the lowest accuracy (91.18%), followed by the Browning and Norinco classifications (96.88%), whereas the Glock, Ruger, Sig Sauer, and Smith & Wesson classifications had the highest accuracy (98.41%). These results suggest that the developed mobile phone application based on a deep learning algorithm and the custom-built portable hardware have promising potential for use at crime scenes to classify firearms from bullet markings. By narrowing down the list of suspects, this convenient approach can potentially accelerate bullet identification processes for many forensic science examiners.","keywords: {convolutional neural nets;image classification;learning (artificial intelligence);military computing;mobile computing;projectiles;weapons;automated firearm classification;bullet markings;firearm violence;Thailand;mobile phone application;ImageNet;ResNet50;Xception;five-fold cross validation technique;CZ classification;Norinco classifications;Smith & Wesson classifications;deep learning;bullet identification processes;DenseNet121;firearm brand;panoramic image;Browning classifications;Beretta classifications;Sig Sauer classifications;Ruger classifications;Glock classifications;Forensics;Machine learning;Surface topography;Three-dimensional displays;Correlation;Feature extraction;Forensic science;automated firearm classification;9 mm bullet marking;densely connected convolutional network},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9076037&isnumber=8948470,134,CNN,0.99 auc,CNN,,,,,2,
"F. Paredes-Vallés, K. Y. W. Scheper and G. C. H. E. de Croon, ""Unsupervised Learning of a Hierarchical Spiking Neural Network for Optical Flow Estimation: From Events to Global Motion Perception,"" in IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 42, no. 8, pp. 2051-2064, 1 Aug. 2020.",doi: 10.1109/TPAMI.2019.2903179,"Abstract: The combination of spiking neural networks and event-based vision sensors holds the potential of highly efficient and high-bandwidth optical flow estimation. This paper presents the first hierarchical spiking architecture in which motion (direction and speed) selectivity emerges in an unsupervised fashion from the raw stimuli generated with an event-based camera. A novel adaptive neuron model and stable spike-timing-dependent plasticity formulation are at the core of this neural network governing its spike-based processing and learning, respectively. After convergence, the neural architecture exhibits the main properties of biological visual motion systems, namely feature extraction and local and global motion perception. Convolutional layers with input synapses characterized by single and multiple transmission delays are employed for feature and local motion perception, respectively; while global motion selectivity emerges in a final fully-connected layer. The proposed solution is validated using synthetic and real event sequences. Along with this paper, we provide the cuSNN library, a framework that enables GPU-accelerated simulations of large-scale spiking neural networks. Source code and samples are available at https://github.com/tudelft/cuSNN.","keywords: {cameras;computer vision;convolutional neural nets;feature extraction;graphics processing units;image sensors;image sequences;unsupervised learning;visual perception;unsupervised learning;hierarchical spiking neural network;global motion perception;event-based vision sensors;high-bandwidth optical flow estimation;hierarchical spiking architecture;unsupervised fashion;event-based camera;spike-timing-dependent plasticity formulation;spike-based processing;neural architecture;biological visual motion systems;local motion perception;global motion selectivity;synthetic event sequences;real event sequences;adaptive neuron model;cuSNN library;Neurons;Visualization;Biomedical optical imaging;Optical sensors;Biological system modeling;Biological information theory;Vision sensors;Event-based vision;feature extraction;motion detection;neural nets;neuromorphic computing;unsupervised learning},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8660483&isnumber=9130977,135,SNN,,cuSNN,https://github.com/tudelft/cuSNN,,,????,,
"Y. Sun, B. Xue, M. Zhang and G. G. Yen, ""Completely Automated CNN Architecture Design Based on Blocks,"" in IEEE Transactions on Neural Networks and Learning Systems, vol. 31, no. 4, pp. 1242-1254, April 2020.",doi: 10.1109/TNNLS.2019.2919608,"Abstract: The performance of convolutional neural networks (CNNs) highly relies on their architectures. In order to design a CNN with promising performance, extensive expertise in both CNNs and the investigated problem domain is required, which is not necessarily available to every interested user. To address this problem, we propose to automatically evolve CNN architectures by using a genetic algorithm (GA) based on ResNet and DenseNet blocks. The proposed algorithm is completely automatic in designing CNN architectures. In particular, neither preprocessing before it starts nor postprocessing in terms of CNNs is needed. Furthermore, the proposed algorithm does not require users with domain knowledge on CNNs, the investigated problem, or even GAs. The proposed algorithm is evaluated on the CIFAR10 and CIFAR100 benchmark data sets against 18 state-of-the-art peer competitors. Experimental results show that the proposed algorithm outperforms the state-of-the-art CNNs hand-crafted and the CNNs designed by automatic peer competitors in terms of the classification performance and achieves a competitive classification accuracy against semiautomatic peer competitors. In addition, the proposed algorithm consumes much less computational resource than most peer competitors in finding the best CNN architectures.","keywords: {convolutional neural nets;genetic algorithms;pattern classification;CIFAR10 benchmark data set;CIFAR100 benchmark data set;DenseNet block;ResNet block;classification performance;automatic peer competitors;genetic algorithm;CNN architectures;convolutional neural networks;automated CNN architecture design;Computer architecture;Genetic algorithms;Evolutionary computation;Encoding;Optimization;Sociology;Statistics;Automatic architecture design;convolutional neural networks (CNNs);evolutionary deep learning;genetic algorithms (GAs);neural networks},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8742788&isnumber=9056859,136,R-CNN,88.71 F1,SWCVAE,,Detection of Industrial Robots,,Endoder_decoder,,
"S. Muhammad Usman, S. Khalid and M. H. Aslam, ""Epileptic Seizures Prediction Using Deep Learning Techniques,"" in IEEE Access, vol. 8, pp. 39998-40007, 2020.",doi: 10.1109/ACCESS.2020.2976866,"Abstract: Epilepsy is a very common neurological disease that has affected more than 65 million people worldwide. In more than 30 % of the cases, people affected by this disease cannot be cured with medicines or surgery. However, predicting a seizure before it actually occurs can help in its prevention; through therapeutic intervention. Studies have observed that abnormal activity inside the brain begins a few minutes before the start of a seizure, which is known as preictal state. Many researchers have tried to find a way for predicting this preictal state of a seizure but an effective prediction in terms of high sensitivity and specificity still remains a challenge. The current study, proposes a seizure prediction system that employs deep learning methods. This method includes preprocessing of scalp EEG signals, automated features extraction; using convolution neural network and classification with the support of vector machines. The proposed method has been applied on 24 subjects of scalp EEG dataset of CHBMIT resulting in successfully achieving an average sensitivity and specificity of 92.7% and 90.8% respectively.","keywords: {convolutional neural nets;diseases;electroencephalography;feature extraction;learning (artificial intelligence);medical disorders;medical signal processing;neurophysiology;seizure prediction system;deep learning methods;epileptic seizures prediction;deep learning techniques;neurological disease;therapeutic intervention;preictal state prediction;scalp EEG signals;automated features extraction;convolution neural network;Electroencephalography;Feature extraction;Scalp;Machine learning;Prediction methods;Support vector machines;Electrodes;Epilepsy prediction;seizures;preictal state;scalp EEG;intracranial EEG;deep learning;CNN},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9016244&isnumber=8948470,137,CNN,"0.927 presicion, 0.908 recall",CNN,,Epileptic Seizures Prediction,,,,4
"R. Liu, B. Yang and A. G. Hauptmann, ""Simultaneous Bearing Fault Recognition and Remaining Useful Life Prediction Using Joint-Loss Convolutional Neural Network,"" in IEEE Transactions on Industrial Informatics, vol. 16, no. 1, pp. 87-96, Jan. 2020.",doi: 10.1109/TII.2019.2915536,"Abstract: Fault diagnosis and remaining useful life (RUL) prediction are always two major issues in modern industrial systems, which are usually regarded as two separated tasks to make the problem easier but ignore the fact that there are certain information of these two tasks that can be shared to improve the performance. Therefore, to capture common features between different relative problems, a joint-loss convolutional neural network (JL-CNN) architecture is proposed in this paper, which can implement bearing fault recognition and RUL prediction in parallel by sharing the parameters and partial networks, meanwhile keeping the output layers of different tasks. The JL-CNN is constructed based on a CNN, which is a widely used deep learning method because of its powerful feature extraction ability. During optimization phase, a JL function is designed to enable the proposed approach to learn the diagnosis-prognosis features and improve generalization while reducing the overfitting risk and computation cost. Moreover, because the information behind the signals of different problems has been shared and exploited deeper, the generalization and the accuracy of results can also be improved. Finally, the effectiveness of the JL-CNN method is validated by run-to-failure dataset. Compared with support vector regression and traditional CNN, the mean-square-error of the proposed method decreases 82.7% and 24.9%, respectively. Therefore, results and comparisons show that the proposed method can be applied for the intercrossed applications between fault diagnosis and RUL prediction.","keywords: {convolutional neural nets;fault diagnosis;feature extraction;learning (artificial intelligence);mean square error methods;mechanical engineering computing;neural net architecture;remaining life assessment;rolling bearings;roller bearings;mean-square-error;joint-loss convolutional neural network architecture;remaining useful life prediction;RUL prediction;JL-CNN method;diagnosis-prognosis features;JL function;feature extraction;deep learning method;modern industrial systems;fault diagnosis;bearing fault recognition;Task analysis;Fault diagnosis;Convolution;Hidden Markov models;Feature extraction;Neural networks;Mathematical model;Bearing;deep learning;fault diagnosis;joint-loss (JL) learning;remaining useful life (RUL) prediction},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8709822&isnumber=8952812,138,CNN,1,JL-CNN,,Bearing Fault Recognition,,,,3
"Y. Zhang and T. Cheng, ""A Deep Learning Approach to Infer Employment Status of Passengers by Using Smart Card Data,"" in IEEE Transactions on Intelligent Transportation Systems, vol. 21, no. 2, pp. 617-629, Feb. 2020.",doi: 10.1109/TITS.2019.2896460,"Abstract: Understanding the employment status of passengers in public transit systems is significant for transport operators in many real applications such as forecasting travel demand and providing personalized transportation service. This paper develops a deep learning approach to infer a passenger's employment status by using smart card data (SCD) with a household survey. This paper first extracts an individual passenger's weekly travel patterns in different travel modes from the raw SCD as a three-dimensional image. A deep learning architecture, called a thresholding multi-channel convolutional neural network, was developed to predict an individual's employment status. The approach proposed here solves two critical problems of using the SCD for employment status studies. First, it automatically incorporates learning temporal features in different travel modes without the need for handcrafted travel feature design. Second, it considers the class-imbalance problem by leveraging the ensemble of oversampling and thresholding techniques. By applying our approach to a real dataset collected from the metropolitan area of London, U.K., about 72% of passengers were correctly categorized into six types of employment statuses. The promising results show the tight correlation between temporal travel behavior, mode choice, and social-demographic roles. To the best of our knowledge, this is the first paper to infer employment status by using the SCD.","keywords: {convolutional neural nets;learning (artificial intelligence);public transport;smart cards;travel industry;smart card data;travel demand forecasting;SCD;deep learning architecture;handcrafted travel feature design;temporal travel behavior;personalized transportation service;passenger employment status;public transit systems;thresholding multichannel convolutional neural network;Employment;Feature extraction;Deep learning;Predictive models;Smart cards;Transportation;Correlation;Deep learning;employment status inference;travel mode choice;smart card data;temporal travel behavior},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8645820&isnumber=8979479,139,CNN,0.72,MC-CNN,,Employment Status of Passengers by Using Smart Card,"Londons Oyster Card Data, LTDS, Employment Status Data",,1,
"R. Zhou, F. Liu and C. W. Gravelle, ""Deep Learning for Modulation Recognition: A Survey With a Demonstration,"" in IEEE Access, vol. 8, pp. 67366-67376, 2020.",doi: 10.1109/ACCESS.2020.2986330,"Abstract: In this paper, we review a variety of deep learning algorithms and models for modulation recognition and classification of wireless communication signals. Specifically, deep learning (DL) has shown overwhelming advantages in computer vision, robotics, and voice recognition. Recently, DL has been proposed to apply to wireless communications for signal detection and classification in order to better learn the active users for electromagnetic spectrum sharing purposes. Therefore, we aim to provide a survey on the most recent techniques which use DL for recognizing and classifying a wireless signal. We focus on the most widely used DL models, emphasize the advantages and limitations, and discuss the challenges as well as future directions. In addition, we also apply a DL algorithm, convolutional neural network (CNN), to demonstrate the feasibility of using CNN to recognize and classify the over-the-air wireless signals using Mathworks DL toolbox with PlutoSDR and Universal Software Radio Peripheral (USRP), respectively.","keywords: {convolutional neural nets;learning (artificial intelligence);radio spectrum management;signal classification;signal detection;software radio;telecommunication computing;wireless signal;DL algorithm;over-the-air wireless signals;modulation recognition;deep learning algorithms;signal detection;active users;electromagnetic spectrum sharing purposes;wireless communication signal classification;Wireless communication;Computational modeling;Binary phase shift keying;Machine learning;Convolutional neural networks;Convolutional neural network;deep learning;deep belief network;modulation recognition;recurrent neural network;software defined radio},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9058656&isnumber=8948470,140,CNN/LSTM,,,,WIFI Modulation Recognition,,review,,
"X. Fu, B. Liang, Y. Huang, X. Ding and J. Paisley, ""Lightweight Pyramid Networks for Image Deraining,"" in IEEE Transactions on Neural Networks and Learning Systems, vol. 31, no. 6, pp. 1794-1807, June 2020.",doi: 10.1109/TNNLS.2019.2926481,"Abstract: Existing deep convolutional neural networks (CNNs) have found major success in image deraining, but at the expense of an enormous number of parameters. This limits their potential applications, e.g., in mobile devices. In this paper, we propose a lightweight pyramid networt (LPNet) for single-image deraining. Instead of designing a complex network structure, we use domain-specific knowledge to simplify the learning process. In particular, we find that by introducing the mature Gaussian-Laplacian image pyramid decomposition technology to the neural network, the learning problem at each pyramid level is greatly simplified and can be handled by a relatively shallow network with few parameters. We adopt recursive and residual network structures to build the proposed LPNet, which has less than 8K parameters while still achieving the state-of-the-art performance on rain removal. We also discuss the potential value of LPNet for other low- and high-level vision tasks.","keywords: {adaptive filters;computer vision;convolutional neural nets;Gaussian processes;image enhancement;image representation;image restoration;learning (artificial intelligence);video signal processing;residual network structures;LPNet;lightweight pyramid networks;deep convolutional neural networks;enormous number;mobile devices;lightweight pyramid networt;single-image deraining;complex network structure;domain-specific knowledge;learning process;mature Gaussian-Laplacian image pyramid decomposition technology;neural network;learning problem;pyramid level;relatively shallow network;recursive network structures;Rain;Laplace equations;Feature extraction;Learning systems;Task analysis;Knowledge engineering;Computer vision;Deep convolutional neural network (CNN);image pyramid;lightweight networks;rain removal;residual learning},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8767931&isnumber=9106620,141,Pyramid CNN,,LPNet,,Deraining,,,1,
"S. Wang, Z. Li, S. Zhang, M. Jiang, X. Wang and Z. Wei, ""Molecular Property Prediction Based on a Multichannel Substructure Graph,"" in IEEE Access, vol. 8, pp. 18601-18614, 2020.",doi: 10.1109/ACCESS.2020.2968535,"Abstract: Molecular property prediction is important to drug design. With the development of artificial intelligence, deep learning methods are effective for extracting molecular features. In this paper, we propose a multichannel substructure-graph gated recurrent unit (GRU) architecture, which is a novel GRU-based neural network with attention mechanisms applied to molecular substructures to learn and predict properties. In the architecture, molecular features are extracted at the node level and molecule level for capturing fine-grained and coarse-grained information. In addition, three bidirectional GRUs are adopted to extract the features on three channels to generate the molecular representations. Different attention weights are assigned to the entities in the molecule to evaluate their contributions. Experiments are implemented to compare our model with benchmark models in molecular property prediction for both regression and classification tasks, and the results show that our model has strong robustness and generalizability.","keywords: {bioinformatics;feature extraction;graph theory;learning (artificial intelligence);neural net architecture;pattern classification;recurrent neural nets;regression analysis;molecular property prediction;deep learning;recurrent unit architecture;molecular substructures;molecular representations;GRU-based neural network;drug design;artificial intelligence;molecular feature extraction;multichannel substructure graph gated recurrent unit architecture;regression tasks;classification tasks;drug discovery;Feature extraction;Chemicals;Joining processes;Deep learning;Logic gates;Convolutional neural networks;Molecular graph;molecular property prediction;substructure-graph},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8964313&isnumber=8948470,142,GRU,.75 AUC,graph BiGRU,https://github.com/ShuangWangCN/MSGG,Molecular Property Prediction,"PDBbind, BACE, ESOL, BBBP",,1,
"K. Wang, X. Peng, J. Yang, D. Meng and Y. Qiao, ""Region Attention Networks for Pose and Occlusion Robust Facial Expression Recognition,"" in IEEE Transactions on Image Processing, vol. 29, pp. 4057-4069, 2020.",doi: 10.1109/TIP.2019.2956143,"Abstract: Occlusion and pose variations, which can change facial appearance significantly, are two major obstacles for automatic Facial Expression Recognition (FER). Though automatic FER has made substantial progresses in the past few decades, occlusion-robust and pose-invariant issues of FER have received relatively less attention, especially in real-world scenarios. This paper addresses the real-world pose and occlusion robust FER problem in the following aspects. First, to stimulate the research of FER under real-world occlusions and variant poses, we annotate several in-the-wild FER datasets with pose and occlusion attributes for the community. Second, we propose a novel Region Attention Network (RAN), to adaptively capture the importance of facial regions for occlusion and pose variant FER. The RAN aggregates and embeds varied number of region features produced by a backbone convolutional neural network into a compact fixed-length representation. Last, inspired by the fact that facial expressions are mainly defined by facial action units, we propose a region biased loss to encourage high attention weights for the most important regions. We validate our RAN and region biased loss on both our built test datasets and four popular datasets: FERPlus, AffectNet, RAF-DB, and SFEW. Extensive experiments show that our RAN and region biased loss largely improve the performance of FER with occlusion and variant pose. Our method also achieves state-of-the-art results on FERPlus, AffectNet, RAF-DB, and SFEW. Code and the collected test data will be publicly available.","keywords: {convolutional neural nets;face recognition;image representation;occlusion robust facial expression recognition;automatic facial expression recognition;automatic FER;pose-invariant issues;occlusion robust FER problem;in-the-wild FER datasets;RAN;pose variant FER;backbone convolutional neural network;facial action units;region biased loss;region attention networks;FERPlus datasets;RAF-DB datasets;SFEW datasets;AffectNet datasets;Face;Face recognition;Feature extraction;Face detection;Task analysis;Image recognition;Aggregates;Facial expression recognition;occlusion-robust and pose-invariant;region attention network;deep convolutional neural networks},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8974606&isnumber=8835130,143,R-CNN attention,0.8916,RAN,https://github.com/kaiwang960112/Challengecondition-FER-dataset,Emotion Recognition,FER,,2,
"M. Dong, Y. Li, X. Tang, J. Xu, S. Bi and Y. Cai, ""Variable Convolution and Pooling Convolutional Neural Network for Text Sentiment Classification,"" in IEEE Access, vol. 8, pp. 16174-16186, 2020.",doi: 10.1109/ACCESS.2020.2966726,"Abstract: With the popularity of the internet, the expression of emotions and methods of communication are becoming increasingly abundant, and most of these emotions are transmitted in text form. Text sentiment classification research mainly includes three methods based on sentiment dictionaries, machine learning and deep learning. In recent years, many deep learning-based works have used TextCNN (text convolution neural network) to extract text semantic information for text sentiment analysis. However, TextCNN only considers the length of the sentence when extracting semantic information. It ignores the semantic features between word vectors and only considers the maximum feature value of the feature image in the pooling layer without considering other information. Therefore, in this paper, we propose a convolutional neural network based on multiple convolutions and pooling for text sentiment classification (variable convolution and pooling convolution neural network, VCPCNN). There are three contributions in this paper. First, a multiconvolution and pooling neural network is proposed for the TextCNN network structure. Second, four convolution operations are introduced in the word embedding dimension or direction, which are helpful for mining the local features on the semantic dimensions of word vectors. Finally, average pooling is introduced in the pooling layer, which is beneficial for saving the important feature information of the extracted features. The verification test was carried out on four emotional datasets, including English emotional polarity, Chinese emotional polarity, Chinese subjective and objective emotion and Chinese multicategory. Our approach is effective in that its result was up to 1.97% higher than that of the TextCNN network.","keywords: {convolutional neural nets;data mining;feature extraction;learning (artificial intelligence);natural language processing;pattern classification;text analysis;pooling layer;pooling convolution neural network;pooling neural network;TextCNN network structure;convolution operations;pooling convolutional neural network;text sentiment classification research;sentiment dictionaries;deep learning-based works;text convolution neural network;text semantic information;text sentiment analysis;semantic features;English emotional polarity dataset;Chinese emotional polarity dataset;Chinese subjective and objective emotion dataset;Chinese multicategory dataset;Feature extraction;Convolution;Dictionaries;Semantics;Data mining;Sentiment analysis;Deep learning;Text sentiment classification;deep learning;CNN},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8960358&isnumber=8948470,144,TextCNN,0.7887,VCPCNN,,Sentiment Classification,"EmoTweet-28, Kaggle film comment dataset, Stanford emotion dataset, Yelp",,1,
"A. Kumar, M. Fulham, D. Feng and J. Kim, ""Co-Learning Feature Fusion Maps From PET-CT Images of Lung Cancer,"" in IEEE Transactions on Medical Imaging, vol. 39, no. 1, pp. 204-217, Jan. 2020.",doi: 10.1109/TMI.2019.2923601,"Abstract: The analysis of multi-modality positron emission tomography and computed tomography (PET-CT) images for computer-aided diagnosis applications (e.g., detection and segmentation) requires combining the sensitivity of PET to detect abnormal regions with anatomical localization from CT. Current methods for PET-CT image analysis either process the modalities separately or fuse information from each modality based on knowledge about the image analysis task. These methods generally do not consider the spatially varying visual characteristics that encode different information across different modalities, which have different priorities at different locations. For example, a high abnormal PET uptake in the lungs is more meaningful for tumor detection than physiological PET uptake in the heart. Our aim is to improve the fusion of the complementary information in multi-modality PET-CT with a new supervised convolutional neural network (CNN) that learns to fuse complementary information for multi-modality medical image analysis. Our CNN first encodes modalityspecific features and then uses them to derive a spatially varying fusion map that quantifies the relative importance of each modality's feature across different spatial locations. These fusion maps are then multiplied with the modalityspecific feature maps to obtain a representation of the complementary multi-modality information at different locations, which can then be used for image analysis. We evaluated the ability of our CNN to detect and segment multiple regions (lungs, mediastinum, and tumors) with different fusion requirements using a dataset of PET-CT images of lung cancer. We compared our method to baseline techniques for multi-modality image fusion (fused inputs (FSs), multi-branch (MB) techniques, and multi-channel (MC) techniques) and segmentation. Our findings show that our CNN had a significantly higher foreground detection accuracy (99.29%, p <; 0.05) than the fusion baselines (FS: 99.00%, MB: 99.08%, and TC: 98.92%) and a significantly higher Dice score (63.85%) than the recent PET-CT tumor segmentation methods.","keywords: {cancer;computerised tomography;image classification;image fusion;image segmentation;learning (artificial intelligence);lung;medical image processing;neural nets;positron emission tomography;tumours;fusion requirements;PET-CT images;lung cancer;CNN;fusion baselines;recent PET-CT tumor segmentation methods;fusion maps;multimodality positron emission tomography;computed tomography images;computer-aided diagnosis applications;PET-CT image analysis;image analysis task;encode different information;high abnormal PET uptake;tumor detection;physiological PET uptake;complementary information;multimodality PET-CT;multimodality medical image analysis;modalityspecific features;spatially varying fusion map;modality;spatial locations;modalityspecific feature maps;complementary multimodality information;Computed tomography;Tumors;Lung;Image segmentation;Biomedical imaging;Cancer;Multi-modality imaging;deep learning;fusion learning;PET-CT},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8737963&isnumber=8946770,145,CNN,0.99,CNN,,Lung Cancer,,CT,,1
"L. Xu, S. Lv, Y. Deng and X. Li, ""A Weakly Supervised Surface Defect Detection Based on Convolutional Neural Network,"" in IEEE Access, vol. 8, pp. 42285-42296, 2020.",doi: 10.1109/ACCESS.2020.2977821,"Abstract: Surface defect detection is a critical task in product quality assurance for manufacturing lines. The deep learning-based methods recently developed for defect detection are typically trained using a supervised learning strategy and large defect sample sets. Conventional methods often require additional pixel-level labeling or bounding boxes to predict the location of defects. However, the number of required samples and the time-intensive annotation process limits the practical use of these algorithms. As such, this study proposes a weakly supervised detection framework in which a CNN model is trained to identify surface cracks in motor commutators. The model was trained using small subsets of defect samples (~5-30) and does not require a pre-trained network. This approach consists of localization and decision networks that simultaneously predict both the location and probability of defects. A new loss function was also developed to identify abnormal regions in a sample with accessible image-level labels. A collaboration learning strategy was then applied to utilize the loss function and compensate for imbalances at the pixel level. Experimental results using a small number of image-level training labels from a real industrial dataset exhibited a 99.5% recognition accuracy, which is comparable to relevant methods using pixel-level labels.","keywords: {automatic optical inspection;convolutional neural nets;feature extraction;image classification;production engineering computing;supervised learning;image-level training labels;pixel level;collaboration learning strategy;loss function;decision networks;pre-trained network;surface cracks;CNN model;time-intensive annotation process;pixel-level labeling;defect sample sets;supervised learning strategy;deep learning-based methods;manufacturing lines;product quality assurance;convolutional neural network;weakly supervised surface defect detection;Task analysis;Training;Image segmentation;Inspection;Labeling;Feature extraction;Supervised learning;Surface defect detection;quality control;weak supervision;convolutional neural network;localization network},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9020085&isnumber=8948470,146,CNN,0.995,CNN,,Surface Defect Detection,,,,
"Y. Wang et al., ""Breast Cancer Image Classification via Multi-Network Features and Dual-Network Orthogonal Low-Rank Learning,"" in IEEE Access, vol. 8, pp. 27779-27792, 2020.",doi: 10.1109/ACCESS.2020.2964276,"Abstract: Histopathological image analysis is an important technique for early diagnosis and detection of breast cancer in clinical practice. However, it has limited efficiency and thus the detection of breast cancer is still an open issue in medical image analysis. To improve the early diagnostic accuracy of breast cancer and reduce the workload of doctors, we devise a classification framework based on histology images by combining deep learning with machine learning methodologies in this paper. Specifically, we devise a multi-network feature extraction model by using pre-trained deep convolution neural networks (DCNNs), develop an effective feature dimension reduction method and train an ensemble support vector machine (E-SVM). First, we preprocess the histological images via scale transformation and color enhancement methods. Second, the multi-network features are extracted by using four pre-trained DCNNs (e.g., DenseNet-121, ResNet-50, multi-level InceptionV3, and multi-level VGG-16). Third, a feature selection method via dual-network orthogonal low-rank learning (DOLL) is further developed for performance boosting and overfitting alleviation. Finally, an E-SVM is trained via fused features and voting strategy to perform the classification task, which classifies the images into four classes (i.e., benign, in situ carcinomas, invasive carcinomas, and normal). We evaluate the proposed method on the public ICIAR 2018 Challenge dataset of histology images of breast cancer and achieve a high classification accuracy of 97.70%. Experimental results show that our method can achieve quite promising performance and outperform state-of-the-art methods.","keywords: {cancer;convolutional neural nets;feature extraction;feature selection;image classification;image colour analysis;image enhancement;learning (artificial intelligence);medical image processing;support vector machines;medical image analysis;histology images;deep learning;multinetwork feature extraction model;deep convolution neural networks;feature dimension reduction method;histological images;color enhancement methods;multinetwork features;pre-trained DCNNs;multilevel VGG-16;feature selection method;low-rank learning;breast cancer image classification;histopathological image analysis;dual-network orthogonal low-rank learning;ensemble support vector machine;Breast cancer;Feature extraction;Deep learning;Image analysis;Convolution;Breast cancer image classification;deep convolutional neural network;multi-network features;low-rank learning;ensemble support vector machine},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8950452&isnumber=8948470,147,CNN,0.977,CNN,,Breast Cancer detection,ICIAR 2018,,1,1
"M. U. Salur and I. Aydin, ""A Novel Hybrid Deep Learning Model for Sentiment Classification,"" in IEEE Access, vol. 8, pp. 58080-58093, 2020.",doi: 10.1109/ACCESS.2020.2982538,"Abstract: A massive use of social media platforms such as Twitter and Facebook by omnifarious organizations has increased the critical individual feedback on the situation, events, products, and services. However, sentiment classification plays an important role in the user's feedback evaluation. At present, deep learning such as long short-term memory (LSTM), gated recurrent unit (GRU), bidirectionally long short-term memory (BiLSTM) or convolutional neural network (CNN) are prevalently preferred in sentiment classification. Moreover, word embedding such as Word2Vec and FastText is closely examined in text for mapping closely related to the vectors of real numbers. However, both deep learning and word embedding methods have strengths and weaknesses. Combining the strengths of the deep learning models with that of word embedding is the key to high-performance sentiment classification in the field of natural language processing (NLP). In the present study, we propose a novel hybrid deep learning model that strategically combines different word embedding (Word2Vec, FastText, character-level embedding) with different deep learning methods (LSTM, GRU, BiLSTM, CNN). The proposed model extracts features of different deep learning methods of word embedding, combines these features and classifies texts in terms of sentiment. To verify the performance of the proposed model, several deep learning models called basic models were created to perform series of experiments. By comparing, the performance of the proposed model with that of past studies, the proposed model offers better sentiment classification performance.","keywords: {feature extraction;learning (artificial intelligence);natural language processing;pattern classification;recurrent neural nets;sentiment analysis;social networking (online);hybrid deep learning model;social media platforms;critical individual feedback;short-term memory;gated recurrent unit;convolutional neural network;word embedding methods;deep learning models;high-performance sentiment classification;character-level embedding;sentiment classification performance;deep learning methods;word embedding;LSTM;GRU;BiLSTM;CNN;Deep learning;Feature extraction;Sentiment analysis;Numerical models;Twitter;Sentiment classification;Turkish tweets analysis;hybrid model;word embedding;deep learning;LSTM;CNN},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9044300&isnumber=8948470,148,LSTM,0.8214,"LSTM, GRU, BiLSTM, CNN",,Sentiment Classification,GSM,,,
"L. Dong et al., ""Very High Resolution Remote Sensing Imagery Classification Using a Fusion of Random Forest and Deep Learning Technique—Subtropical Area for Example,"" in IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, vol. 13, pp. 113-128, 2020.",doi: 10.1109/JSTARS.2019.2953234,"Abstract: Recently, convolutional neural networks (CNNs) showed excellent performance in many tasks, such as computer vision and remote sensing semantic segmentation. Especially, the ability to learn high-representation features of CNN draws much attention. And random forest (RF) algorithm, on the other hand, is widely applied for variables selection, classification, and regression. Based on the previous fusion models that fused CNN with the other models, such as conditional random fields (CRFs), support vector machine (SVM), and RF, this article tested a method based on the fusion of an RF classifier and the CNN for a very high resolution remote sensing (VHRRS) based forests mapping. The study area is located in the south of China and the main purpose was to precisely distinguish Lei bamboo forests from the other subtropical forests. The main novelties of this article are as follows. First, a test was conducted to confirm if a fusion of CNN and RF make an improvement in the VHRRS information extraction. Second, based on RF, variables with high importance were selected. Then, a test was again conducted to confirm if the learning from the selected variables will further give better results.","keywords: {computer vision;convolutional neural nets;feature extraction;geophysical image processing;image classification;image segmentation;learning (artificial intelligence);regression analysis;remote sensing;support vector machines;vegetation mapping;remote sensing semantic segmentation;high-representation features;CNN;random forest algorithm;variables selection;fusion models;conditional random fields;support vector machine;RF classifier;high resolution remote sensing based forests mapping;Lei bamboo forests;subtropical forests;high resolution remote sensing imagery classification;deep learning technique;subtropical area;convolutional neural networks;computer vision;Radio frequency;Forestry;Remote sensing;Vegetation mapping;Spatial resolution;Feature extraction;Random forests;Classification;convolutional neural networks (CNNs);random forest (RF);subtropical forest;very high resolution remote sensing (VHRRS)},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8935521&isnumber=8994817,149,CNN,0.96:0.99,CNN,,Remote Sensing,,,1,
"R. Xie et al., ""Integrating Image-Based and Knowledge-Based Representation Learning,"" in IEEE Transactions on Cognitive and Developmental Systems, vol. 12, no. 2, pp. 169-178, June 2020.",doi: 10.1109/TCDS.2019.2906685,"Abstract: A variety of brain areas is involved in language understanding and generation, accounting for the scope of language that can refer to many real-world matters. In this paper, we investigate how regularities among real-world entities impact emergent language representations. Specifically, we consider knowledge bases, which represent entities and their relations as structured triples, and image representations, which are obtained via deep convolutional networks. We combine these sources of information to learn representations of an image-based knowledge representation learning (IKRL) model. An attention mechanism lets more informative images contribute more to the image-based representations. Evaluation results show that the model outperforms all baselines on the tasks of knowledge graph (KG) completion and triple classification. In analyzing the learned models, we found that the structure-based and image-based representations integrate different aspects of the entities and the attention mechanism provides robustness during learning.","keywords: {convolutional neural nets;image representation;knowledge representation;learning (artificial intelligence);natural language processing;language understanding;language representations;knowledge bases;image representations;image-based knowledge representation learning;informative images;image-based representation learning;deep convolutional networks;attention mechanism;Visualization;Knowledge representation;Brain modeling;Task analysis;Head;Knowledge based systems;Computational modeling;Attention mechanisms and development;embodied cognition;generation of representation during development},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8689107&isnumber=9113770,150,,,,,,,????,3,
"W. Kong, Z. Y. Dong, B. Wang, J. Zhao and J. Huang, ""A Practical Solution for Non-Intrusive Type II Load Monitoring Based on Deep Learning and Post-Processing,"" in IEEE Transactions on Smart Grid, vol. 11, no. 1, pp. 148-160, Jan. 2020.",doi: 10.1109/TSG.2019.2918330,"Abstract: This paper presents a practical and effective non-intrusive load monitoring (NILM) solution to estimate the energy consumption for common multi-functional home appliances (type II appliances). Type II home appliances are usually the most challenging cases in load disaggregation because they usually have multiple power consumption states, complex state transitions, and multiple operational modes. The practicality of the proposed deep convolutional neural networks-based approach comes from the minimum prerequisite information from the previously unseen customers. That means no submetered information for the target appliances in the NILM service subscriber's house is needed to provide appliance level identification and estimate under the proposed architecture. Our solution also includes a novel post-processing technique that boost the performance significantly on type II home appliances. The effectiveness of the solution is evaluated on a public dataset to allow comparison with the previous works.","keywords: {convolutional neural nets;domestic appliances;home automation;home computing;learning (artificial intelligence);load dispatching;power consumption;power engineering computing;power system measurement;nonintrusive type II load monitoring;deep learning;energy consumption;type II home appliances;load disaggregation;multiple power consumption states;deep convolutional neural networks;NILM;post-processing technique;multifunctional home appliances;Home appliances;Hidden Markov models;Smart meters;Power demand;Deep learning;Monitoring;Convolutional neural networks;Non-intrusive load monitoring;energy disaggregation;convolutional neural network;deep learning},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8720065&isnumber=8941148,151,CNN,0.956,CNN,,Load Monitoring,UK-Dale Dataset,,,
"Y. Zuo, Q. Wu, Y. Fang, P. An, L. Huang and Z. Chen, ""Multi-Scale Frequency Reconstruction for Guided Depth Map Super-Resolution via Deep Residual Network,"" in IEEE Transactions on Circuits and Systems for Video Technology, vol. 30, no. 2, pp. 297-306, Feb. 2020.",doi: 10.1109/TCSVT.2018.2890271,"Abstract: The depth maps obtained by the consumer-level sensors are always noisy in the low-resolution (LR) domain. Existing methods for the guided depth super-resolution, which are based on the pre-defined local and global models, perform well in general cases (e.g., joint bilateral filter and Markov random field). However, such model-based methods may fail to describe the potential relationship between RGB-D image pairs. To solve this problem, this paper proposes a data-driven approach based on the deep convolutional neural network with global and local residual learning. It progressively upsamples the LR depth map guided by the high-resolution intensity image in multiple scales. A global residual learning is adopted to learn the difference between the ground truth and the coarsely upsampled depth map, and the local residual learning is introduced in each scale-dependent reconstruction sub-network. This scheme can restore the depth structure from coarse to fine via multi-scale frequency synthesis. In addition, batch normalization layers are used to improve the performance of depth map denoising. Our method is evaluated in noise-free and noisy cases. A comprehensive comparison against 17 state-of-the-art methods is carried out. The experimental results show that the proposed method has faster convergence speed as well as improved performances based on the qualitative and quantitative evaluations.","keywords: {image colour analysis;image denoising;image reconstruction;image resolution;neural nets;multiscale frequency reconstruction;guided depth map super-resolution;deep residual network;consumer-level sensors;low-resolution domain;guided depth super-resolution;global models;RGB-D image pairs;deep convolutional neural network;local residual learning;LR depth map;high-resolution intensity image;global residual learning;depth structure;multiscale frequency synthesis;depth map denoising;scale-dependent reconstruction subnetwork;Color;Image reconstruction;Image edge detection;Image resolution;Noise measurement;Dictionaries;Training;Depth map super-resolution (SR);deep convolutional neural network (DCNN);depth denoising;residual learning;batch-normalization},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8598786&isnumber=8984597,152,CNN,,ResNet,,Frequency Reconstruction,,,2,
"Y. Tamaazousti, H. Le Borgne, C. Hudelot, M. -E. -A. Seddik and M. Tamaazousti, ""Learning More Universal Representations for Transfer-Learning,"" in IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 42, no. 9, pp. 2212-2224, 1 Sept. 2020.",doi: 10.1109/TPAMI.2019.2913857,"Abstract: A representation is supposed universal if it encodes any element of the visual world (e.g., objects, scenes) in any configuration (e.g., scale, context). While not expecting pure universal representations, the goal in the literature is to improve the universality level, starting from a representation with a certain level. To improve that universality level, one can diversify the source-task, but it requires many additive annotated data that is costly in terms of manual work and possible expertise. We formalize such a diversification process then propose two methods to improve the universality of CNN representations that limit the need for additive annotated data. The first relies on human categorization knowledge and the second on re-training using fine-tuning. We propose a new aggregating metric to evaluate the universality in a transfer-learning scheme, that addresses more aspects than previous works. Based on it, we show the interest of our methods on 10 target-problems, relating to classification on a variety of visual domains.","keywords: {convolutional neural nets;image classification;image representation;learning (artificial intelligence);visual world;pure universal representations;universality level;additive annotated data;CNN representations;transfer-learning scheme;Task analysis;Visualization;Measurement;Semantics;Additives;Veins;Training;Universal representations;universality evaluation;transfer-learning;visual recognition},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8703078&isnumber=9158589,153,CNN,,MulDiP+FoRT,,Transfer-Learning,"ILSVRC, VOC12",,1,
"H. Xiao, B. Kang, Y. Liu, M. Zhang and J. Feng, ""Online Meta Adaptation for Fast Video Object Segmentation,"" in IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 42, no. 5, pp. 1205-1217, 1 May 2020.",doi: 10.1109/TPAMI.2018.2890659,"Abstract: Conventional deep neural networks based video object segmentation (VOS) methods are dominated by heavily fine-tuning a segmentation model on the first frame of a given video, which is time-consuming and inefficient. In this paper, we propose a novel method which rapidly adapts a base segmentation model to new video sequences with only a couple of model-update iterations, without sacrificing performance. Such attractive efficiency benefits from the meta-learning paradigm which leads to a meta-segmentation model and a novel continuous learning approach which enables online adaptation of the segmentation model. Concretely, we train a meta-learner on multiple VOS tasks such that the meta model can capture their common knowledge and gains the ability to fast adapt the segmentation model to new video sequences. Furthermore, to deal with unique challenges of VOS tasks from temporal variations in the video, e.g., object motion and appearance changes, we propose a principled online adaptation approach that continuously adapts the segmentation model across video frames by exploiting temporal context effectively, providing robustness to annoying temporal variations. Integrating the meta-learner with the online adaptation approach, the proposed VOS model achieves competitive performance against the state-of-the-arts and moreover provides faster per-frame processing speed.","keywords: {convolutional neural nets;image motion analysis;image segmentation;image sequences;learning (artificial intelligence);object tracking;video signal processing;online meta adaptation;fast video object segmentation;video object segmentation methods;base segmentation model;video sequences;model-update iterations;meta-learning paradigm;meta-segmentation model;principled online adaptation approach;video frames;VOS model;conventional deep neural networks;Adaptation models;Task analysis;Object segmentation;Optical imaging;Motion segmentation;Image segmentation;Runtime;Meta learning;video object segmentation;convolutional neural networks},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8611188&isnumber=9055268,154,R-CNN,,MVOS,,Object Segmentation,DAVIS-16,,2,
"Z. Chen, K. Gryllias and W. Li, ""Intelligent Fault Diagnosis for Rotary Machinery Using Transferable Convolutional Neural Network,"" in IEEE Transactions on Industrial Informatics, vol. 16, no. 1, pp. 339-349, Jan. 2020.",doi: 10.1109/TII.2019.2917233,"Abstract: Deep neural networks present very competitive results in mechanical fault diagnosis. However, training deep models require high computing power while the performance of deep architectures in extracting discriminative features for decision making often suffers from the lack of sufficient training data. In this paper, a transferable convolutional neural network (CNN) is proposed to improve the learning of target tasks. First, a one-dimensional CNN is constructed and pretrained based on large source task datasets. Then a transfer learning strategy is adopted to train a deep model on target tasks by reusing the pretrained network. Thus, the proposed method not only utilizes the learning power of deep network but also leverages the prior knowledge from the source task. Four case studies are considered and the effects of transfer layers and training sample size on classification effectiveness are investigated. Results show that the proposed method exhibits better performance compared with other algorithms.","keywords: {convolutional neural nets;data analysis;fault diagnosis;feature extraction;learning (artificial intelligence);machinery;mechanical engineering computing;pattern classification;transfer learning strategy;source task datasets;mechanical fault diagnosis;deep neural networks;convolutional neural network;rotary machinery;intelligent fault diagnosis;training sample size;transfer layers;Task analysis;Fault diagnosis;Feature extraction;Kernel;Training;Training data;Deep learning;Convolutional neural network (CNN);fault diagnosis;rotary machinery;transfer learning},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8716596&isnumber=8952812,155,CNN,0.97,TCNN,,Fault Diagnosis for Rotary,,,,
"H. Yang, J. -Y. Kim, H. Kim and S. P. Adhikari, ""Guided Soft Attention Network for Classification of Breast Cancer Histopathology Images,"" in IEEE Transactions on Medical Imaging, vol. 39, no. 5, pp. 1306-1315, May 2020.",doi: 10.1109/TMI.2019.2948026,"Abstract: An attention guided convolutional neural network (CNN) for the classification of breast cancer histopathology images is proposed. Neural networks are generally applied as black box models and often the network's decisions are difficult to interpret. Making the decision process transparent, and hence reliable is important for a computer-assisted diagnosis (CAD) system. Moreover, it is crucial that the network's decision be based on histopathological features that are in agreement with a human expert. To this end, we propose to use additional region-level supervision for the classification of breast cancer histopathology images using CNN, where the regions of interest (RoI) are localized and used to guide the attention of the classification network simultaneously. The proposed supervised attention mechanism specifically activates neurons in diagnostically relevant regions while suppressing activations in irrelevant and noisy areas. The class activation maps generated by the proposed method correlate well with the expectations of an expert pathologist. Moreover, the proposed method surpasses the state-of-the-art on the BACH microscopy test dataset (part A) with a significant margin.","keywords: {cancer;convolutional neural nets;image classification;medical image processing;class activation maps;computer-assisted diagnosis system;black box models;region-level supervision;convolutional neural network;guided soft attention network;supervised attention mechanism;classification network;breast cancer histopathology images;histopathological features;Breast cancer;Microscopy;Noise measurement;Neural networks;Pathology;Training;Task analysis;Breast cancer;microscopy image;convolutional neural network;guided attention;pattern recognition and classification},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8873545&isnumber=9084068,156,attention CNN,0.9,CNN,,Breast Cancer detection,,,1,1
"V. A. Sindagi and V. M. Patel, ""HA-CCN: Hierarchical Attention-Based Crowd Counting Network,"" in IEEE Transactions on Image Processing, vol. 29, pp. 323-335, 2020.",doi: 10.1109/TIP.2019.2928634,"Abstract: Single image-based crowd counting has recently witnessed increased focus, but many leading methods are far from optimal, especially in highly congested scenes. In this paper, we present the Hierarchical Attention-based Crowd Counting Network (HA-CCN) that employs attention mechanisms at various levels to selectively enhance the features of the network. The proposed method, which is based on the VGG16 network, consists of a spatial attention module (SAM) and a set of global attention modules (GAM). SAM enhances low-level features in the network by infusing spatial segmentation information, whereas the GAM focuses on enhancing channel-wise information in the higher level layers. The proposed method is a single-step training framework, simple to implement and achieves the state-of-the-art results on different datasets. Furthermore, we extend the proposed counting network by introducing a novel set-up to adapt the network to different scenes and datasets via weak supervision using image-level labels. This new set up reduces the burden of acquiring labor intensive point-wise annotations for new datasets while improving the cross-dataset performance.","keywords: {convolutional neural nets;feature extraction;image annotation;image segmentation;learning (artificial intelligence);VGG16 network;spatial attention module;global attention modules;HA-CCN;single image-based crowd counting;hierarchical attention-based crowd counting network;SAM;GAM;infusing spatial segmentation information;channel-wise information;single-step training framework;low-level features;convolutional neural network;CNN;labor intensive point-wise annotations;Training;Task analysis;Adaptation models;Supervised learning;Semantics;Decoding;Image segmentation;Crowd counting;weakly supervised learning;crowd analytics},",URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8767009&isnumber=8835130,157,attention CNN,,HA-CCN,,,UCF-QNRF,,2,
